---
sidebar_position: 12
title: "‚ö° Am√©liorez les performances des LLM locaux avec des mod√®les d√©di√©s aux t√¢ches"
---

# Am√©liorez les performances avec des mod√®les d√©di√©s aux t√¢ches

Open-WebUI propose plusieurs fonctionnalit√©s automatis√©es‚Äîtelles que la g√©n√©ration de titres, la cr√©ation de tags, l'autocompl√©tion et la g√©n√©ration de requ√™tes de recherche‚Äîpour am√©liorer l'exp√©rience utilisateur. Cependant, ces fonctionnalit√©s peuvent g√©n√©rer de multiples requ√™tes simultan√©es vers votre mod√®le local, ce qui peut nuire aux performances sur les syst√®mes avec des ressources limit√©es.

Ce guide explique comment optimiser votre configuration en configurant un mod√®le de t√¢che d√©di√© et l√©ger, ou en d√©sactivant s√©lectivement les fonctionnalit√©s automatiques, pour garantir que votre fonctionnalit√© principale de chat reste r√©active et efficace.

---

> [!ASTUCE]
>## Pourquoi Open-WebUI semble lent ?
>Par d√©faut, Open-WebUI poss√®de plusieurs t√¢ches d'arri√®re-plan qui peuvent donner l'impression de magie, mais qui peuvent √©galement imposer une charge importante sur les ressources locales :
>- **G√©n√©ration de titre**
>- **G√©n√©ration de tags**
>- **G√©n√©ration d'autocompl√©tion** (cette fonction se d√©clenche √† chaque frappe)
>- **G√©n√©ration de requ√™tes de recherche**
>
>Chacune de ces fonctionnalit√©s effectue des requ√™tes asynchrones vers votre mod√®le. Par exemple, des appels continus de la fonction d'autocompl√©tion peuvent consid√©rablement retarder les r√©ponses sur des appareils avec une m√©moire ou une puissance de traitement limit√©es, tels qu'un Mac avec 32 Go de RAM ex√©cutant un mod√®le quantifi√© 32B.
>
>L'optimisation du mod√®le de t√¢ches peut aider √† isoler ces t√¢ches d'arri√®re-plan de votre application principale de chat, am√©liorant ainsi la r√©activit√© globale.
>
---

## ‚ö° Comment optimiser les performances du mod√®le de t√¢ches

Suivez ces √©tapes pour configurer un mod√®le de t√¢che efficace :

### √âtape 1¬†: Acc√©der au panneau d'administration

1. Ouvrez Open-WebUI dans votre navigateur.
2. Acc√©dez au **panneau d'administration**.
3. Cliquez sur **Param√®tres** dans le menu lat√©ral.

### √âtape 2¬†: Configurer le mod√®le de t√¢ches

1. Allez dans **Interface > D√©finir le mod√®le de t√¢ches**.
2. Choisissez l'une des options suivantes en fonction de vos besoins :

   - **Mod√®le local l√©ger (recommand√©)**
     - S√©lectionnez un mod√®le compact tel que **Llama 3.2 3B** ou **Qwen2.5 3B**.
     - Ces mod√®les offrent des r√©ponses rapides tout en consommant peu de ressources syst√®me.

   - **Point de terminaison API h√©berg√© (pour une vitesse maximale)**
     - Connectez-vous √† un service API h√©berg√© pour g√©rer le traitement des t√¢ches.
     - Cela peut √™tre tr√®s √©conomique. Par exemple, OpenRouter propose les mod√®les Llama et Qwen √† moins de **1,5 cent par million de tokens d'entr√©e**.

   - **D√©sactiver les automatisations inutiles**
     - Si certaines fonctionnalit√©s automatis√©es ne sont pas n√©cessaires, d√©sactivez-les pour r√©duire les appels d'arri√®re-plan inutiles‚Äîsurtout les fonctionnalit√©s comme l'autocompl√©tion.

![Configuration du mod√®le local r√©gl√©e sur Qwen2.5:3b](/images/tutorials/tips/set-task-model.png)

### √âtape 3¬†: Enregistrer vos modifications et tester

1. Enregistrez la nouvelle configuration.
2. Interagissez avec votre interface de chat et observez la r√©activit√©.
3. Si n√©cessaire, ajustez en d√©sactivant davantage les fonctionnalit√©s automatis√©es inutilis√©es, ou en exp√©rimentant diff√©rents mod√®les de t√¢ches.

---

## üöÄ Configuration recommand√©e pour les mod√®les locaux

| Strat√©gie d'optimisation         | Avantage                                  | Recommand√© pour                        |
|---------------------------------|------------------------------------------|----------------------------------------|
| **Mod√®le local l√©ger**          | R√©duit l'utilisation des ressources       | Syst√®mes avec mat√©riel limit√©          |
| **Point de terminaison API h√©berg√©** | Offre les temps de r√©ponse les plus rapides| Utilisateurs avec acc√®s internet/API fiable|
| **D√©sactiver les fonctionnalit√©s automatis√©es** | Maximise les performances en r√©duisant la charge | Ceux ax√©s sur la fonctionnalit√© principale de chat|

Mettre en ≈ìuvre ces recommandations peut grandement am√©liorer la r√©activit√© d'Open-WebUI tout en permettant √† vos mod√®les locaux de g√©rer efficacement les interactions de chat.

---

## üí° Conseils suppl√©mentaires

- **Surveillez les ressources syst√®me¬†:** Utilisez les outils de votre syst√®me d'exploitation (comme le Moniteur d'activit√© sur macOS ou le Gestionnaire des t√¢ches sous Windows) pour surveiller l'utilisation des ressources.
- **R√©duisez les appels parall√®les au mod√®le¬†:** Limiter les automatisations d'arri√®re-plan emp√™che les requ√™tes simultan√©es de surcharger votre LLM.
- **Exp√©rimentez les configurations¬†:** Testez diff√©rents mod√®les l√©gers ou points de terminaison h√©berg√©s pour trouver un √©quilibre optimal entre vitesse et fonctionnalit√©.
- **Restez √† jour¬†:** Les mises √† jour r√©guli√®res d'Open-WebUI incluent souvent des am√©liorations de performances et des corrections de bugs, veillez donc √† tenir votre logiciel √† jour.

---

En appliquant ces modifications de configuration, vous soutiendrez une exp√©rience Open-WebUI plus r√©active et efficace, permettant √† votre LLM local de se concentrer sur la fourniture d'interactions de chat de haute qualit√© sans d√©lais inutiles.
