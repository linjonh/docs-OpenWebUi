---
sidebar_position: 6
title: "📝 評価"
---


## なぜモデルを評価する必要があるのか？

中規模企業の機械学習エンジニアである**Alex**をご紹介します。Alexは世の中に多数のAIモデル—GPTs、LLaMAなど—が存在することを知っていますが、どれが現在のタスクに最適なのかを判断する必要があります。これらのモデルは紙の上では素晴らしいように聞こえますが、Alexは公共のリーダーボードだけを頼りにすることはできません。それらのモデルは文脈や条件によって異なる性能を発揮し、評価データセットでトレーニングされているモデルもあるかもしれません（注意が必要です！）。さらに、これらのモデルが生成する文章が時々…違和感を覚えることもあります。

そこでOpen WebUIが登場します。これにより、Alexとそのチームは自分たちの実際のニーズに基づいてモデルを簡単に評価する方法を提供します。複雑な数式なし。面倒な操作もなし。ただ単にモデルと対話しながら親指で評価するだけ。

### TL;DR

- **評価の重要性**: モデルが多すぎて、すべてが特定のニーズを満たすわけではありません。一般的な公共リーダーボードは常に信頼できるわけではありません。
- **問題解決方法**: Open WebUIは内蔵された評価システムを提供します。サムズアップ／サムズダウンでモデルの応答を評価できます。
- **舞台裏で何が起こるのか**: 評価に応じてパーソナライズされたリーダーボードが調整され、評価されたチャットのスナップショットが将来のモデル微調整に使用されます！
- **評価オプション**:
  - **Arena Model**: モデルをランダムに選択して比較。
  - **通常の対話**: 通常のチャットを行い、応答を評価。

---

### なぜ公共評価では十分ではないのか？

- 公共リーダーボードは**あなたの**特定のユースケースに合わせたものではありません。
- 一部のモデルは評価データセットでトレーニングされており、結果の公平性に影響を与える可能性があります。
- モデルは全体的には良好に動作するかもしれませんが、そのコミュニケーションスタイルや応答が求める「雰囲気」に合わないことがあります。

### 解決策: Open WebUIによるパーソナライズされた評価

Open WebUIには、モデルと対話しながら特定のニーズに最も適したモデルを見つけることができる内蔵の評価機能があります。

仕組みは簡単です！

- **チャット中**に、応答が気に入ったらサムズアップ、そうでなければサムズダウンを付けます。メッセージに**兄弟メッセージ**（例: 再生成された応答や並行比較の一部）が含まれる場合、これはあなたの**個人リーダーボード**に貢献しています。
- **リーダーボード**は管理セクションで簡単にアクセス可能で、あなたのチームにとって最も良い結果を出すモデルを追跡できます。

便利な機能？ **応答を評価するとき**、システムはその会話の**スナップショット**をキャプチャします。これが後にモデルの改善や将来のモデルトレーニングに使用されます。（注: 現在開発途中です！）

---

### AIモデルを評価する2つの方法

Open WebUIはAIモデルを評価するための2つの簡単なアプローチを提供します。

### **1. Arena Model**

**Arena Model**は利用可能なモデルのプールからランダムにモデルを選択し、公平かつ偏らない評価を確保します。これにより、手動比較の潜在的な欠陥—**生態学的妥当性**（無意識、または意識的に特定のモデルを優先することを回避）—を排除するのに役立ちます。

使用方法:
- Arena Modelのセレクターからモデルを選択します。
- 通常通りモデルを使用しますが、これで「アリーナモード」に入りました。
  
リーダーボードにフィードバックを反映させるには、**兄弟メッセージ**が必要です。兄弟メッセージとは何でしょうか？兄弟メッセージとは、同じクエリによって生成された代替応答（メッセージ再生成や複数モデルによる並行応答）を指します。この方法で、応答を**直接比較**できます。

- **採点のヒント**: 1つの応答にサムズアップすると、もう1つは自動的にサムズダウンされます。ですので、慎重に判断し、真に優れていると思うメッセージのみをアップしてください！
- 応答を評価したら、モデルがどのように順位付けされているかをリーダーボードで確認できます。

これがArena Modelインターフェースの例です:

![Arena Model Example](/images/evaluation/arena.png)

さらに深く知りたい？[**Chatbot Arena**](https://lmarena.ai/)のようなセットアップを再現することもできます！

![Chatbot Arena Example](/images/evaluation/arena-many.png)

### **2. 通常の対話**

「アリーナモード」に切り替えずとも、Open WebUIを通常通り利用し、日常的な操作中にAIモデルの応答を評価することが可能です。モデル応答に対してサムズアップ／サムズダウンをいつでも気軽に行うことができます。ただし、**リーダーボード評価にフィードバックを利用したい**場合は、モデルを切り替え、別のモデルと対話する必要があります。これにより、**兄弟応答**が生じ、2つの異なるモデル間の比較のみがランキングに影響を与えるようにします。

例えば、通常の対話中の評価方法は以下の通りです:

![Normal Model Rating Interface](/images/evaluation/normal.png)

そして、アリーナに似たマルチモデル比較の設定例はこちらです:

![Multi-Model Comparison](/images/evaluation/normal-many.png)

---

## リーダーボード

評価した後、管理パネルの**ランキングボード**をチェックしてみてください。ここで、モデルがどのようにパフォーマンスを発揮しているかを視覚的に確認できます。**イロレーティングシステム**（チェスのランキングのようなもの）を使って順位付けされています。評価中にどのモデルが本当に際立っているのかをリアルに見ることができます。

これはランキングボードのサンプルレイアウトです：

![ランキングボード例](/images/evaluation/leaderboard.png)

### トピックベースのリランキング

チャットを評価する際に、**トピックごとにタグ付け**することで、より詳細な洞察を得ることができます。これは、**顧客サービス、クリエイティブライティング、技術サポート**など、異なる分野で作業している場合に特に便利です。

#### 自動タグ付け
Open WebUIは、会話のトピックに基づいて**自動的にチャットをタグ付け**しようとします。ただし、使用しているモデルによっては、自動タグ付け機能が**失敗したり**会話を誤解することがあります。その場合は、フィードバックを正確にするために**手動でチャットにタグ付けをする**のが最善です。

- **手動でタグ付けする方法**：レスポンスを評価するとき、会話のコンテキストに基づいて独自のタグを追加するオプションがあります。
  
これを省略しないでください！タグ付けは非常に強力で、**特定のトピックに基づいてモデルを再ランク付けする**ことができます。たとえば、技術サポートの質問に答えるうえでどのモデルが最適か、または一般的な顧客問い合わせでどのモデルが優れているかを確認したい場合に役立ちます。

リランキングの例は次のようになります：

![トピックごとのリランキングランキングボード](/images/evaluation/leaderboard-reranked.png)

---

### サイドノート: モデルのファインチューニング用のチャットスナップショット

モデルのレスポンスを評価するたびに、Open WebUIはそのチャットの*スナップショットをキャプチャ*します。これらのスナップショットは、最終的に**独自のモデルをファインチューニング**するために使用できます——つまり、評価がAIの継続的な改善に貢献するのです。

*(この機能は現在積極的に開発されていますので、続報をお楽しみに！)*

---

## まとめ

**要約すると**、Open WebUIの評価システムには2つの明確な目標があります：
1. **モデルを簡単に比較**する手助けをすること。
2. 最終的には、あなたの個別のニーズに最も適したモデルを見つけること。

このシステムの核心には、AIモデルの評価を**シンプル、透明、カスタマイズ可能**にするということがあります。アリーナモデルまたは通常のチャットインタラクションのいずれを使用しても、**特定のユースケースに最適なAIモデルを決定するためのコントロールを完全に握っています**！

**いつでも**、すべてのデータは**あなたのインスタンスに安全に保存**され、あなたが特に**コミュニティ共有を選択**しない限り共有されることはありません。あなたのプライバシーとデータの自主性が常に優先されます。