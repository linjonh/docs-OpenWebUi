---
sidebar_position: 400
title: "⭐ 特徴"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUIの主要な特徴 ⭐

- 🚀 **簡単なセットアップ**: Docker、Kubernetes、Podman、Helm Charts (`kubectl`、`kustomize`、`podman`、もしくは`helm`)を使用してシームレスにインストール。`:ollama`イメージはOllamaが同梱されており、CUDA対応の`:cuda`イメージもサポートしています。

- 🛠️ **ガイド付き初期設定**: 初回設定時に管理者アカウントを作成する明示的なフローを含め、明確な手順でセットアッププロセスを完了できます。

- 🤝 **OpenAI API統合**: OpenAI互換APIを簡単に統合して、多様な会話とOllamaモデルを並行して利用可能。OpenAI API URLは、Open WebUIをさまざまなサードパーティ製アプリケーションとシームレスに統合するためにカスタマイズできます。

- 🛡️ **詳細な権限とユーザーグループ**: 管理者が詳細なユーザーロール、ユーザーグループ、およびワークスペース内の権限を作成する機能を提供することで、すべてのユーザーに安全な使用環境を確保します。この詳細設定により、セキュリティが向上するだけでなく、カスタムユーザー体験を可能にし、ユーザー間の所有感と責任感を育成します。

- 📱 **レスポンシブデザイン**: デスクトップPC、ノートパソコン、モバイルデバイスでシームレスな体験を楽しめます。

- 📱 **モバイル対応プログレッシブウェブアプリ (PWA)**: `localhost`または個人ドメインでのオフラインアクセスとスムーズなユーザーインターフェースを備えたモバイル端末向けのネイティブPWA体験を楽しめます。デバイスにインストール可能なPWAにするためには、安全なコンテキストで提供される必要があります。通常はHTTPS経由で提供される必要があります。

  :::info

  - PWAをセットアップするには、Linux、Docker、リバースプロキシ（例えば`Nginx`、`Caddy`、`Traefik`など）といった技術の基礎的な理解が必要です。これらのツールを使用することで、自身のニーズに合わせたPWAを簡単に構築・展開するプロセスを効率化できます。「ワンクリックインストール」オプションはありませんが、HTTPSを使用して安全にOpen WebUIインスタンスを展開するためにはユーザーの経験が必要です。これらのリソースを使用することで、ニーズに合わせてPWAを作成・展開するプロセスを容易にできます。

  :::

- ✒️🔢 **MarkdownとLaTeXの完全サポート**: Markdown、LaTeX、そしてリッチテキスト機能を活用して、LLM体験をより豊かにします。

- 🧩 **モデルビルダー**: Open WebUIから直接ベースOllamaモデルを使用してカスタムモデルを簡単に作成可能。カスタムキャラクターやエージェントの作成、モデル要素のカスタマイズ、[Open WebUI Community](https://openwebui.com/)経由でのモデルインポートも容易に行えます。

- 📚 **ローカルおよびリモートRAG統合**: チャットインタラクションの未来を探索し、Retrieval Augmented Generation (RAG)技術を用いてドキュメントを調べることができます。ドキュメントはワークスペースの「Documents」タブにロードされた後、クエリの前にポンドキー[`#`]を使用するか、プロンプトをポンドキー[`#`]で開始し、続いてURLを指定することでウェブページコンテンツ統合が可能です。

- 📄 **ドキュメント抽出**: PDF、Word文書、Excelスプレッドシート、PowerPointプレゼンテーションなどさまざまな形式のドキュメントからテキストやデータを抽出。高度なドキュメント処理機能により、ナレッジベースとのシームレスな統合を実現し、複雑なドキュメントから構造やフォーマットを保持した正確な情報の取得・生成を可能にします。

- 🔍 **RAG用ウェブ検索**: 様々な検索プロバイダーから結果を選択し、ローカルのRetrieval Augmented Generation (RAG)体験に直接注入できます。

- 🌐 **ウェブブラウズ機能**: URLの後に`#`コマンドを用いることでチャット体験にウェブサイトをシームレスに統合。この機能により、会話にウェブコンテンツを直接組み込むことが可能になり、インタラクションの豊かさや深さを向上させます。

- 🎨 **画像生成統合**: 動的なビジュアルコンテンツでチャット体験を豊かにするために画像生成機能をシームレスに組み込み可能。

- ⚙️ **同時モデル使用**: 複数のモデルを同時に簡単に操作し、それぞれ独自の強みを活用して最適な回答を提供。多様なモデルモダリティを並行して利用することで体験を向上させます。

- 🔐 **ロールベースアクセス制御（RBAC）**: 制限された権限で安全なアクセスを確保。承認された人のみがOllamaにアクセス可能で、モデル作成および取得権は管理者のみに限定されています。

- 🌐🌍 **多言語対応**: 国際化(`i18n`)機能により、好みの言語でOpen WebUIを体験可能。当社は対応言語を拡張するため貢献者を積極的に募集中です！

- 🌟 **継続的な更新**: Open WebUIの改善に向けて定期的な更新、修正、新機能の追加に取り組み続けます。

## さらに多くの注目すべき機能を含んでいます... ⚡️

---

### 🔧 パイプライン対応

- 🔧 **パイプラインフレームワーク**: モジュール式のプラグインフレームワークにより、Open WebUI体験をシームレスに統合・カスタマイズ可能です。これによりカスタマイズと機能が強化されます (https://github.com/open-webui/pipelines)。AIエージェントから家庭オートメーションAPIまで、Pythonライブラリの統合やカスタムロジックの追加が簡単に実現できます。

- 📥 **パイプラインのアップロード**: `管理パネル` > `設定` > `パイプライン`メニューから直接パイプラインをアップロードし、管理プロセスを簡素化します。

#### 私たちのパイプラインフレームワークでの可能性は無限であり、事実上の制限はありません。始めるためのいくつかの事前構築されたパイプラインをご利用ください!

- 🔗 **ファンクションコーリング**: [Function Calling](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)をパイプラインを通じてシームレスに統合し、詳細な機能呼び出し機能を備えたLLMとのやり取りを強化できます。

- 📚 **カスタムRAG**: [リトリーバル・オーグメンテーション生成 (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag)のカスタムパイプラインを統合し、カスタムRAGロジックを使用してLLMとの対話を強化します。

- 📊 **Langfuseによるメッセージ監視**: [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py)パイプラインを介して、リアルタイムの使用統計でメッセージインタラクションを監視・分析します。

- ⚖️ **ユーザーのレート制限**: [Rate Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py)パイプラインを使って、LLMへのリクエストフローを管理し、レート制限を超えないようにします。

- 🌍 **リアルタイムLibreTranslate翻訳**: [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py)パイプラインを使用してLLMとのやり取りにリアルタイム翻訳を組み込み、言語を超えたコミュニケーションを実現します。
  - このパイプラインを機能させるには、DockerコンテナでのLibreTranslateのセットアップが必要です。

- 🛡️ **有害メッセージフィルタリング**: [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py)パイプラインを使用し、有害なメッセージを自動的にフィルタリングして、クリーンで安全なチャット環境を維持します。

- 🔒 **LLM-Guard**: [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py)パイプラインを使用して、LLMとの安全なやり取りを確保します。この機能には、プロンプト注入スキャナーが含まれており、大規模言語モデルを対象にした巧妙な入力操作を検出して緩和し、データ漏洩を防ぎ、プロンプト注入攻撃に対する抵抗層を追加します。

- 🕒 **会話のターン制限**: [Conversation Turn Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py)パイプラインを使用して、会話のターンに制限を設定し、やり取りの管理を改善します。

- 📈 **OpenAI生成統計**: [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py)パイプラインは、OpenAIモデルの詳細な生成統計を提供します。

- **🚀 マルチモデル対応**: [各プロバイダー](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)からのさまざまなAIモデルとのシームレスな統合を通じて、選択肢が広がり、多様な言語モデルとのやり取りが可能になります。

#### 豊富な機能とカスタマイズオプションに加え、[使用可能な例のパイプラインライブラリ](https://github.com/open-webui/pipelines/tree/main/examples)や[実用的な例のスキャフォールドパイプライン](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)を提供しています。これらのリソースにより開発プロセスが効率化され、Pythonとパイプラインを活用して強力なLLMのインタラクションを迅速に作成できるようになります。楽しい開発を！ 💡

---

### 🖥️ ユーザーエクスペリエンス

- 🖥️ **直感的なインターフェース**: ChatGPTのユーザーインターフェースからインスピレーションを得て、ユーザーの使いやすさを念頭に設計されました。

- ⚡ **高速な応答性**: 常に速くて応答性の高い性能をお楽しみください。

- 🎨 **スプラッシュスクリーン**: よりスムーズなユーザー体験を提供する簡易な読み込み画面。

- 🌐 **パーソナライズされたインターフェース**: 設定 > インターフェースから新しくデザインされた検索ランディングページと従来のチャットUIを選択可能。これにより、個別に調整された体験が提供されます。

- 📦 **Pipインストール方法**: Open WebUIのインストールは、コマンド`pip install open-webui`を使用して簡単に行うことができます。このプロセスは効率的で、新しいユーザーにも利用しやすいです。詳細情報はこちらへ: https://pypi.org/project/open-webui/。

- 🌈 **テーマカスタマイズ**: Open WebUIの体験を個性的にしましょう。シンプルで洗練されたテーマ、カスタマイズ可能なチャット背景画像、そして3つのモード（ライト、ダーク、OLEDダーク）を選べます。または、*Her*に選ばせてみても面白いかも！ ;)

- 🖼️ **カスタム背景対応**: 設定 > インターフェイスからカスタム背景を設定して、体験をパーソナライズしましょう。

- 📝 **Markdown対応のリッチバナー**: Markdown対応により、より視覚的に魅力的なバナーを作成して、動的でリッチなコンテンツを発表できます。

- 💻 **コード構文ハイライト**: 構文ハイライト機能により、コードの可読性が向上し、明確で簡潔なコードビューを提供します。

- 🗨️ **ユーザーメッセージのMarkdownレンダリング**: ユーザーメッセージがMarkdownでレンダリングされることで、可読性と対話が向上します。

- 🎨 **柔軟なテキスト入力オプション**: チャットでのリッチテキスト入力と従来のテキストエリア入力を切り替えることができ、先進的なフォーマットとシンプルなテキスト入力のどちらかを選べるようにします。

- 👆 **シームレスなコード共有**: コード共有とコラボレーションプロセスを簡素化し、コードブロックのフローティングコピーボタンやコードスパンからのクリックコピー機能など、便利なコピーオプションを提供することで、時間を節約し、ストレスを軽減します。

- 🎨 **インタラクティブアーティファクト**: ウェブコンテンツやSVGをインターフェイス内で直接レンダリングでき、素早い反復やライブ変更をサポートし、創造性と生産性を向上させます。

- 🖊️ **ライブコード編集**: 強化されたコードブロックにより、LLMレスポンス内で直接ライブ編集が可能です。ライブリロードをアーティファクトがサポートしているため、コーディングやテストが効率化されます。

- 🔍 **SVG拡張操作**: SVG画像（Mermaidダイアグラムを含む）にパン＆ズーム機能を追加し、複雑な概念の理解を深めることができます。

- 🔍 **テキスト選択クイックアクション**: LLMレスポンス内でテキストをハイライトするとフローティングボタンが表示され、"質問する"や"説明する"などの深い対話を提供し、全体的なユーザー体験を向上させます。

- ↕️ **双方向チャット対応**: 左から右、右から左へのチャット方向を簡単に切り替えられ、様々な言語の好みに対応します。

- 📱 **モバイルでのアクセシビリティ**: モバイルデバイスでは、シンプルなスワイプジェスチャーでサイドバーの開閉が可能です。

- 🤳 **対応デバイスでのハプティックフィードバック**: Androidデバイスは、特定の操作で触覚フィードバックをサポートし、没入感のあるタクタイル体験を提供します。

- 🔍 **ユーザー設定検索**: 設定フィールドを迅速に検索できるため、使いやすさとナビゲーションが向上します。

- 📜 **オフラインでのSwaggerドキュメント**: 開発者に優しいSwagger APIドキュメントにオフラインでアクセスでき、どこにいても完全なアクセシビリティを提供します。

- 💾 **パフォーマンス最適化**: 大規模な依存関係の遅延読み込みにより、初期のメモリ使用量を最小限に抑え、パフォーマンスを向上させ、読み込み時間を短縮します。

- 🚀 **永続的かつスケーラブルな設定**: Open WebUIの設定はデータベース（webui.db）に保存され、負荷分散がスムーズで高可用性のセットアップが可能になり、複数のインスタンス間での設定の永続性を確保します。このため設定へのアクセスや再利用が簡単になります。

- 🔄 **インポート/エクスポートの携帯性**: Open WebUIの設定を簡単にインポートおよびエクスポートできるため、複数のシステム間での設定複製が容易です。

- ❓ **ドキュメント＆ショートカットに簡単アクセス**: メインUI画面の右下隅にあるクエスチョンマークボタン（デスクトップPCやノートPCなどの大きな画面で使用可能）から、Open WebUIのドキュメントページや利用可能なキーボードショートカットに簡単にアクセスできます。

- 📜 **変更履歴＆アップデート確認**: ユーザーは、`設定` > `詳細` > `新機能を見る`メニューで包括的な変更履歴にアクセスし、更新を確認できます。この機能により、最新の機能、改善点、バグ修正について簡単に把握し、アップデートを確認することができます。

---

### 💬 会話

- 💬 **真の非同期チャット**: 真の非同期チャット機能により、複数のタスクを並行して実行できます。例えば、チャットを作成し、他の作業を行い、後で戻ってきて返信を確認できます。

- 🔔 **チャット完了通知**: 非アクティブなタブでチャットが完了した際に、即時のUI内通知で更新情報を受け取ることができ、完了した返信を見逃しません。

- 🌐 **通知Webhook統合**: 長時間のチャットや外部統合のニーズに対応するため、タブが閉じている間でもタイムリーな更新を受け取れるカスタマイズ可能なWebhook通知をサポートします。

- 📚 **チャンネル（ベータ）**: ユーザーとAIの間でリアルタイムコラボレーションを実現するDiscord/Slack風のチャットルーム、チャンネル用のボット作成、そしてプロアクティブなマルチエージェントワークフローの非同期通信を行います。

- 🖊️ **チャンネルのリアルタイム入力中インジケーター**: チャンネル内でリアルタイムの入力中インジケーターにより、コラボレーションが向上し、全員が集中し、情報を把握できます。

- 👤 **ユーザーステータスインジケーター**: チャンネル内でプロファイル画像をクリックすることで、ユーザーのステータスを素早く確認できます。これにより、連携や利用可能状況の把握が向上します。

- 💬 **チャットコントロール**: 各チャットセッションのパラメーターを簡単に調整でき、インタラクションをより正確に制御できます。

- 💖 **お気に入りのレスポンス管理**: チャット概要から直接お気に入りのレスポンスを簡単にマークし整理することで、好みのレスポンスへのアクセスや取り出しが容易になります。

- 📌 **ピン留めチャット**: 重要な会話を簡単にアクセスできるよう、チャットのピン留めに対応しています。

- 🔍 **RAG埋め込みのサポート**: `管理パネル` > `設定` > `ドキュメント` メニューでRetrieval Augmented Generation（RAG）の埋め込みモデルを直接変更でき、ドキュメント処理機能が向上します。この機能はOllamaモデルとOpenAIモデルをサポートしています。

- 📜 **RAG機能の引用**: Retrieval Augmented Generation（RAG）機能により、LLMに入力されたドキュメントの文脈を簡単に追跡でき、参照ポイントとして引用を追加します。

- 🌟 **拡張されたRAGパイプライン**: 当社のRAG埋め込み機能に対する`BM25`による再ランキングを`CrossEncoder`で強化しつつ、関連性スコアの閾値を設定できる切替可能なハイブリッド検索サブ機能。

- 📹 **YouTube RAGパイプライン**: 動画URLを経由してYouTube動画を要約するための特化したRetrieval Augmented Generation（RAG）パイプラインで、動画文字起こしに直接スムーズにアクセスできます。

- 📁 **包括的なドキュメント取得**: 全文ドキュメントの取得と従来のスニペットの切替を可能にし、要約などの包括的なタスクをサポートし、ドキュメント機能を強化します。

- 🌟 **RAGの引用関連性**: RAGの結果に関連性の割合を追加し、引用の正確性を簡単に評価できます。

- 🗂️ **高度なRAG**: 取得前に最適なクエリーを決定するためにチャット履歴をスマートに前処理し、RAGの精度を向上させます。

- 📚 **RAGのインライン引用**: Retrieval-Augmented Generation（RAG）のレスポンスにシームレスなインライン引用が追加され、追跡性が向上し、新たにアップロードされたファイルのソースを明確に示します。

- 📁 **大規模テキスト処理**: 大量に貼り付けられたテキストをオプションでファイルアップロードに変換し、RAGで直接使用できるようにして、チャットインターフェースを整理できます。

- 🔄 **マルチモーダルサポート**: 画像（例：`LLaVA`など）を含むマルチモーダルインタラクションをサポートするモデルと簡単に連携できます。

- 🤖 **複数モデルサポート**: さまざまなモデル間を素早く切り替えて、多様なチャットインタラクションを実現します。

- 🔀 **複数モデルチャットのレスポンス統合**: 複数モデルからのレスポンスを1つの一貫した返信に統合し、対話を充実させます。

- ✅ **チャット内で同一モデルの複数インスタンスをサポート**: 複数モデルのチャットが拡張され、同一モデルの複数インスタンスを追加できるようになりました。

- 💬 **一時的なチャット機能**: ユーザーのインタラクションの柔軟性を向上させるため、従来のチャット履歴設定を廃止し、一時的なチャット機能を導入しました。

- 🖋️ **ユーザーメッセージ編集**: ユーザーチャット編集機能を強化し、変更を送信せずに保存できるようになりました。

- 💬 **効率的な会話編集**: Cmd/Ctrl+Shift+Enterショートカットを使用して、新しいメッセージペアを迅速かつ直感的に作成し、会話の長さテストをスムーズに行えます。

- 🖼️ **クライアント側画像圧縮**: 設定 > インターフェースから画像をアップロードする前にクライアント側で圧縮できるため、帯域幅を節約しパフォーマンスが向上します。

- 👥 **`@`モデル統合**: 会話中にローカルまたは外部の任意の利用可能なモデルにシームレスに切り替えることで、複数モデルの集合知を1つのチャットで活用できます。`@` コマンドを使用して、会話内で名前を指定することでモデルを指定できます。

- 🏷️ **会話のタグ付け**: 効率的な`tag:`クエリーシステムを使用してタグ付けされたチャットを簡単に分類し、迅速に参照し、データ収集を効率化できます。これにより、インターフェースを乱すことなく会話を管理、検索、整理できます。

- 🧠 **自動タグ付け**: 会話は、効率的な自動生成タイトルを反映して、オプションで自動的にタグ付けされ、組織化が改善されます。

- 👶 **チャットのクローン化**: 任意のチャットのスナップショットを簡単にクローン化し、保存して、将来参照したり継続したりできます。この機能により、中断した場所から再開したり、セッションを他者と共有したりするのが簡単になります。チャットのクローンを作成するには、チャットのドロップダウンオプションの`クローン`ボタンをクリックしてください。クローンについていけますか？

- ⭐ **会話フローのビジュアル化**: 会話フローの理解や複雑な議論のナビゲーションを向上させるためのインタラクティブなメッセージ図。

- 📁 **チャットフォルダー**: チャットをフォルダーに整理し、ドラッグアンドドロップで簡単に管理し、共有や分析のためにシームレスにエクスポートできます。

- 📤 **簡単なチャットインポート**: チャットエクスポート（JSON）をサイドバーにドラッグ＆ドロップするだけで、作業スペースにインポートできます。

- 📜 **プロンプトプリセットサポート**: チャット入力で`/`コマンドを使用して、カスタムプリセットプロンプトに即座にアクセスできます。事前定義された会話の開始フレーズを簡単に読み込み、やり取りを迅速化します。[Open WebUI Community](https://openwebui.com/)との統合を介してプロンプトをインポートしたり、自分で作成することもできます！

- 📅 **プロンプト変数サポート**: `{{CLIPBOARD}}`, `{{CURRENT_DATE}}`, `{{CURRENT_DATETIME}}`, `{{CURRENT_TIME}}`, `{{CURRENT_TIMEZONE}}`, `{{CURRENT_WEEKDAY}}`, `{{USER_NAME}}`, `{{USER_LANGUAGE}}`, `{{USER_LOCATION}}`などのプロンプト変数を、システムプロンプト内で使用したり、スラッシュコマンドを使ってチャット内で直接プロンプトを選択することができます。
  - `{{USER_LOCATION}}`プロンプト変数を使用するには、HTTPSによる安全な接続が必要です。このプロンプト変数を利用するには、`設定` > `インターフェース`メニューで`{{USER_LOCATION}}`をオンにする必要があります。
  - `{{CLIPBOARD}}`プロンプト変数を使用するには、デバイスのクリップボードへのアクセスが必要です。

- 🧠 **メモリー機能**: `設定` > `パーソナライズ` > `メモリー`メニューで、LLMが記憶する情報を手動で追加できます。メモリーは追加、編集、削除が可能です。

---

### 💻 モデル管理


- 🛠️ **モデルビルダー**: すべてのモデルを編集ページ内で持続的なモデルビルダーモードを使用して構築および編集できます。

- 📚 **モデルの知識サポート**: ツール、機能、および知識コレクションをモデルの編集ページから直接モデルに関連付けることができ、各モデルに利用可能な情報を強化します。

- 🗂️ **モデルプリセット**: OllamaとOpenAI APIの両方でモデルプリセットを作成および管理できます。

- 🏷️ **モデルタグ付け**: モデルワークスペースでは、タグ付けを使用してモデルを整理できます。

- 📋 **モデルセレクターのドロップダウン順序設定**: モデルワークスペース内でドラッグ＆ドロップすることでモデルを簡単に整理でき、モデルドロップダウンメニューにその変更が反映されます。

- 🔍 **モデルセレクターのドロップダウン検索**: 曖昧検索やモデルタグ、モデル説明付きで詳細情報を表示し、モデルを簡単に探して選択できます。

- ⌨️ **矢印キーでのモデル選択**: 矢印キーを使用してモデルをより迅速に選択することで、アクセス性を向上します。

- 🔧 **モデルワークスペースでのクイック操作**: モデルワークスペースでShiftキーを使用して表示/非表示またはモデル削除のクイック操作を強化。

- 😄 **透明なモデル使用状況**: 知識を拡張したモデルを使用中に、システムの状態を可視化されたステータス表示により把握可能。

- ⚙️ **高度なパラメータによる詳細な制御**: `seed`、`temperature`、`frequency penalty`、`context length`などのモデルパラメータを調整することで、より深いレベルの制御が可能。

- 🔄 **シームレスな統合**: [Ollamaライブラリー](https://ollama.com/library/)のモデルページから直接`ollama run {model:tag}`CLIコマンドをコピーし、モデルドロップダウンに貼り付けて簡単にモデルを選択＆取得。

- 🗂️ **Ollamaモデファイル作成**: Ollamaのモデルファイルを作成するには、`管理パネル` > `設定` > `モデル` > `モデルを作成`メニューに移動します。

- ⬆️ **GGUFファイルモデル作成**: Open WebUIの`管理設定` > `設定` > `モデル` > `実験的`メニューからGGUFファイルを直接アップロードして、Ollamaモデルを簡単に作成可能。マシンからのアップロードやHugging FaceからのGGUFファイルダウンロードオプションでプロセスを簡略化。

- ⚙️ **デフォルトモデル設定**: 新しいチャットのデフォルトモデル設定は、モバイルデバイスの`設定` > `インターフェース`メニューで設定できるほか、デスクトップPCやノートパソコンではモデルセレクタードロップダウンで新しいチャット時により簡単に設定可能。

- 💡 **LLM応答のインサイト**: 外部モデルAPIのインサイトや包括的なローカルモデル情報を含む、生成されたすべての応答の詳細を表示可能。

- 🕒 **モデルの詳細をひと目で確認**: モデルワークスペースでモデルのハッシュや最終更新タイムスタンプなどの重要な詳細を直接確認し、追跡と管理を強化。

- 📥🗑️ **モデルのダウンロード/削除**: Open WebUIからモデルを簡単にダウンロードまたは削除可能。

- 🔄 **Ollamaモデルを一括更新**: ローカルにインストールされているすべてのモデルを一度に更新する便利なボタンがあり、モデル管理を効率化。

- 🍻 **TavernAIキャラクターカード統合**: モデルビルダーでTavernAIキャラクターカード統合を活用し、より視覚的なストーリーテリングを体験できます。ユーザーはTavernAIキャラクターカードPNGをモデルファイルに組み込むことで、没入感のある魅力的なユーザー体験を提供可能。

- 🎲 **モデルプレイグラウンド（ベータ版）**: モデルプレイグラウンド領域（`ベータ版`）でモデルを試し、パラメータを簡単に調査して展開前にライブチャット環境で性能をテスト可能。

---

### 👥 コラボレーション

- 🗨️ **ローカルチャット共有**: 効率的かつシームレスな方法でチャットリンクを生成して共有し、コラボレーションとコミュニケーションを強化。

- 👍👎 **RLHFアノテーション**: あなたのメッセージにインパクトを与えるために、親指を上げる、または下げる形式で評価し、1-10の範囲で応答を評価できます。その後、テキストによるフィードバックを提供するオプションがあり、`RLHF`（人間のフィードバックによる強化学習）のデータセット作成を支援します。メッセージを使用してモデルを訓練または微調整しつつ、ローカルに保存されたデータの機密性を十分に確保します。

- 🔧 **包括的なフィードバックエクスポート**: フィードバック履歴データをJSON形式でエクスポートし、RLHF処理やさらなる分析とのシームレスな統合を実現。改善のための貴重な洞察を提供します。

- 🤝 **コミュニティシェアリング**: `Share to Open WebUI Community`ボタンをクリックして、[Open WebUIコミュニティ](https://openwebui.com/)とチャットセッションを共有できます。この機能を利用することで、他のユーザーと交流し、このプラットフォームでコラボレーションができます。
  - この機能を利用するには、Open WebUIコミュニティアカウントにサインインしてください。チャットを共有することで、生き生きとしたコミュニティを形成し、知識の共有と共同の問題解決を促進します。この機能は任意であり、`Admin Settings` > `Settings` > `General`メニューで管理者のみがオンまたはオフに切り替えることができます。

- 🏆 **コミュニティリーダーボード**: リーダーボードシステムを活用してリアルタイムでパフォーマンスを追跡。これはELO評価システムを使用しており、フィードバック履歴の共有オプションも可能です。

- ⚔️ **モデル評価アリーナ**: 管理設定から直接モデルの盲目的なA/Bテストを実施し、真の横並び比較を行うことで、ニーズに最適なモデルを見つけるのが容易になります。

- 🎯 **トピックベースのランキング**: 実験的なトピックベースの再ランク付けシステムにより、タグの類似性を基に順位を調整し、さらに正確なランキングを発見します。

- 📂 **統合された共同ワークスペース**: モデルファイル、プロンプト、ドキュメント、ツール、機能を1か所で管理できるだけでなく、複数のユーザーがモデル、知識、プロンプト、ツールにコラボレートして貢献することを可能にし、ワークフローを簡素化し、チームワークを強化します。

---

### 📚 履歴とアーカイブ

- 📜 **チャット履歴**: チャットナビゲーションサイドバー経由で会話履歴に簡単にアクセスして管理できます。`Settings` > `Chats`メニューでチャット履歴を無効にすると、新しいやり取りでチャット履歴が作成されなくなります。

- 🔄 **再生成履歴へのアクセス**: すべてのLLM応答再生成履歴を簡単に再訪問して探索できます。

- 📬 **チャットをアーカイブ**: モデルとの完了した会話を簡単に保存し、将来の参照ややり取りのために保持。すっきりとしたチャットインターフェースを保つことができます。

- 🗃️ **すべてのチャットをアーカイブ**: この機能を使用すると、すべてのチャットを一括でアーカイブできます。

- 📦 **すべてのアーカイブされたチャットをJSON形式でエクスポート**: すべてのアーカイブされたチャットを1つのJSONファイルで簡単にエクスポートでき、バックアップや転送に使用できます。

- 📄 **チャットをJSON/PDF/TXT形式でダウンロード**: チャットを`.json`, `.pdf`, `.txt`のいずれかの形式で個別に簡単にダウンロードできます。

- 📤📥 **チャット履歴のインポート/エクスポート**: `Import Chats`および`Export Chats`オプションを通じて、プラットフォーム内外でチャットデータをシームレスに移動できます。

- 🗑️ **すべてのチャットを削除**: このオプションを使用すると、すべてのチャットを永久に削除し、新しいスタートを切ることができます。

---

### 🎙️ オーディオ、音声、およびアクセシビリティ

- 🗣️ **音声入力サポート**: モデルと音声でやり取りできる便利さを楽しみましょう。また、無音状態が3秒続いた後に自動的に音声入力を送信するオプションを利用して、よりスムーズな体験を提供します。
  - マイクアクセスを有効にするには、HTTPSを介した安全な接続を手動で設定する必要があります。または[自己責任でURLを手動でホワイトリスト化する](https://docs.openwebui.com/troubleshooting/microphone-error)ことができます。

- 😊 **絵文字コール**: `Settings` > `Interface`メニューからこの機能をオンにすると、LLMが音声通話中に絵文字を使用して感情を表現し、より動的なやり取りができます。
  - この機能が機能するには、HTTPSを介した安全な接続でのマイクアクセスが必要です。

- 🎙️ **ハンズフリー音声通話機能**: ハンズフリーで音声通話を開始し、よりシームレスなやり取りを実現します。
  - この機能が機能するには、HTTPSを介した安全な接続でのマイクアクセスが必要です。

- 📹 **ビデオ通話機能**: LlaVAやGPT-4oなどの対応ビジョンモデルを使用してビデオ通話を有効にし、コミュニケーションに視覚的次元を追加します。
  - この機能が機能するには、安全なHTTPS接続を介したカメラとマイクの両方のアクセスが必要です。

- 👆 **タップで中断**: モバイルデバイスでのタップ一つで音声会話中にAIの発話を中断し、やり取りをスムーズに制御できます。

- 🎙️ **音声による中断**: モバイルデバイスでの音声によって音声会話中にAIの発話を中断し、やり取りをスムーズに制御できます。

- 🔊 **カスタマイズ可能な音声読み上げエンドポイント**: OpenAI互換のエンドポイントを構成することで、LLM応答の音声読み上げ体験をカスタマイズできます。

- 🔗 **直接的な通話モードアクセス**: モバイルデバイスユーザー向けの便利なショートカットとして、URLから直接通話モードを起動します。

- ✨ **カスタマイズ可能なテキスト音声変換 (TTS)**: メッセージコンテンツの分割方法を制御することで、柔軟な音声出力オプションを可能にします。

- 🔊 **Azure Speech Servicesとの統合**: Azure Speech Servicesをサポートし、テキスト音声変換 (TTS) の幅広い音声合成オプションを提供します。

- 🎚️ **カスタマイズ可能なオーディオ再生**: コールモード設定で、オーディオの再生速度を自由に調整でき、アクセシビリティと使いやすさを向上させます。

- 🎵 **幅広いオーディオ互換性**: RAGでaudio/x-m4aを含む幅広いオーディオファイル形式のトランスクリプションをサポートし、プラットフォーム内でのオーディオコンテンツ互換性を拡大します。

- 🔊 **オーディオ圧縮**: 実験的なオーディオ圧縮により、OpenAIの音声認識処理の25MB制限を回避可能にし、音声ベースの対話の可能性を広げます。

- 🗣️ **実験的なSpeechT5 TTS**: より良いテキスト音声変換機能を提供するローカルSpeechT5サポートを利用できます。

---

### 🐍 コード実行

- 🚀 **汎用でUI非依存のOpenAI互換プラグインフレームワーク**: 効率的なデータ処理とモデルトレーニングのために[Open WebUI Pipelines](https://github.com/open-webui/pipelines)をシームレスに統合およびカスタマイズ可能。

- 🛠️ **ネイティブPython関数呼び出し**: Open WebUI内で直接Pythonを利用してカスタムコードを楽に統合可能。カスタムRAGパイプライン、ウェブ検索ツール、およびエディター内でエージェントのような操作を開発、統合可能です。

- 🐍 **Pythonコード実行**: Pyodideを介してブラウザ内でローカルにPythonコードを実行可能、Pyodide対応ライブラリも幅広くサポートします。

- 🌊 **Mermaidレンダリング**: Open WebUI内で[Mermaid Diagramming and Charting Tool](https://mermaid.js.org/intro/)を使用し、視覚的に魅力的な図やフローチャートを作成できます。

- 🔗 **Iframeサポート**: 関数やツールを利用して、チャットインターフェース内でHTMLを直接レンダリング可能です。

---

### 🔒 統合とセキュリティ

- ✨ **複数のOpenAI互換APIサポート**: 様々なOpenAI互換APIをシームレスに統合およびカスタマイズ可能、チャット対話の柔軟性を高めます。

- 🔑 **シンプルなAPIキー管理**: OpenAIライブラリでOpen WebUIを利用するためのシークレットキーを簡単に生成および管理可能、統合と開発が容易になります。

- 🌐 **HTTP/Sプロキシサポート**: `http_proxy`または`https_proxy`環境変数を使用してネットワーク設定を簡単に構成できます。これらの変数セットにより、HTTPおよびHTTPSプロキシ用のURLを指定できます。

- 🌐🔗 **外部Ollamaサーバー接続**: 環境変数を設定することで、異なるアドレスでホストされる外部Ollamaサーバーとシームレスにリンク可能。

- 🛢️ **柔軟なデータベース統合**: SQLite、Postgres、Milvusのような多様なベクターデータベースを含むカスタムデータベースと環境変数を利用して接続可能で、柔軟でスケーラブルなデータ管理を実現します。

- 🌐🗣️ **外部音声認識サポート**: 外部音声認識 (`STT`) サービスを追加し、柔軟性を向上させ、好みのプロバイダーを選択してシームレスに操作できます。

- 🌐 **リモートChromaDBサポート**: リモートChromaDBサーバーに接続して、データベースの機能を拡張可能です。

- 🔀 **複数のOllamaインスタンス負荷分散**: チャットリクエストを複数のOllamaインスタンスに効率的に分散することで、パフォーマンスと信頼性を向上させます。

- 🚀 **高度な負荷分散と信頼性**: Redisフルサポートのステートレスインスタンス、WebSocket自動再接続、強化された負荷分散機能を活用して、WebUIのパフォーマンス、信頼性、スケーラビリティを向上させます。

- ☁️ **実験的なS3サポート**: S3サポートを備えるステートレスWebUIインスタンスを可能にし、負荷の大きい作業負担を分散し、拡張性を向上させます。

- 🛠️ **OAuthによるユーザーグループ管理**: グループレベルの管理を使用して、コラボレーション環境での管理と拡張性を向上させます。

---

### 👑 管理

- 👑 **スーパ管理者の自動割り当て**: 初回サインアップ者が自動的にスーパ管理者として割り当てられ、その役割は他の管理者も含め変更不可能。

- 🛡️ **詳細なユーザー権限管理**: ロールベースのカスタマイズ可能な権限を通じて、ユーザーのアクションやアクセスを制限し、特定のタスクを実行する権限を持つのは認可された人物のみに制限。

- 👥 **マルチユーザー管理**: ページネーションを備えた直感的な管理パネルで、複数のユーザー管理をシームレスに実行し、ユーザー管理作業を簡素化。

- 🔧 **管理者パネル**: ユーザー管理システムにより、オンボーディングやユーザー管理を効率化し、ユーザーを直接追加するか、またはCSVインポートで一括追加可能。

- 👥 **アクティブユーザー指標**: アクティブユーザーの数や、誰がどのモデルを利用しているかを監視し、ユーザー数が増加してパフォーマンスに影響が出そうな場合に役立てます。

- 🔒 **デフォルトのサインアップロール**: 新規サインアップ時のデフォルトロールを「pending」、「user」、または「admin」に指定できるため、新規ユーザーの権限やアクセスレベルを柔軟に管理可能です。

- 🔒 **新規サインアップ防止**: 新規ユーザーのサインアップを無効化し、プラットフォームへのアクセスを制限して、ユーザー数を一定に保つことができます。

- 🔒 **チャット削除防止**: 管理者が設定を切り替えることで、すべてのユーザーがチャットメッセージを削除することを防止し、監査やコンプライアンス目的でチャットメッセージを保持できます。

- 🔗 **Webhook統合**: Webhookを使用して新しいユーザーのサインアップイベントを購読できます（`Discord`、`Google Chat`、`Slack`、`Microsoft Teams`に対応）、リアルタイム通知や自動化が可能です。

- 📣 **カスタマイズ可能な通知バナー**: 管理者はconfig.json内で持続可能なカスタマイズ可能なバナーを作成できます。バナーの内容、背景色（`info`、`warning`、`error`、`success`）や、非表示可能性を設定するオプションがあり、バナーはログインしたユーザーのみがアクセス可能で、機密情報の機密性を確保します。

- 🛡️ **モデルホワイトリスト**: 管理者がユーザーの`user`ロールに対してモデルをホワイトリスト化することで、セキュリティとアクセス制御を強化し、承認されたモデルのみアクセス可能にします。

- 🔑 **コミュニティ共有の管理者コントロール**: 管理者は`管理者パネル` > `設定`メニュー内のトグルスイッチを使用して、すべてのユーザーに対するコミュニティ共有を有効または無効にできます。このトグルスイッチにより、アクセシビリティとプライバシーを管理し、安全な環境を確保します。管理者は、`コミュニティで共有`ボタンをすべてのユーザー向けに有効または無効にすることで、コミュニティ参加とコラボレーションを制御することができます。

- 📧 **信頼できるメール認証**: 信頼できるメールヘッダーを使用してオプションで認証を行い、Open WebUIインスタンスを保護する追加のセキュリティ層を追加します。

- 🔒 **バックエンドリバースプロキシ対応**: Open WebUIのバックエンドとOllama間の直接通信を通じてセキュリティを強化します。この重要な機能により、Ollamaをローカルエリアネットワーク（LAN）に公開する必要がなくなります。Open WebUIの`/ollama/api`ルートに送信されたリクエストは、バックエンドからOllamaにシームレスにリダイレクトされ、全体的なシステムセキュリティを向上させ、追加の保護層を提供します。

- 🔒 **認証**: Open WebUIは、SSO、OAuth、SAML、またはOIDCなどのフェデレーション認証スキームをネイティブにサポートしていません。ただし、認証を認証リバースプロキシに委任するように設定することで、事実上のシングルサインオン（`SSO`）エクスペリエンスを実現できます。このセットアップにより、ユーザー認証と管理を集中化し、セキュリティとユーザーの利便性を向上させます。Open WebUIを認証リバースプロキシと統合することで、既存の認証システムを活用し、ユーザーのOpen WebUIへのアクセスを簡素化できます。この機能の設定に関する詳細については、[Federated Authentication Support](https://docs.openwebui.com/features/sso)を参照してください。

- 🔓 **認証のオプション化**: `WEBUI_AUTH`を`False`に設定することで、認証を無効化する柔軟性を楽しめます。既存のユーザーがいない新規インストールやデモ目的で最適なソリューションです。

- 🚫 **高度なAPIセキュリティ**: カスタマイズされたモデルフィルターに基づいてAPIユーザーをブロックし、APIアクセスに対するセキュリティと制御を強化します。

- ❗ **管理者向け更新通知**: 管理者がログイン時に即座に更新通知を受け取り、最新の変更やシステム状況を把握し続けられるようにします。

- 👥 **ユーザーグループ管理**: 組織化と制御をスムーズに進めるためにユーザーグループを作成および管理します。

- 🔐 **グループベースのアクセス制御**: ユーザーグループに基づいてモデル、ナレッジ、プロンプト、ツールへのアクセスを細かく設定し、より制御されたセキュアな環境を提供します。

- 🛠️ **きめ細やかなユーザー権限**: ワークスペースの権限を簡単に管理できるほか、ファイルのアップロード、削除、編集、一時チャットの権限やモデル、ナレッジ、プロンプト、ツールの作成権限も管理可能です。

- 🔑 **LDAP認証**: ユーザー管理にLDAPをサポートし、セキュリティとスケーラビリティを向上させます。

- 🌐 **カスタマイズ可能なOpenAI接続**: 接頭辞ID対応やAPI用の明示的なモデルID対応を含むカスタムOpenAI設定で、スムーズな操作を実現します。

- 🔐 **Ollama APIキー管理**: 接頭辞ID対応を含むOllamaの資格情報を管理し、安全で効率的な操作を実現します。

- 🔄 **接続管理**: 必要に応じてOpenAIおよびOllama接続を個別に有効または無効にできます。

- 🎨 **直感的なモデルワークスペース**: 再設計された使いやすいインターフェースで、ユーザーやグループ間でモデルを管理します。

- 🔑 **APIキー認証**: APIキー認証を簡単に有効または無効にして、セキュリティを強化します。

- 🔄 **統一モデルのリセット**: 管理設定からすべてのモデルをワンクリック操作でリセットおよび削除します。

- 🔓 **柔軟なモデルアクセス制御**: 信頼できる環境でワークフローを簡単にするため、BYPASS_MODEL_ACCESS_CONTROL環境変数を使用して、ユーザーロールのモデルアクセス制御を簡単に解除します。

- 🔒 **設定できるAPIキー認証制限**: 信頼できる環境でのスムーズな設定のため、デフォルトでオフになっているAPIキー認証のエンドポイント制限を柔軟に構成します。

---
