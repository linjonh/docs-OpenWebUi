---
sidebar_position: 2  
title: "âš™ï¸ Werkzeuge"  
---

# âš™ï¸ Was sind Werkzeuge?

Werkzeuge sind kleine Python-Skripte, die Ihrer LLM zusÃ¤tzliche FÃ¤higkeiten verleihen. Wenn sie aktiviert sind, ermÃ¶glichen sie Ihrem Chatbot erstaunliche Dinge â€” wie das Durchsuchen des Internets, das Extrahieren von Daten, das Erstellen von Bildern, das Antworten mit KI-Stimmen und mehr.

Betrachten Sie Werkzeuge als nÃ¼tzliche Plugins, die Ihre KI beim Chatten mit Ihnen verwenden kann.

---

## ğŸš€ Was kÃ¶nnen Werkzeuge fÃ¼r mich tun?

Hier sind nur einige Beispiele dafÃ¼r, was Werkzeuge Ihrer KI-Assistenz ermÃ¶glichen:

- ğŸŒ Websuche: Erhalten Sie Echtzeit-Antworten durch das Durchsuchen des Internets.
- ğŸ–¼ï¸ Bilderstellung: Erstellen Sie Bilder aus Ihren Eingaben.
- ğŸ”Š Sprachausgabe: Erzeugen Sie KI-Stimmen mit ElevenLabs.

Entdecken Sie hier einsatzbereite Werkzeuge:  
ğŸ§° [Werkzeuge-Schaufenster](https://openwebui.com/tools)

---


## ğŸ“¦ Wie installiert man Werkzeuge

Es gibt zwei einfache MÃ¶glichkeiten, Werkzeuge in Open WebUI zu installieren:

1. Besuchen Sie die [Community-Werkzeugbibliothek](https://openwebui.com/tools)
2. WÃ¤hlen Sie ein Werkzeug aus und klicken Sie auf die SchaltflÃ¤che "Get".
3. Geben Sie die IP-Adresse oder URL Ihrer Open WebUI-Instanz ein.
4. Klicken Sie auf â€Importieren in WebUIâ€œ â€” fertig!

ğŸ›‘ Sicherheitstipp: Importieren Sie niemals ein Werkzeug, das Sie nicht kennen oder dem Sie nicht vertrauen. Diese sind Python-Skripte und kÃ¶nnten unsicheren Code ausfÃ¼hren.

---


## ğŸ”§ Wie benutzt man Werkzeuge in Open WebUI

Sobald Sie Werkzeuge installiert haben (wir zeigen Ihnen unten, wie), kÃ¶nnen Sie sie aktivieren und nutzen:

Es gibt zwei MÃ¶glichkeiten, ein Werkzeug fÃ¼r Ihr Modell zu aktivieren:

### â• Option 1: Aktivieren Ã¼ber das Chat-Fenster

Klicken Sie wÃ¤hrend des Chatens auf das â•-Symbol im Eingabebereich. Sie sehen eine Liste der verfÃ¼gbaren Werkzeuge â€” Sie kÃ¶nnen jedes fÃ¼r die aktuelle Sitzung aktivieren.

ğŸ’¡ Tipp: Das Aktivieren eines Werkzeugs gibt dem Modell die Erlaubnis, es zu verwenden â€” aber es kÃ¶nnte es nur nutzen, wenn es fÃ¼r die Aufgabe nÃ¼tzlich ist.

### âœï¸ Option 2: StandardmÃ¤ÃŸig aktivieren (Empfohlen fÃ¼r hÃ¤ufige Nutzung)
1. Gehen Sie zu: Arbeitsbereich â¡ï¸ Modelle
2. WÃ¤hlen Sie das Modell aus, das Sie verwenden (wie GPT-4 oder LLaMa2), und klicken Sie auf das âœï¸ Bearbeitungssymbol.
3. Scrollen Sie nach unten zum Abschnitt â€Werkzeugeâ€œ.
4. âœ… Markieren Sie die Werkzeuge, zu denen Ihr Modell standardmÃ¤ÃŸig Zugriff haben soll.
5. Klicken Sie auf Speichern.

Dies stellt sicher, dass das Modell stets diese Werkzeuge bereit hat, wenn Sie mit ihm chatten.

Sie kÃ¶nnen Ihrem LLM auch erlauben, die richtigen Werkzeuge automatisch auszuwÃ¤hlen, indem Sie den AutoTool-Filter verwenden:

ğŸ”— [AutoTool Filter](https://openwebui.com/f/hub/autotool_filter/)

ğŸ¯ Hinweis: Auch beim Einsatz des AutoTool-Filters mÃ¼ssen Sie Ihre Werkzeuge mithilfe von Option 2 aktivieren.

âœ… Und das war's â€” Ihr LLM ist jetzt werkzeuggestÃ¼tzt! Sie sind bereit, Ihre Chats mit Websuche, Bilderstellung, Sprachausgabe und mehr zu verbessern.

---

## ğŸ§  Wie Werkzeuge verwendet werden: Standard vs. Native

Sobald Werkzeuge fÃ¼r Ihr Modell aktiviert sind, bietet Open WebUI Ihnen zwei verschiedene MÃ¶glichkeiten, Ihrem LLM die Nutzung von Werkzeugen in GesprÃ¤chen zu erlauben.

Sie kÃ¶nnen entscheiden, wie das Modell Werkzeuge aufruft, indem Sie zwischen folgenden Optionen wÃ¤hlen:

- ğŸŸ¡ Standardmodus (Prompt-basiert)
- ğŸŸ¢ Nativer Modus (Eingebaute Funktionsaufrufe)

Lassen Sie uns dies aufschlÃ¼sseln:

### ğŸŸ¡ Standardmodus (Prompt-basierte WerkzeugauslÃ¶sung)

Dies ist die Standardeinstellung in Open WebUI.

Hierbei benÃ¶tigt Ihr LLM keine native UnterstÃ¼tzung von Funktionsaufrufen. Stattdessen fÃ¼hren wir das Modell mithilfe einer intelligenten Werkzeugauswahl-Promptvorlage, um ein Werkzeug auszuwÃ¤hlen und zu verwenden.

âœ… Funktioniert mit fast jedem Modell  
âœ… GroÃŸartige MÃ¶glichkeit, Werkzeuge mit grundlegenden oder lokalen Modellen zu nutzen  
â— Nicht so zuverlÃ¤ssig oder flexibel wie der Native Modus beim Verkettung von Werkzeugen

### ğŸŸ¢ Nativer Modus (Eingebaute Funktionsaufrufe)

Wenn Ihr Modell â€nativesâ€œ Funktionsaufrufen unterstÃ¼tzt (wie GPT-4o oder GPT-3.5-turbo-1106), kÃ¶nnen Sie diesen leistungsstarken Modus verwenden, damit das LLM in Echtzeit entscheidet, wann und wie mehrere Werkzeuge wÃ¤hrend einer einzigen Chat-Nachricht aufgerufen werden sollen.

âœ… Schnell, prÃ¤zise und kann mehrere Werkzeuge in einer Antwort verketten  
âœ… Das natÃ¼rlichste und fortschrittlichste Erlebnis  
â— Erfordert ein Modell, das tatsÃ¤chlich native Funktionsaufrufe unterstÃ¼tzt

### âœ³ï¸ Wie zwischen den Modi wechseln

MÃ¶chten Sie native Funktionsaufrufe in Ihren Chats aktivieren? So funktioniert es:

![Chat-Steuerung](/images/features/plugin/tools/chat-controls.png)

1. Ã–ffnen Sie das Chat-Fenster mit Ihrem Modell.
2. Klicken Sie auf âš™ï¸â€¯Chat-Steuerungen > Erweiterte Parameter.
3. Suchen Sie die Funktionseinstellungsoption â€šFunktionsaufrufeâ€˜ und Ã¤ndern Sie sie von Standard â†’ Native.

Das war's! Ihr Chat verwendet nun echte native WerkzeugunterstÃ¼tzung (sofern das Modell dies unterstÃ¼tzt).

â¡ï¸ Wir empfehlen die Nutzung von GPT-4o oder einem anderen OpenAI-Modell fÃ¼r die beste Erfahrung mit nativen Funktionsaufrufen.  
ğŸ” Einige lokale Modelle kÃ¶nnten UnterstÃ¼tzung beanspruchen, haben jedoch oft Schwierigkeiten mit genauer oder komplizierter Werkzeugnutzung.

ğŸ’¡ Zusammenfassung:

| Modus     | Zielgruppe                       | Vorteile                                | Nachteile                             |
|----------|----------------------------------|-----------------------------------------|--------------------------------------|
| Standard  | Jedes Modell                     | Breite KompatibilitÃ¤t, sicherer, flexibel| KÃ¶nnte weniger genau oder langsamer sein|
| Native    | GPT-4o, etc.                     | Schnell, intelligent, hervorragende Werkzeugverkettung | BenÃ¶tigt echte UnterstÃ¼tzung fÃ¼r Funktionsaufrufe |

WÃ¤hlen Sie den Modus, der fÃ¼r Ihre Umgebung am besten geeignet ist â€“ und denken Sie daran, dass Sie jederzeit Ã¼ber die Chat-Steuerungen wechseln kÃ¶nnen.

ğŸ‘ Und das war's â€” Ihr LLM weiÃŸ nun, wie und wann es Tools intelligent nutzen kann.

---

## ğŸ§  Zusammenfassung

Tools sind Erweiterungen, die Ihrem KI-Modell viel mehr als nur Chatten ermÃ¶glichen. Von der Beantwortung von Echtzeitfragen bis hin zur Generierung von Bildern oder dem Vorlesen â€” Tools erwecken Ihre KI zum Leben.

- Besuchen Sie: [https://openwebui.com/tools](https://openwebui.com/tools), um neue Tools zu entdecken.
- Installieren Sie sie manuell oder mit einem Klick.
- Aktivieren Sie sie pro Modell aus dem Arbeitsbereich â¡ï¸ Modelle.
- Nutzen Sie sie im Chat durch einen Klick auf â•

Jetzt machen Sie Ihre KI vieeeel schlauer ğŸ¤–âœ¨
