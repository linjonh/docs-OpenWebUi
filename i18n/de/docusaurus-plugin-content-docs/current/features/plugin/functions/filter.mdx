---
sidebar_position: 2
title: "ğŸª„ Filter Funktion"
---

# ğŸª„ Filter Funktion: Eingaben und Ausgaben anpassen

Willkommen zu der umfassenden Anleitung zu Filterfunktionen in Open WebUI! Filter sind ein flexibles und leistungsstarkes **Plugin-System**, das Daten *vor dem Versand an das Large Language Model (LLM)* (Eingabe) oder *nach der RÃ¼ckkehr vom LLM* (Ausgabe) modifiziert. Egal, ob Sie Eingaben fÃ¼r mehr Kontext transformieren oder Ausgaben fÃ¼r bessere Lesbarkeit bereinigen mÃ¶chten â€“ **Filterfunktionen** ermÃ¶glichen Ihnen alles.

Diese Anleitung wird Ihnen erklÃ¤ren, **was Filter sind**, wie sie funktionieren, wie sie strukturiert sind und alles, was Sie wissen mÃ¼ssen, um leistungsstarke und benutzerfreundliche Filter selbst zu erstellen. Lassen Sie uns loslegen â€“ keine Sorge, ich werde Metaphern, Beispiele und Tipps verwenden, um alles kristallklar zu machen! ğŸŒŸ

---

## ğŸŒŠ Was sind Filter in Open WebUI?

Stellen Sie sich Open WebUI als einen **Wasserstrom** vor, der durch Rohre flieÃŸt:

- **Benutzereingaben** und **LLM-Ausgaben** sind das Wasser.
- **Filter** sind die **Wasserbehandlungsstufen**, die das Wasser reinigen, modifizieren und anpassen, bevor es sein endgÃ¼ltiges Ziel erreicht.

Filter sitzen in der Mitte des Flusses â€“ wie Kontrollpunkte â€“, wo Sie entscheiden, was angepasst werden muss.

Hier ist eine kurze Zusammenfassung dessen, was Filter tun:

1. **Benutzereingaben Ã¤ndern (Inlet-Funktion)**: Vorbereiten der Eingabedaten, bevor sie das KI-Modell erreichen. Hier kÃ¶nnen Sie Klarheit erhÃ¶hen, Kontext hinzufÃ¼gen, Text bereinigen oder Nachrichten neu formatieren, um spezifische Anforderungen zu erfÃ¼llen.
2. **Modell-Ausgaben abfangen (Stream-Funktion)**: Erfassen und Anpassen der KI-Antworten **wÃ¤hrend sie vom Modell generiert werden**. Dies ist nÃ¼tzlich fÃ¼r EchtzeitÃ¤nderungen, wie das Filtern sensibler Informationen oder das Formatieren der Ausgabe fÃ¼r bessere Lesbarkeit.
3. **Modell-Ausgaben Ã¤ndern (Outlet-Funktion)**: Anpassen der KI-Antwort **nach der Verarbeitung**, bevor sie dem Benutzer angezeigt wird. Dies hilft, Daten zu verfeinern, zu protokollieren oder fÃ¼r eine sauberere Benutzererfahrung anzupassen.

> **Wichtiges Konzept:** Filter sind keine eigenstÃ¤ndigen Modelle, sondern Werkzeuge, die die Daten zwischen *zu* und *von* den Modellen verbessern oder transformieren.

Filter sind wie **Ãœbersetzer oder Redakteure** im KI-Workflow: Sie kÃ¶nnen die Konversation abfangen und Ã¤ndern, ohne den Fluss zu unterbrechen.

---

## ğŸ—ºï¸ Struktur einer Filterfunktion: Das GrundgerÃ¼st

Beginnen wir mit der einfachsten Darstellung einer Filterfunktion. Machen Sie sich keine Sorgen, wenn einige Teile zunÃ¤chst technisch erscheinen â€“ wir werden alles Schritt fÃ¼r Schritt aufschlÃ¼sseln!

### ğŸ¦´ BasisgerÃ¼st eines Filters

```python
from pydantic import BaseModel
from typing import Optional

class Filter:
    # Ventile: Konfigurationsoptionen fÃ¼r den Filter
    class Valves(BaseModel):
        pass

    def __init__(self):
        # Ventile initialisieren (optionale Konfiguration fÃ¼r den Filter)
        self.valves = self.Valves()

    def inlet(self, body: dict) -> dict:
        # Hier manipulieren Sie Benutzereingaben.
        print(f"inlet called: {body}")
        return body

    def stream(self, event: dict) -> dict:
        # Hier modifizieren Sie gestreamte Teile der Modellausgabe.
        print(f"stream event: {event}")
        return event

    def outlet(self, body: dict) -> None:
        # Hier manipulieren Sie Modellausgaben.
        print(f"outlet called: {body}")
```

---

### ğŸ†• ğŸ§² Beispiel fÃ¼r einen Umschaltfilter: InteraktivitÃ¤t und Symbole hinzufÃ¼gen (Neu in Open WebUI 0.6.10)

Filter kÃ¶nnen mehr als nur Text modifizieren â€“ sie kÃ¶nnen UI-Schalter einfÃ¼gen und benutzerdefinierte Symbole anzeigen. Zum Beispiel mÃ¶chten Sie vielleicht einen Filter, der mit einem Schaltknopf in der BenutzeroberflÃ¤che ein-/ausgeschaltet werden kann und ein spezielles Symbol im Nachrichten-Eingabe-UI von Open WebUI anzeigt.

Hier ist ein Beispiel, wie Sie einen solchen Umschaltfilter erstellen kÃ¶nnten:

```python
from pydantic import BaseModel, Field
from typing import Optional

class Filter:
    class Valves(BaseModel):
        pass

    def __init__(self):
        self.valves = self.Valves()
        self.toggle = True # WICHTIG: Dies erstellt eine Schalter-UI in Open WebUI
        # TIPP: Verwenden Sie SVG-Daten-URI!
        self.icon = """data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyNCAyNCIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZT0iY3VycmVudENvbG9yIiBjbGFzcz0ic2l6ZS02Ij4KICA8cGF0aCBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGQ9Ik0xMiAxOHYtNS4yNW0wIDBhNi4wMSA2LjAxIDAgMCAwIDEuNS0uMTg5bS0xLjUuMTg5YTYuMDEgNi4wMSAwIDAgMS0xLjUtLjE4OW0zLjc1IDcuNDc4YTEyLjA2IDEyLjA2IDAgMCAxLTQuNSAwbTMuNzUgMi4zODNhMTQuNDA2IDE0LjQwNiAwIDAgMS0zIDBNMTQuMjUgMTh2LS4xOTJjMC0uOTgzLjY1OC0xLjgyMyAxLjUwOC0yLjMxNmE3LjUgNy41IDAgMSAwLTcuNTE3IDBjLjg1LjQ5MyAxLjUwOSAxLjMzMyAxLjUwOSAyLjMxNlYxOCIgLz4KPC9zdmc+Cg=="""
        pass

    async def inlet(
        self, body: dict, __event_emitter__, __user__: Optional[dict] = None
    ) -> dict:
        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": "Umschaltet!",
                    "done": True
                    "hidden": False,
                },
            }
        )
        return body
```

#### ğŸ–¼ï¸ Was passiert gerade?
- **toggle = True** erstellt eine Schalter-UI in Open WebUI â€“ Benutzer kÃ¶nnen den Filter manuell in Echtzeit aktivieren oder deaktivieren.
- **icon** (mit einer Data URI) wird als kleines Bild neben dem Namen des Filters angezeigt. Sie kÃ¶nnen jedes SVG verwenden, solange es als Data URI codiert ist!
- **Die `inlet`-Funktion** verwendet das spezielle Argument `__event_emitter__`, um Feedback/Status an die UI zu senden, wie z.B. einen kleinen Toast/Benachrichtigung, der "Umschalten!" anzeigt.

![Toggle Filter](/images/features/plugin/functions/toggle-filter.png)

Sie kÃ¶nnen diese Mechanismen nutzen, um Ihre Filter dynamisch, interaktiv und visuell einzigartig im Plugin-Ã–kosystem von Open WebUI zu gestalten.

---

### ğŸ¯ Wichtige Komponenten erklÃ¤rt

#### 1ï¸âƒ£ **`Valves`-Klasse (Optionale Einstellungen)**

Stellen Sie sich **Valves** als die Regler und Schieberegler fÃ¼r Ihren Filter vor. Wenn Sie den Benutzern konfigurierbare Optionen zur Anpassung des Verhaltens Ihres Filters geben mÃ¶chten, definieren Sie diese hier.

```python
class Valves(BaseModel):
    OPTION_NAME: str = "Standardwert"
```

Zum Beispiel:  
Wenn Sie einen Filter erstellen, der Antworten in GroÃŸbuchstaben umwandelt, kÃ¶nnten Sie den Benutzern erlauben, zu konfigurieren, ob jede Ausgabe vollstÃ¤ndig kapitalisiert wird, z.B. Ã¼ber ein Ventil wie `TRANSFORM_UPPERCASE: bool = True/False`.

---

#### 2ï¸âƒ£ **`inlet`-Funktion (Eingabevorverarbeitung)**


Die `inlet`-Funktion ist wie **das Vorbereiten von Essen vor dem Kochen**. Stellen Sie sich vor, Sie sind ein Koch: Bevor die Zutaten in das Rezept (hier das LLM) kommen, kÃ¶nnten Sie GemÃ¼se waschen, Zwiebeln schneiden oder das Fleisch wÃ¼rzen. Ohne diesen Schritt kÃ¶nnte Ihr fertiges Gericht geschmacklos sein, ungewaschenes GemÃ¼se enthalten oder einfach inkonsistent sein.

In der Welt von Open WebUI erledigt die `inlet`-Funktion diese wichtige Vorbereitungsarbeit mit der **Benutzereingabe**, bevor sie an das Modell gesendet wird. Sie stellt sicher, dass die Eingabe so sauber, kontextbezogen und hilfreich wie mÃ¶glich ist, damit die KI damit umgehen kann.

ğŸ“¥ **Eingabe**:  
- **`body`**: Die Rohdaten aus Open WebUI an das Modell. Sie haben das Format einer Chat-Abschluss-Anfrage (normalerweise ein WÃ¶rterbuch, das Felder wie die Nachrichten des GesprÃ¤chs, Modelleinstellungen und andere Metadaten enthÃ¤lt). Betrachten Sie dies als Ihre Rezeptzutaten.

ğŸš€ **Ihre Aufgabe**:  
Modifizieren und zurÃ¼ckgeben des `body`. Die modifizierte Version des `body` ist das, mit dem das LLM arbeitet, also ist dies Ihre Gelegenheit, der Eingabe Klarheit, Struktur und Kontext zu verleihen.


##### ğŸ³ Warum sollten Sie die `inlet` verwenden?
1. **Kontext hinzufÃ¼gen**: Automatisch wichtige Informationen zur Benutzereingabe hinzufÃ¼gen, insbesondere wenn ihr Text vage oder unvollstÃ¤ndig ist. Zum Beispiel kÃ¶nnten Sie hinzufÃ¼gen "Du bist ein freundlicher Assistent" oder "Hilf diesem Benutzer bei der Fehlerbehebung eines Softwarefehlers."
   
2. **Daten formatieren**: Wenn die Eingabe ein bestimmtes Format wie JSON oder Markdown erfordert, kÃ¶nnen Sie dies vor dem Senden an das Modell umwandeln.

3. **Eingabe bereinigen**: UnerwÃ¼nschte Zeichen entfernen, mÃ¶glicherweise schÃ¤dliche oder verwirrende Symbole (wie Ã¼bermÃ¤ÃŸige Leerzeichen oder Emojis) entfernen oder sensible Informationen ersetzen.

4. **Benutzereingabe vereinfachen**: Wenn sich die Ausgabe Ihres Modells durch zusÃ¤tzliche Anleitung verbessert, kÃ¶nnen Sie die `inlet` nutzen, um klÃ¤rende Anweisungen automatisch einzufÃ¼gen!


##### ğŸ’¡ Beispielanwendungen: Weiterentwicklung der Essenszubereitung
###### ğŸ¥— Beispiel 1: Systemkontext hinzufÃ¼gen
Angenommen, das LLM ist ein Koch, der ein Gericht fÃ¼r die italienische KÃ¼che vorbereitet, aber der Benutzer hat nicht erwÃ¤hnt "Dies ist fÃ¼r die italienische KÃ¼che." Sie kÃ¶nnen sicherstellen, dass die Nachricht klar ist, indem Sie diesen Kontext vor dem Senden der Daten an das Modell hinzufÃ¼gen.

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # Systemnachricht fÃ¼r italienischen Kontext in die Unterhaltung hinzufÃ¼gen
    context_message = {
        "role": "system",
        "content": "Du hilfst dem Benutzer, ein italienisches Essen vorzubereiten."
    }
    # EinfÃ¼gen des Kontexts am Anfang der Chat-Historie
    body.setdefault("messages", []).insert(0, context_message)
    return body
```

ğŸ“– **Was passiert?**
- Jede Benutzereingabe wie "Was sind gute Ideen fÃ¼rs Abendessen?" trÃ¤gt nun das italienische Thema, da wir den Systemkontext gesetzt haben! KÃ¤sekuchen wird mÃ¶glicherweise nicht als Antwort erscheinen, aber Pasta sicherlich.


###### ğŸ”ª Beispiel 2: Eingabe bereinigen (MerkwÃ¼rdige Zeichen entfernen)
Angenommen, die Eingabe des Benutzers sieht chaotisch aus oder enthÃ¤lt unerwÃ¼nschte Symbole wie `!!!`, was die Unterhaltung ineffizient oder fÃ¼r das Modell schwieriger zu parsen macht. Sie kÃ¶nnen sie bereinigen, wÃ¤hrend Sie den Kerninhalt beibehalten.

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # Bereinigen der letzten Benutzereingabe (vom Ende der messages-Liste)
    last_message = body["messages"][-1]["content"]
    body["messages"][-1]["content"] = last_message.replace("!!!", "").strip()
    return body
```

ğŸ“– **Was passiert?**
- Vorher: `"Wie kann ich dieses Problem debuggen!!!"` â¡ï¸ An das Modell gesendet als `"Wie kann ich dieses Problem debuggen"`

Hinweis: Der Benutzer fÃ¼hlt das Gleiche, aber das Modell verarbeitet eine sauberere und leichter verstÃ¤ndliche Anfrage.


##### ğŸ“Š Wie `inlet` hilft, die Eingabe fÃ¼r das LLM zu optimieren:
- Verbessert die **Genauigkeit**, indem es mehrdeutige Anfragen klÃ¤rt.
- Macht die KI **effizienter**, indem unnÃ¶tige Elemente wie Emojis, HTML-Tags oder Ã¼berflÃ¼ssige Satzzeichen entfernt werden.
- GewÃ¤hrleistet **Konsistenz**, indem Benutzereingaben so formatiert werden, dass sie den erwarteten Mustern oder Schemas des Modells entsprechen (z. B. JSON fÃ¼r einen bestimmten Anwendungsfall).


ğŸ’­ **Betrachten Sie `inlet` als den Sous-Chef in Ihrer KÃ¼che** â€“ es sorgt dafÃ¼r, dass alles, was ins Modell (Ihr AI-"Rezept") eingeht, perfekt vorbereitet, gereinigt und gewÃ¼rzt ist. Je besser die Eingabe, desto besser das Ergebnis!

---

#### ğŸ†• 3ï¸âƒ£ **`stream` Hook (Neu in Open WebUI 0.5.17)**

##### ğŸ”„ Was ist der `stream` Hook?
Die **`stream`-Funktion** ist eine neue Funktion, die in Open WebUI **0.5.17** eingefÃ¼hrt wurde und es ermÃ¶glicht, **gestreamte Modellantworten in Echtzeit abzufangen und zu Ã¤ndern**.

Im Gegensatz zu `outlet`, das eine vollstÃ¤ndige abgeschlossene Antwort verarbeitet, arbeitet `stream` mit **einzelnen Chunks**, wÃ¤hrend sie vom Modell empfangen werden.

##### ğŸ› ï¸ Wann sollte der Stream-Hook verwendet werden?
- **Stream-Antworten** Ã¤ndern, bevor sie den Benutzern angezeigt werden.
- **Echtzeit-Zensur oder Bereinigung** implementieren.
- **Gestreamte Daten Ã¼berwachen** fÃ¼r Logging/Debugging.

##### ğŸ“œ Beispiel: Streaming-Chunks protokollieren

So kÃ¶nnen Sie gestreamte LLM-Antworten inspizieren und bearbeiten:
```python
def stream(self, event: dict) -> dict:
    print(event)  # Jeden eingehenden Chunk zur Inspektion ausgeben
    return event
```

> **Beispiel fÃ¼r gestreamte Ereignisse:**
```jsonl
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "Hi"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "!"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": " ğŸ˜Š"}}]}
```
ğŸ“– **Was passiert?**
- Jede Zeile reprÃ¤sentiert ein **kleines Fragment** der gestreamten Antwort des Modells.
- Das Feld **`delta.content`** enthÃ¤lt den fortlaufend generierten Text.

##### ğŸ”„ Beispiel: Emojis aus gestreamten Daten entfernen
```python
def stream(self, event: dict) -> dict:
    for choice in event.get("choices", []):
        delta = choice.get("delta", {})
        if "content" in delta:
            delta["content"] = delta["content"].replace("ğŸ˜Š", "")  # Emojis entfernen
    return event
```
ğŸ“– **Vorher:** `"Hi ğŸ˜Š"`  
ğŸ“– **Nachher:** `"Hi"`

---

#### 4ï¸âƒ£ **`outlet`-Funktion (Post-Processing der Ausgabe)**

Die `outlet`-Funktion ist wie ein **Korrekturleser**: Sie rÃ¤umt die Antwort der KI auf (oder nimmt abschlieÃŸende Ã„nderungen vor), *nachdem sie vom LLM verarbeitet wurde.*  

ğŸ“¤ **Eingabe**:
- **`body`**: EnthÃ¤lt **alle aktuellen Nachrichten** im Chat (Benutzerhistorie + LLM-Antworten).

ğŸš€ **Ihre Aufgabe**: Passen Sie diesen `body` an. Sie kÃ¶nnen ihn bereinigen, ergÃ¤nzen oder Ã„nderungen protokollieren, sollten jedoch berÃ¼cksichtigen, wie jede Anpassung die Benutzererfahrung beeinflusst.

ğŸ’¡ **Best Practices**:
- Bevorzugen Sie Protokollierung gegenÃ¼ber direkten Ã„nderungen im Outlet (z. B. fÃ¼r Debugging oder Analysen).
- Wenn umfangreiche Ã„nderungen erforderlich sind (z. B. zur Formatierung von Ausgaben), sollten Sie stattdessen die **Pipe-Funktion** verwenden.

ğŸ’¡ **Beispielanwendung**: Entfernen Sie vertrauliche API-Antworten, die der Benutzer nicht sehen soll:
```python
def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    for message in body["messages"]:
        message["content"] = message["content"].replace("<API_KEY>", "[REDACTED]")
    return body 
```

---

## ğŸŒŸ Filter in Aktion: Praktische Beispiele erstellen

Erstellen wir einige Beispiele aus der realen Welt, um zu sehen, wie Sie Filter verwenden wÃ¼rden!

### ğŸ“š Beispiel #1: Kontext zu jeder Benutzereingabe hinzufÃ¼gen

MÃ¶chten Sie, dass das LLM immer weiÃŸ, dass es einem Kunden bei der Fehlerbehebung von Softwareproblemen hilft? Sie kÃ¶nnen Anweisungen wie **"Sie sind ein Software-Fehlerbehebungsassistent"** zu jeder Benutzeranfrage hinzufÃ¼gen.

```python
class Filter:
    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        context_message = {
            "role": "system", 
            "content": "Sie sind ein Software-Fehlerbehebungsassistent."
        }
        body.setdefault("messages", []).insert(0, context_message)
        return body
```

---

### ğŸ“š Beispiel #2: Ausgaben zur leichteren Lesbarkeit hervorheben

RÃ¼ckgabe einer Ausgabe im Markdown- oder einem anderen formatierten Stil? Verwenden Sie die `outlet`-Funktion!

```python
class Filter:
    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # "Hervorheben"-Markdown zu jeder Antwort hinzufÃ¼gen
        for message in body["messages"]:
            if message["role"] == "assistant":  # Antwort des Modells anvisieren
                message["content"] = f"**{message[content]}**"  # Mit Markdown hervorheben
        return body
```

---

## ğŸš§ MÃ¶gliche Verwirrung: Klarstellungen im FAQ ğŸ›‘ 

### **F: Wie unterscheiden sich Filter von Pipe-Funktionen?**

Filter Ã¤ndern Daten, die **ins Modell gehen** und **vom Modell zurÃ¼ckkommen**, interagieren aber nicht signifikant mit Logik auÃŸerhalb dieser Phasen. Pipes hingegen:
- KÃ¶nnen **externe APIs** integrieren oder die Backend-Operationen grundlegend verÃ¤ndern.
- Bieten benutzerdefinierte Logik als komplett neue "Modelle" an.

### **F: Kann ich umfangreiche Nachbearbeitung innerhalb von `outlet` durchfÃ¼hren?**

Sie kÃ¶nnen, aber **es ist nicht die beste Praxis.**:
- **Filter** sind dafÃ¼r gedacht, leichte Ã„nderungen vorzunehmen oder Protokollierung anzuwenden.
- Wenn umfangreiche Modifikationen erforderlich sind, ziehen Sie stattdessen eine **Pipe-Funktion** in Betracht.

---

## ğŸ‰ Zusammenfassung: Warum Filterfunktionen erstellen?

Bis jetzt haben Sie gelernt:
1. **Inlet** manipuliert **Benutzereingaben** (Vorverarbeitung).
2. **Stream** fÃ¤ngt **gestreamte Modellausgaben** ab und modifiziert diese (in Echtzeit).
3. **Outlet** verÃ¤ndert **KI-Ausgaben** (Nachbearbeitung).
4. Filter eignen sich am besten fÃ¼r leichte, Echtzeit-Anpassungen des Datenflusses.
5. Mit **Valves** kÃ¶nnen Sie Benutzern die MÃ¶glichkeit geben, Filter dynamisch fÃ¼r maÃŸgeschneidertes Verhalten zu konfigurieren.

---

ğŸš€ **Ihre Aufgabe**: Experimentieren Sie! Welche kleine Anpassung oder KontextergÃ¤nzung kÃ¶nnte Ihr Open WebUI-Erlebnis verbessern? Filter machen SpaÃŸ beim Erstellen, sind flexibel in der Anwendung und kÃ¶nnen Ihre Modelle auf die nÃ¤chste Stufe bringen!

Viel SpaÃŸ beim Programmieren! âœ¨
