---
sidebar_position: 2
title: "ü™Ñ Filter Funktion"
---

# ü™Ñ Filter Funktion: Eingaben und Ausgaben anpassen

Willkommen zu der umfassenden Anleitung zu Filterfunktionen in Open WebUI! Filter sind ein flexibles und leistungsstarkes **Plugin-System**, das Daten *vor dem Versand an das Large Language Model (LLM)* (Eingabe) oder *nach der R√ºckkehr vom LLM* (Ausgabe) modifiziert. Egal, ob Sie Eingaben f√ºr mehr Kontext transformieren oder Ausgaben f√ºr bessere Lesbarkeit bereinigen m√∂chten ‚Äì **Filterfunktionen** erm√∂glichen Ihnen alles.

Diese Anleitung wird Ihnen erkl√§ren, **was Filter sind**, wie sie funktionieren, wie sie strukturiert sind und alles, was Sie wissen m√ºssen, um leistungsstarke und benutzerfreundliche Filter selbst zu erstellen. Lassen Sie uns loslegen ‚Äì keine Sorge, ich werde Metaphern, Beispiele und Tipps verwenden, um alles kristallklar zu machen! üåü

---

## üåä Was sind Filter in Open WebUI?

Stellen Sie sich Open WebUI als einen **Wasserstrom** vor, der durch Rohre flie√üt:

- **Benutzereingaben** und **LLM-Ausgaben** sind das Wasser.
- **Filter** sind die **Wasserbehandlungsstufen**, die das Wasser reinigen, modifizieren und anpassen, bevor es sein endg√ºltiges Ziel erreicht.

Filter sitzen in der Mitte des Flusses ‚Äì wie Kontrollpunkte ‚Äì, wo Sie entscheiden, was angepasst werden muss.

Hier ist eine kurze Zusammenfassung dessen, was Filter tun:

1. **Benutzereingaben √§ndern (Inlet-Funktion)**: Vorbereiten der Eingabedaten, bevor sie das KI-Modell erreichen. Hier k√∂nnen Sie Klarheit erh√∂hen, Kontext hinzuf√ºgen, Text bereinigen oder Nachrichten neu formatieren, um spezifische Anforderungen zu erf√ºllen.
2. **Modell-Ausgaben abfangen (Stream-Funktion)**: Erfassen und Anpassen der KI-Antworten **w√§hrend sie vom Modell generiert werden**. Dies ist n√ºtzlich f√ºr Echtzeit√§nderungen, wie das Filtern sensibler Informationen oder das Formatieren der Ausgabe f√ºr bessere Lesbarkeit.
3. **Modell-Ausgaben √§ndern (Outlet-Funktion)**: Anpassen der KI-Antwort **nach der Verarbeitung**, bevor sie dem Benutzer angezeigt wird. Dies hilft, Daten zu verfeinern, zu protokollieren oder f√ºr eine sauberere Benutzererfahrung anzupassen.

> **Wichtiges Konzept:** Filter sind keine eigenst√§ndigen Modelle, sondern Werkzeuge, die die Daten zwischen *zu* und *von* den Modellen verbessern oder transformieren.

Filter sind wie **√úbersetzer oder Redakteure** im KI-Workflow: Sie k√∂nnen die Konversation abfangen und √§ndern, ohne den Fluss zu unterbrechen.

---

## üó∫Ô∏è Struktur einer Filterfunktion: Das Grundger√ºst

Beginnen wir mit der einfachsten Darstellung einer Filterfunktion. Machen Sie sich keine Sorgen, wenn einige Teile zun√§chst technisch erscheinen ‚Äì wir werden alles Schritt f√ºr Schritt aufschl√ºsseln!

### ü¶¥ Basisger√ºst eines Filters

```python
from pydantic import BaseModel
from typing import Optional

class Filter:
    # Ventile: Konfigurationsoptionen f√ºr den Filter
    class Valves(BaseModel):
        pass

    def __init__(self):
        # Ventile initialisieren (optionale Konfiguration f√ºr den Filter)
        self.valves = self.Valves()

    def inlet(self, body: dict) -> dict:
        # Hier manipulieren Sie Benutzereingaben.
        print(f"inlet called: {body}")
        return body

    def stream(self, event: dict) -> dict:
        # Hier modifizieren Sie gestreamte Teile der Modellausgabe.
        print(f"stream event: {event}")
        return event

    def outlet(self, body: dict) -> None:
        # Hier manipulieren Sie Modellausgaben.
        print(f"outlet called: {body}")
```

---

### üÜï üß≤ Beispiel f√ºr einen Umschaltfilter: Interaktivit√§t und Symbole hinzuf√ºgen (Neu in Open WebUI 0.6.10)

Filter k√∂nnen mehr als nur Text modifizieren ‚Äì sie k√∂nnen UI-Schalter einf√ºgen und benutzerdefinierte Symbole anzeigen. Zum Beispiel m√∂chten Sie vielleicht einen Filter, der mit einem Schaltknopf in der Benutzeroberfl√§che ein-/ausgeschaltet werden kann und ein spezielles Symbol im Nachrichten-Eingabe-UI von Open WebUI anzeigt.

Hier ist ein Beispiel, wie Sie einen solchen Umschaltfilter erstellen k√∂nnten:

```python
from pydantic import BaseModel, Field
from typing import Optional

class Filter:
    class Valves(BaseModel):
        pass

    def __init__(self):
        self.valves = self.Valves()
        self.toggle = True # WICHTIG: Dies erstellt eine Schalter-UI in Open WebUI
        # TIPP: Verwenden Sie SVG-Daten-URI!
        self.icon = """data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyNCAyNCIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZT0iY3VycmVudENvbG9yIiBjbGFzcz0ic2l6ZS02Ij4KICA8cGF0aCBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGQ9Ik0xMiAxOHYtNS4yNW0wIDBhNi4wMSA2LjAxIDAgMCAwIDEuNS0uMTg5bS0xLjUuMTg5YTYuMDEgNi4wMSAwIDAgMS0xLjUtLjE4OW0zLjc1IDcuNDc4YTEyLjA2IDEyLjA2IDAgMCAxLTQuNSAwbTMuNzUgMi4zODNhMTQuNDA2IDE0LjQwNiAwIDAgMS0zIDBNMTQuMjUgMTh2LS4xOTJjMC0uOTgzLjY1OC0xLjgyMyAxLjUwOC0yLjMxNmE3LjUgNy41IDAgMSAwLTcuNTE3IDBjLjg1LjQ5MyAxLjUwOSAxLjMzMyAxLjUwOSAyLjMxNlYxOCIgLz4KPC9zdmc+Cg=="""
        pass

    async def inlet(
        self, body: dict, __event_emitter__, __user__: Optional[dict] = None
    ) -> dict:
        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": "Umschaltet!",
                    "done": True
                    "hidden": False,
                },
            }
        )
        return body
```

#### üñºÔ∏è Was passiert gerade?
- **toggle = True** erstellt eine Schalter-UI in Open WebUI ‚Äì Benutzer k√∂nnen den Filter manuell in Echtzeit aktivieren oder deaktivieren.
- **icon** (mit einer Data URI) wird als kleines Bild neben dem Namen des Filters angezeigt. Sie k√∂nnen jedes SVG verwenden, solange es als Data URI codiert ist!
- **Die `inlet`-Funktion** verwendet das spezielle Argument `__event_emitter__`, um Feedback/Status an die UI zu senden, wie z.B. einen kleinen Toast/Benachrichtigung, der "Umschalten!" anzeigt.

![Toggle Filter](/images/features/plugin/functions/toggle-filter.png)

Sie k√∂nnen diese Mechanismen nutzen, um Ihre Filter dynamisch, interaktiv und visuell einzigartig im Plugin-√ñkosystem von Open WebUI zu gestalten.

---

### üéØ Wichtige Komponenten erkl√§rt

#### 1Ô∏è‚É£ **`Valves`-Klasse (Optionale Einstellungen)**

Stellen Sie sich **Valves** als die Regler und Schieberegler f√ºr Ihren Filter vor. Wenn Sie den Benutzern konfigurierbare Optionen zur Anpassung des Verhaltens Ihres Filters geben m√∂chten, definieren Sie diese hier.

```python
class Valves(BaseModel):
    OPTION_NAME: str = "Standardwert"
```

Zum Beispiel:  
Wenn Sie einen Filter erstellen, der Antworten in Gro√übuchstaben umwandelt, k√∂nnten Sie den Benutzern erlauben, zu konfigurieren, ob jede Ausgabe vollst√§ndig kapitalisiert wird, z.B. √ºber ein Ventil wie `TRANSFORM_UPPERCASE: bool = True/False`.

---

#### 2Ô∏è‚É£ **`inlet`-Funktion (Eingabevorverarbeitung)**


Die `inlet`-Funktion ist wie **das Vorbereiten von Essen vor dem Kochen**. Stellen Sie sich vor, Sie sind ein Koch: Bevor die Zutaten in das Rezept (hier das LLM) kommen, k√∂nnten Sie Gem√ºse waschen, Zwiebeln schneiden oder das Fleisch w√ºrzen. Ohne diesen Schritt k√∂nnte Ihr fertiges Gericht geschmacklos sein, ungewaschenes Gem√ºse enthalten oder einfach inkonsistent sein.

In der Welt von Open WebUI erledigt die `inlet`-Funktion diese wichtige Vorbereitungsarbeit mit der **Benutzereingabe**, bevor sie an das Modell gesendet wird. Sie stellt sicher, dass die Eingabe so sauber, kontextbezogen und hilfreich wie m√∂glich ist, damit die KI damit umgehen kann.

üì• **Eingabe**:  
- **`body`**: Die Rohdaten aus Open WebUI an das Modell. Sie haben das Format einer Chat-Abschluss-Anfrage (normalerweise ein W√∂rterbuch, das Felder wie die Nachrichten des Gespr√§chs, Modelleinstellungen und andere Metadaten enth√§lt). Betrachten Sie dies als Ihre Rezeptzutaten.

üöÄ **Ihre Aufgabe**:  
Modifizieren und zur√ºckgeben des `body`. Die modifizierte Version des `body` ist das, mit dem das LLM arbeitet, also ist dies Ihre Gelegenheit, der Eingabe Klarheit, Struktur und Kontext zu verleihen.


##### üç≥ Warum sollten Sie die `inlet` verwenden?
1. **Kontext hinzuf√ºgen**: Automatisch wichtige Informationen zur Benutzereingabe hinzuf√ºgen, insbesondere wenn ihr Text vage oder unvollst√§ndig ist. Zum Beispiel k√∂nnten Sie hinzuf√ºgen "Du bist ein freundlicher Assistent" oder "Hilf diesem Benutzer bei der Fehlerbehebung eines Softwarefehlers."
   
2. **Daten formatieren**: Wenn die Eingabe ein bestimmtes Format wie JSON oder Markdown erfordert, k√∂nnen Sie dies vor dem Senden an das Modell umwandeln.

3. **Eingabe bereinigen**: Unerw√ºnschte Zeichen entfernen, m√∂glicherweise sch√§dliche oder verwirrende Symbole (wie √ºberm√§√üige Leerzeichen oder Emojis) entfernen oder sensible Informationen ersetzen.

4. **Benutzereingabe vereinfachen**: Wenn sich die Ausgabe Ihres Modells durch zus√§tzliche Anleitung verbessert, k√∂nnen Sie die `inlet` nutzen, um kl√§rende Anweisungen automatisch einzuf√ºgen!


##### üí° Beispielanwendungen: Weiterentwicklung der Essenszubereitung
###### ü•ó Beispiel 1: Systemkontext hinzuf√ºgen
Angenommen, das LLM ist ein Koch, der ein Gericht f√ºr die italienische K√ºche vorbereitet, aber der Benutzer hat nicht erw√§hnt "Dies ist f√ºr die italienische K√ºche." Sie k√∂nnen sicherstellen, dass die Nachricht klar ist, indem Sie diesen Kontext vor dem Senden der Daten an das Modell hinzuf√ºgen.

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # Systemnachricht f√ºr italienischen Kontext in die Unterhaltung hinzuf√ºgen
    context_message = {
        "role": "system",
        "content": "Du hilfst dem Benutzer, ein italienisches Essen vorzubereiten."
    }
    # Einf√ºgen des Kontexts am Anfang der Chat-Historie
    body.setdefault("messages", []).insert(0, context_message)
    return body
```

üìñ **Was passiert?**
- Jede Benutzereingabe wie "Was sind gute Ideen f√ºrs Abendessen?" tr√§gt nun das italienische Thema, da wir den Systemkontext gesetzt haben! K√§sekuchen wird m√∂glicherweise nicht als Antwort erscheinen, aber Pasta sicherlich.


###### üî™ Beispiel 2: Eingabe bereinigen (Merkw√ºrdige Zeichen entfernen)
Angenommen, die Eingabe des Benutzers sieht chaotisch aus oder enth√§lt unerw√ºnschte Symbole wie `!!!`, was die Unterhaltung ineffizient oder f√ºr das Modell schwieriger zu parsen macht. Sie k√∂nnen sie bereinigen, w√§hrend Sie den Kerninhalt beibehalten.

```python
def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    # Bereinigen der letzten Benutzereingabe (vom Ende der messages-Liste)
    last_message = body["messages"][-1]["content"]
    body["messages"][-1]["content"] = last_message.replace("!!!", "").strip()
    return body
```

üìñ **Was passiert?**
- Vorher: `"Wie kann ich dieses Problem debuggen!!!"` ‚û°Ô∏è An das Modell gesendet als `"Wie kann ich dieses Problem debuggen"`

Hinweis: Der Benutzer f√ºhlt das Gleiche, aber das Modell verarbeitet eine sauberere und leichter verst√§ndliche Anfrage.


##### üìä Wie `inlet` hilft, die Eingabe f√ºr das LLM zu optimieren:
- Verbessert die **Genauigkeit**, indem es mehrdeutige Anfragen kl√§rt.
- Macht die KI **effizienter**, indem unn√∂tige Elemente wie Emojis, HTML-Tags oder √ºberfl√ºssige Satzzeichen entfernt werden.
- Gew√§hrleistet **Konsistenz**, indem Benutzereingaben so formatiert werden, dass sie den erwarteten Mustern oder Schemas des Modells entsprechen (z. B. JSON f√ºr einen bestimmten Anwendungsfall).


üí≠ **Betrachten Sie `inlet` als den Sous-Chef in Ihrer K√ºche** ‚Äì es sorgt daf√ºr, dass alles, was ins Modell (Ihr AI-"Rezept") eingeht, perfekt vorbereitet, gereinigt und gew√ºrzt ist. Je besser die Eingabe, desto besser das Ergebnis!

---

#### üÜï 3Ô∏è‚É£ **`stream` Hook (Neu in Open WebUI 0.5.17)**

##### üîÑ Was ist der `stream` Hook?
Die **`stream`-Funktion** ist eine neue Funktion, die in Open WebUI **0.5.17** eingef√ºhrt wurde und es erm√∂glicht, **gestreamte Modellantworten in Echtzeit abzufangen und zu √§ndern**.

Im Gegensatz zu `outlet`, das eine vollst√§ndige abgeschlossene Antwort verarbeitet, arbeitet `stream` mit **einzelnen Chunks**, w√§hrend sie vom Modell empfangen werden.

##### üõ†Ô∏è Wann sollte der Stream-Hook verwendet werden?
- **Stream-Antworten** √§ndern, bevor sie den Benutzern angezeigt werden.
- **Echtzeit-Zensur oder Bereinigung** implementieren.
- **Gestreamte Daten √ºberwachen** f√ºr Logging/Debugging.

##### üìú Beispiel: Streaming-Chunks protokollieren

So k√∂nnen Sie gestreamte LLM-Antworten inspizieren und bearbeiten:
```python
def stream(self, event: dict) -> dict:
    print(event)  # Jeden eingehenden Chunk zur Inspektion ausgeben
    return event
```

> **Beispiel f√ºr gestreamte Ereignisse:**
```jsonl
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "Hi"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "!"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": " üòä"}}]}
```
üìñ **Was passiert?**
- Jede Zeile repr√§sentiert ein **kleines Fragment** der gestreamten Antwort des Modells.
- Das Feld **`delta.content`** enth√§lt den fortlaufend generierten Text.

##### üîÑ Beispiel: Emojis aus gestreamten Daten entfernen
```python
def stream(self, event: dict) -> dict:
    for choice in event.get("choices", []):
        delta = choice.get("delta", {})
        if "content" in delta:
            delta["content"] = delta["content"].replace("üòä", "")  # Emojis entfernen
    return event
```
üìñ **Vorher:** `"Hi üòä"`  
üìñ **Nachher:** `"Hi"`

---

#### 4Ô∏è‚É£ **`outlet`-Funktion (Post-Processing der Ausgabe)**

Die `outlet`-Funktion ist wie ein **Korrekturleser**: Sie r√§umt die Antwort der KI auf (oder nimmt abschlie√üende √Ñnderungen vor), *nachdem sie vom LLM verarbeitet wurde.*  

üì§ **Eingabe**:
- **`body`**: Enth√§lt **alle aktuellen Nachrichten** im Chat (Benutzerhistorie + LLM-Antworten).

üöÄ **Ihre Aufgabe**: Passen Sie diesen `body` an. Sie k√∂nnen ihn bereinigen, erg√§nzen oder √Ñnderungen protokollieren, sollten jedoch ber√ºcksichtigen, wie jede Anpassung die Benutzererfahrung beeinflusst.

üí° **Best Practices**:
- Bevorzugen Sie Protokollierung gegen√ºber direkten √Ñnderungen im Outlet (z. B. f√ºr Debugging oder Analysen).
- Wenn umfangreiche √Ñnderungen erforderlich sind (z. B. zur Formatierung von Ausgaben), sollten Sie stattdessen die **Pipe-Funktion** verwenden.

üí° **Beispielanwendung**: Entfernen Sie vertrauliche API-Antworten, die der Benutzer nicht sehen soll:
```python
def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    for message in body["messages"]:
        message["content"] = message["content"].replace("<API_KEY>", "[REDACTED]")
    return body 
```

---

## üåü Filter in Aktion: Praktische Beispiele erstellen

Erstellen wir einige Beispiele aus der realen Welt, um zu sehen, wie Sie Filter verwenden w√ºrden!

### üìö Beispiel #1: Kontext zu jeder Benutzereingabe hinzuf√ºgen

M√∂chten Sie, dass das LLM immer wei√ü, dass es einem Kunden bei der Fehlerbehebung von Softwareproblemen hilft? Sie k√∂nnen Anweisungen wie **"Sie sind ein Software-Fehlerbehebungsassistent"** zu jeder Benutzeranfrage hinzuf√ºgen.

```python
class Filter:
    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        context_message = {
            "role": "system", 
            "content": "Sie sind ein Software-Fehlerbehebungsassistent."
        }
        body.setdefault("messages", []).insert(0, context_message)
        return body
```

---

### üìö Beispiel #2: Ausgaben zur leichteren Lesbarkeit hervorheben

R√ºckgabe einer Ausgabe im Markdown- oder einem anderen formatierten Stil? Verwenden Sie die `outlet`-Funktion!

```python
class Filter:
    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # "Hervorheben"-Markdown zu jeder Antwort hinzuf√ºgen
        for message in body["messages"]:
            if message["role"] == "assistant":  # Antwort des Modells anvisieren
                message["content"] = f"**{message[content]}**"  # Mit Markdown hervorheben
        return body
```

---

## üöß M√∂gliche Verwirrung: Klarstellungen im FAQ üõë 

### **F: Wie unterscheiden sich Filter von Pipe-Funktionen?**

Filter √§ndern Daten, die **ins Modell gehen** und **vom Modell zur√ºckkommen**, interagieren aber nicht signifikant mit Logik au√üerhalb dieser Phasen. Pipes hingegen:
- K√∂nnen **externe APIs** integrieren oder die Backend-Operationen grundlegend ver√§ndern.
- Bieten benutzerdefinierte Logik als komplett neue "Modelle" an.

### **F: Kann ich umfangreiche Nachbearbeitung innerhalb von `outlet` durchf√ºhren?**

Sie k√∂nnen, aber **es ist nicht die beste Praxis.**:
- **Filter** sind daf√ºr gedacht, leichte √Ñnderungen vorzunehmen oder Protokollierung anzuwenden.
- Wenn umfangreiche Modifikationen erforderlich sind, ziehen Sie stattdessen eine **Pipe-Funktion** in Betracht.

---

## üéâ Zusammenfassung: Warum Filterfunktionen erstellen?

Bis jetzt haben Sie gelernt:
1. **Inlet** manipuliert **Benutzereingaben** (Vorverarbeitung).
2. **Stream** f√§ngt **gestreamte Modellausgaben** ab und modifiziert diese (in Echtzeit).
3. **Outlet** ver√§ndert **KI-Ausgaben** (Nachbearbeitung).
4. Filter eignen sich am besten f√ºr leichte, Echtzeit-Anpassungen des Datenflusses.
5. Mit **Valves** k√∂nnen Sie Benutzern die M√∂glichkeit geben, Filter dynamisch f√ºr ma√ügeschneidertes Verhalten zu konfigurieren.

---

üöÄ **Ihre Aufgabe**: Experimentieren Sie! Welche kleine Anpassung oder Kontexterg√§nzung k√∂nnte Ihr Open WebUI-Erlebnis verbessern? Filter machen Spa√ü beim Erstellen, sind flexibel in der Anwendung und k√∂nnen Ihre Modelle auf die n√§chste Stufe bringen!

Viel Spa√ü beim Programmieren! ‚ú®
