---
sidebar_position: 400
title: "â­ Funktionen"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Hauptfunktionen von Open WebUI â­

- ğŸš€ **Einfaches Setup**: Nahtlose Installation mit Docker, Kubernetes, Podman, Helm Charts (`kubectl`, `kustomize`, `podman` oder `helm`) fÃ¼r ein mÃ¼heloses Erlebnis, mit UnterstÃ¼tzung fÃ¼r sowohl das `:ollama` Bild mit integriertem Ollama als auch das `:cuda` Bild mit CUDA-UnterstÃ¼tzung.

- ğŸ› ï¸ **GefÃ¼hrte anfÃ¤ngliche Einrichtung**: Den Einrichtungsprozess klar abschlieÃŸen, einschlieÃŸlich einer expliziten Anzeige zur Erstellung eines Administratorkontos wÃ¤hrend der erstmaligen Einrichtung.

- ğŸ¤ **OpenAI API-Integration**: MÃ¼helose Integration OpenAI-kompatibler APIs fÃ¼r vielseitige GesprÃ¤che neben Ollama-Modellen. Die OpenAI-API-URL kann angepasst werden, um Open WebUI problemlos mit verschiedenen Drittanbieteranwendungen zu integrieren.

- ğŸ›¡ï¸ **Detaillierte Berechtigungen und Benutzergruppen**: Durch die MÃ¶glichkeit, dass Administratoren detaillierte Benutzerrollen, Benutzergruppen und Berechtigungen im Arbeitsbereich erstellen kÃ¶nnen, gewÃ¤hrleisten wir eine sichere Benutzerumgebung fÃ¼r alle beteiligten Nutzer. Diese GranularitÃ¤t stÃ¤rkt nicht nur die Sicherheit, sondern ermÃ¶glicht auch individualisierte Benutzererfahrungen und fÃ¶rdert ein GefÃ¼hl des Eigentums und der Verantwortung unter den Nutzern.

- ğŸ“± **ReaktionsfÃ¤higes Design**: GenieÃŸen Sie ein nahtloses Erlebnis auf Desktop-PCs, Laptops und mobilen GerÃ¤ten.

- ğŸ“± **Progressive Web App fÃ¼r MobilgerÃ¤te**: Erleben Sie eine native Progressive-Webanwendung auf Ihrem mobilen GerÃ¤t mit Offline-Zugriff auf `localhost` oder einer persÃ¶nlichen Domain und einer flÃ¼ssigen BenutzeroberflÃ¤che. Damit unsere PWA auf Ihrem GerÃ¤t installierbar ist, muss sie in einem sicheren Kontext bereitgestellt werden. Das bedeutet normalerweise, dass sie Ã¼ber HTTPS bereitgestellt werden muss.

  :::info

  - Um eine PWA einzurichten, benÃ¶tigen Sie einige Kenntnisse Ã¼ber Technologien wie Linux, Docker und Reverse-Proxies wie `Nginx`, `Caddy` oder `Traefik`. Diese Tools kÃ¶nnen den Prozess des Erstellens und Bereitstellens einer PWA, die Ihren Anforderungen entspricht, vereinfachen. Obwohl es keine Option fÃ¼r eine â€Ein-Klick-Installationâ€œ gibt und Ihre Option, Ihre Open-WebUI-Instanz sicher Ã¼ber HTTPS bereitzustellen, Benutzererfahrung erfordert, kÃ¶nnen diese Ressourcen dabei helfen, eine PWA zu erstellen und bereitzustellen, die Ihren Anforderungen entspricht.

  :::

- âœ’ï¸ğŸ”¢ **Volle UnterstÃ¼tzung von Markdown und LaTeX**: Bereichern Sie Ihre LLM-Erfahrung mit umfassenden Markdown-, LaTeX- und Rich-Text-FÃ¤higkeiten fÃ¼r eine verbesserte Interaktion.

- ğŸ§© **Modell-Builder**: Erstellen Sie ganz einfach benutzerdefinierte Modelle aus Basis-Ollama-Modellen direkt Ã¼ber Open WebUI. Erstellen und fÃ¼gen Sie benutzerdefinierte Charaktere und Agenten hinzu, passen Sie Modellelemente an und importieren Sie Modelle mÃ¼helos Ã¼ber die [Open WebUI Community](https://openwebui.com/) Integration.

- ğŸ“š **Lokale und Remote-RAG-Integration**: Tauchen Sie in die Zukunft von Chat-Interaktionen ein und erkunden Sie Ihre Dokumente mit unserer hochmodernen Retrieval Augmented Generation (RAG)-Technologie innerhalb Ihrer Chats. Dokumente kÃ¶nnen im `Documents`-Tab des Arbeitsbereichs geladen werden, wo sie anschlieÃŸend mit dem `#`-Zeichen vor einer Anfrage oder durch Starten des Promptes mit dem `#`-Zeichen und einer URL fÃ¼r die Integration von Webseiteninhalten verwendet werden kÃ¶nnen.

- ğŸ“„ **Dokumentextraktion**: Extrahieren Sie Text und Daten aus verschiedenen Dokumentformaten wie PDFs, Word-Dokumenten, Excel-Tabellen, PowerPoint-PrÃ¤sentationen und mehr. Unsere fortschrittlichen Dokumentenverarbeitungsfunktionen ermÃ¶glichen eine nahtlose Integration in Ihre Wissensdatenbank, sodass Informationen aus komplexen Dokumenten prÃ¤zise abgerufen und generiert werden kÃ¶nnen, wÃ¤hrend deren Struktur und Formatierung erhalten bleiben.

- ğŸ” **Web-Suche fÃ¼r RAG**: Sie kÃ¶nnen Websuchen mit einer Auswahl verschiedener Suchanbieter durchfÃ¼hren und die Ergebnisse direkt in Ihre lokale Retrieval Augmented Generation (RAG)-Erfahrung einbringen.

- ğŸŒ **FÃ¤higkeiten fÃ¼rs Web-Browsing**: Integrieren Sie Websites nahtlos in Ihr Chat-Erlebnis, indem Sie den `#`-Befehl gefolgt von einer URL verwenden. Diese Funktion ermÃ¶glicht die direkte Einbindung von Webinhalten in Ihre GesprÃ¤che und verbessert so die Tiefe und Reichhaltigkeit Ihrer Interaktionen.

- ğŸ¨ **Bildgenerierung-Integration**: Nutzen Sie nahtlose BildgenerierungsmÃ¶glichkeiten, um Ihr Chat-Erlebnis mit dynamischen visuellen Inhalten zu bereichern.

- âš™ï¸ **Gleichzeitige Modell-nutzung**: Interagieren Sie mÃ¼helos gleichzeitig mit mehreren Modellen und nutzen Sie deren einzigartige StÃ¤rken fÃ¼r optimale Antworten. Nutzen Sie eine vielfÃ¤ltige Reihe von ModellmodalitÃ¤ten parallel, um Ihr Erlebnis zu verbessern.

- ğŸ” **Rollenbasierte Zugriffskontrolle (RBAC)**: GewÃ¤hrleisten Sie sicheren Zugriff mit eingeschrÃ¤nkten Berechtigungen. Nur autorisierte Personen kÃ¶nnen auf Ihr Ollama zugreifen, wÃ¤hrend Rechte fÃ¼r Modell-Erstellung und Modell-Abruf ausschlieÃŸlich Administratoren vorbehalten sind.

- ğŸŒğŸŒ **Mehrsprachige UnterstÃ¼tzung**: Erleben Sie Open WebUI in Ihrer bevorzugten Sprache mit unserer Internationalisierung (`i18n`)-UnterstÃ¼tzung. Wir laden Sie dazu ein, uns bei der Erweiterung der unterstÃ¼tzten Sprachen zu helfen! Wir suchen aktiv Mitwirkende!

- ğŸŒŸ **Kontinuierliche Updates**: Wir sind bestrebt, Open WebUI mit regelmÃ¤ÃŸigen Updates, Fehlerbehebungen und neuen Funktionen zu verbessern.

## Und viele weitere bemerkenswerte Funktionen, darunter... âš¡ï¸

---

### ğŸ”§ UnterstÃ¼tzung fÃ¼r Pipelines

- ğŸ”§ **Pipelines-Framework**: Integrieren und gestalten Sie Ihre Open WebUI-Erfahrung nahtlos mit unserem modularen Plugin-Framework fÃ¼r erweiterte Anpassung und FunktionalitÃ¤t (https://github.com/open-webui/pipelines). Unser Framework ermÃ¶glicht die einfache HinzufÃ¼gung benutzerdefinierter Logik sowie die Integration von Python-Bibliotheken, von KI-Agenten bis hin zu Heimautomations-APIs.

- ğŸ“¥ **Upload-Pipeline**: Pipelines kÃ¶nnen direkt Ã¼ber das MenÃ¼ `Admin Panel` > `Settings` > `Pipelines` hochgeladen werden, um den Pipeline-Verwaltungsprozess zu optimieren.

#### Die MÃ¶glichkeiten mit unserem Pipelines-Framework kennen keine Grenzen und sind praktisch unbegrenzt. Beginnen Sie mit einigen vorgefertigten Pipelines, um den Einstieg zu erleichtern!

- ğŸ”— **Funktionsaufruf**: Integrieren Sie [Funktionsaufrufe](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py) nahtlos Ã¼ber Pipelines, um Ihre LLM-Interaktionen um fortgeschrittene Funktionsaufruf-FÃ¤higkeiten zu erweitern.

- ğŸ“š **Benutzerdefinierte RAG**: Integrieren Sie eine [benutzerdefinierte Retrieval Augmented Generation (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) Pipeline nahtlos, um Ihre LLM-Interaktionen mit benutzerdefinierter RAG-Logik zu intensivieren.

- ğŸ“Š **NachrichtenÃ¼berwachung mit Langfuse**: Ãœberwachen und analysieren Sie Echtzeitstatistiken von Nachrichteninteraktionen Ã¼ber eine [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py)-Pipeline.

- âš–ï¸ **Benutzer-Ratenbegrenzung**: Verwalten Sie die API-Nutzung effizient durch Steuerung der Anzahl von Anfragen an LLMs, um zu verhindern, dass Ratenlimits Ã¼berschritten werden, mit der [Rate-Limit](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py)-Pipeline.

- ğŸŒ **LibreTranslate-EchtzeitÃ¼bersetzung**: Integrieren Sie EchtzeitÃ¼bersetzungen in Ihre LLM-Interaktionen mithilfe der [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py)-Pipeline und ermÃ¶glichen Sie mehrsprachige Kommunikation.
  - Bitte beachten Sie, dass diese Pipeline weitere Einrichtung mit LibreTranslate in einem Docker-Container erfordert, um zu funktionieren.

- ğŸ›¡ï¸ **Filterung toxischer Nachrichten**: Unsere [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py)-Pipeline filtert automatisch toxische Nachrichten, um eine saubere und sichere Chat-Umgebung zu gewÃ¤hrleisten.

- ğŸ”’ **LLM-Guard**: GewÃ¤hrleisten Sie sichere LLM-Interaktionen mit der [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py)-Pipeline, die einen Prompt Injection Scanner enthÃ¤lt, der ausgeklÃ¼gelte Eingabemanipulationen erkennt und abschwÃ¤cht, die auf groÃŸe Sprachmodelle abzielen. Dadurch werden Ihre LLMs vor Datenlecks geschÃ¼tzt und eine zusÃ¤tzliche Resistenz gegen Prompt Injection-Angriffe hinzugefÃ¼gt.

- ğŸ•’ **Begrenzung der GesprÃ¤chsdrehungen**: Verbessern Sie die Interaktionsverwaltung, indem Sie Grenzen fÃ¼r GesprÃ¤chsdrehungen mit der [Begrenzung der GesprÃ¤chsdrehungen](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py)-Pipeline setzen.

- ğŸ“ˆ **OpenAI-Generierungsstatistiken**: Unsere [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py)-Pipeline bietet detaillierte Generierungsstatistiken fÃ¼r OpenAI-Modelle.

- **ğŸš€ UnterstÃ¼tzung fÃ¼r mehrere Modelle**: Unsere nahtlose Integration mit verschiedenen KI-Modellen von [verschiedenen Anbietern](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers) erweitert Ihre MÃ¶glichkeiten mit einer Vielzahl von Sprachmodellen, aus denen Sie auswÃ¤hlen und mit denen Sie interagieren kÃ¶nnen.

#### ZusÃ¤tzlich zu den umfangreichen Funktionen und Anpassungsoptionen bieten wir [eine Bibliothek von Beispiels-Pipelines, die einsatzbereit sind](https://github.com/open-webui/pipelines/tree/main/examples) zusammen mit [einer praktischen Beispiel-Skelett-Pipeline](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) an, um Ihnen den Einstieg zu erleichtern. Diese Ressourcen vereinfachen Ihren Entwicklungsprozess und ermÃ¶glichen es Ihnen, schnell leistungsstarke LLM-Interaktionen mit Pipelines und Python zu erstellen. Viel SpaÃŸ beim Programmieren! ğŸ’¡

---

### ğŸ–¥ï¸ Benutzererfahrung

- ğŸ–¥ï¸ **Intuitive BenutzeroberflÃ¤che**: Die Chat-BenutzeroberflÃ¤che wurde benutzerfreundlich gestaltet und orientiert sich an der BenutzeroberflÃ¤che von ChatGPT.

- âš¡ **Schnelle ReaktionsfÃ¤higkeit**: GenieÃŸen Sie stets schnelle und reaktionsfÃ¤hige Leistung.

- ğŸ¨ **Splash Screen**: Ein einfaches Lade-Splashscreen fÃ¼r ein reibungsloseres Benutzererlebnis.

- ğŸŒ **Personalisierte BenutzeroberflÃ¤che**: WÃ¤hlen Sie aus einer neu gestalteten Suchstartseite und der klassischen Chat-BenutzeroberflÃ¤che unter Einstellungen > BenutzeroberflÃ¤che, um eine individuelle Erfahrung zu ermÃ¶glichen.

- ğŸ“¦ **Pip Install Methode**: Die Installation von Open WebUI kann Ã¼ber den Befehl `pip install open-webui` durchgefÃ¼hrt werden, der den Prozess vereinfacht und neuen Benutzern den Zugang erleichtert. Weitere Informationen finden Sie unter: https://pypi.org/project/open-webui/.

- ğŸŒˆ **Theme-Anpassung**: Passen Sie Ihr Open WebUI-Erlebnis mit einer Vielzahl von Optionen an, darunter verschiedene solide und elegante Designs, anpassbare Chat-Hintergrundbilder und drei Modi: Light, Dark oder OLED Dark Mode - oder lassen Sie *Her* fÃ¼r Sie wÃ¤hlen! ;)

- ğŸ–¼ï¸ **UnterstÃ¼tzung fÃ¼r benutzerdefinierte HintergrÃ¼nde**: Stellen Sie einen benutzerdefinierten Hintergrund unter Einstellungen > OberflÃ¤che ein, um Ihr Erlebnis zu personalisieren.

- ğŸ“ **Reiche Banner mit Markdown**: Erstellen Sie visuell ansprechende AnkÃ¼ndigungen mit Markdown-UnterstÃ¼tzung in Bannern, die reichhaltigere und dynamischere Inhalte ermÃ¶glichen.

- ğŸ’» **Syntax-Hervorhebung fÃ¼r Code**: Unsere Syntax-Hervorhebung steigert die Lesbarkeit von Code und bietet eine klare und prÃ¤gnante Ansicht Ihres Codes.

- ğŸ—¨ï¸ **Markdown-Wiedergabe in Benutzer-Nachrichten**: Benutzernachrichten werden jetzt in Markdown gerendert, was die Lesbarkeit und Interaktion verbessert.

- ğŸ¨ **Flexible Text-Eingabeoptionen**: Wechseln Sie zwischen der Eingabe von Rich-Text und der klassischen Textbereich-Eingabe fÃ¼r Chats, wobei BenutzerprÃ¤ferenzen berÃ¼cksichtigt werden und die Wahl zwischen fortschrittlicher Formatierung und einfacher Text-Eingabe geboten wird.

- ğŸ‘† **MÃ¼heloses Teilen von Code**: Vereinfachen Sie den Sharing- und Kollaborationsprozess mit praktischen Optionen zum Kopieren von Code, einschlieÃŸlich einer schwebenden KopierschaltflÃ¤che in CodeblÃ¶cken und einer Klick-zu-Kopieren-FunktionalitÃ¤t aus Code-Spans, wodurch Zeit gespart und Frustration reduziert wird.

- ğŸ¨ **Interaktive Artefakte**: Rendern Sie Web-Inhalte und SVGs direkt in der OberflÃ¤che, unterstÃ¼tzen schnelle Iterationen und Live-Ã„nderungen fÃ¼r gesteigerte KreativitÃ¤t und ProduktivitÃ¤t.

- ğŸ–Šï¸ **Live-Code-Bearbeitung**: Verbesserte CodeblÃ¶cke erlauben die Live-Bearbeitung direkt in der LLM-Antwort, mit Live-Neuladungen, unterstÃ¼tzt durch Artefakte, um Coding und Tests zu vereinfachen.

- ğŸ” **Verbesserte Interaktion mit SVG**: Die Schwenk- und Zoomfunktionen fÃ¼r SVG-Bilder, einschlieÃŸlich Mermaid-Diagrammen, ermÃ¶glichen eine tiefere Erforschung und ein besseres VerstÃ¤ndnis komplexer Konzepte.

- ğŸ” **Schnelle Aktionen bei Textauswahl**: Schwebende SchaltflÃ¤chen erscheinen, wenn Text in LLM-Antworten hervorgehoben wird, und bieten tiefere Interaktionen wie "Frage stellen" oder "ErklÃ¤ren", wodurch die Benutzererfahrung insgesamt verbessert wird.

- â†•ï¸ **Bidirektionale Chat-UnterstÃ¼tzung**: Sie kÃ¶nnen einfach zwischen Links-nach-Rechts- und Rechts-nach-Links-Chat-Richtungen wechseln, um verschiedene SprachprÃ¤ferenzen zu berÃ¼cksichtigen.

- ğŸ“± **Mobile Erreichbarkeit**: Die Seitenleiste kann auf MobilgerÃ¤ten mit einer einfachen Wischgeste geÃ¶ffnet und geschlossen werden.

- ğŸ¤³ **Haptisches Feedback auf unterstÃ¼tzten GerÃ¤ten**: Android-GerÃ¤te unterstÃ¼tzen haptisches Feedback fÃ¼r ein immersives taktiles Erlebnis bei bestimmten Interaktionen.

- ğŸ” **Benutzereinstellungen-Suche**: Suchen Sie schnell nach Einstellungenfeldern, um die Benutzerfreundlichkeit und Navigation zu verbessern.

- ğŸ“œ **Offline Swagger-Dokumentation**: Greifen Sie offline auf entwicklerfreundliche Swagger-API-Dokumentation zu, um Ã¼berall vollstÃ¤ndige ZugÃ¤nglichkeit zu gewÃ¤hrleisten.

- ğŸ’¾ **Performance-Optimierungen**: Durch Lazy Loading von groÃŸen AbhÃ¤ngigkeiten wird der anfÃ¤ngliche Speicherverbrauch minimiert, wodurch die Leistung gesteigert und Ladezeiten verkÃ¼rzt werden.

- ğŸš€ **Dauerhafte und skalierbare Konfiguration**: Open WebUI-Konfigurationen werden in einer Datenbank (webui.db) gespeichert, was ein nahtloses Load Balancing, HochverfÃ¼gbarkeits-Setups und dauerhafte Einstellungen Ã¼ber mehrere Instanzen hinweg ermÃ¶glicht, sodass Sie einfach auf Ihre Konfigurationen zugreifen und sie wiederverwenden kÃ¶nnen.

- ğŸ”„ **Portables Importieren/Exportieren**: Importieren und exportieren Sie einfach Open WebUI-Konfigurationen, um den Prozess der Replikation von Einstellungen Ã¼ber mehrere Systeme zu vereinfachen.

- â“ **Schneller Zugriff auf Dokumentation & Shortcuts**: Die Fragezeichen-SchaltflÃ¤che unten rechts auf dem Hauptbildschirm der BenutzeroberflÃ¤che (verfÃ¼gbar auf grÃ¶ÃŸeren Bildschirmen wie Desktop-PCs und Laptops) bietet Benutzern einfachen Zugriff auf die Open WebUI-Dokumentationsseite und verfÃ¼gbare Tastenkombinationen.

- ğŸ“œ **Ã„nderungsprotokoll & Updates prÃ¼fen**: Benutzer kÃ¶nnen ein umfassendes Ã„nderungsprotokoll einsehen und Updates im MenÃ¼ `Einstellungen` > `Ãœber` > `Sehen Sie, wass neu ist`, abrufen, das einen schnellen Ãœberblick Ã¼ber die neuesten Funktionen, Verbesserungen und Fehlerbehebungen sowie die MÃ¶glichkeit bietet, Updates zu prÃ¼fen.

---

### ğŸ’¬ GesprÃ¤che

- ğŸ’¬ **Echter asynchroner Chat**: GenieÃŸen Sie ununterbrochenes Multitasking mit echter asynchroner Chat-UnterstÃ¼tzung, sodass Sie Chats erstellen, weg navigieren und jederzeit zurÃ¼ckkehren kÃ¶nnen, mit bereits fertiggestellten Antworten.

- ğŸ”” **Chat-Abschluss-Benachrichtigungen**: Bleiben Sie mit sofortigen In-UI-Benachrichtigungen auf dem Laufenden, wenn ein Chat in einem nicht aktiven Tab abgeschlossen wird, sodass Sie keine fertige Antwort verpassen.

- ğŸŒ **Webhook-Integrationsbenachrichtigungen**: Erhalten Sie rechtzeitige Updates fÃ¼r lang laufende Chats oder externe Integrationsanforderungen mit konfigurierbaren Webhook-Benachrichtigungen, selbst wenn Ihr Tab geschlossen ist.

- ğŸ“š **KanÃ¤le (Beta)**: Erkunden Sie echte Echtzeit-Kollaboration zwischen Benutzern und AIs mit Discord-/Slack-Ã¤hnlichen Chat-RÃ¤umen, erstellen Sie Bots fÃ¼r KanÃ¤le und schalten Sie asynchrone Kommunikation fÃ¼r proaktive Multi-Agenten-Workflows frei.

- ğŸ–Šï¸ **Echtzeit-Schreibindikatoren in KanÃ¤len**: Verbessern Sie die Zusammenarbeit mit Echtzeit-Schreibindikatoren in KanÃ¤len, die alle informiert und engagiert halten.

- ğŸ‘¤ **Benutzerstatus-Anzeigen**: Sehen Sie den Status eines Benutzers, indem Sie dessen Profilbild in KanÃ¤len anklicken. Dies bietet eine bessere Koordination und Einblicke in die VerfÃ¼gbarkeit.

- ğŸ’¬ **Chat-Steuerung**: Passen Sie Parameter fÃ¼r jede Chat-Sitzung einfach an und ermÃ¶glichen Sie prÃ¤zisere Steuerung Ihrer Interaktionen.

- ğŸ’– **Verwaltung bevorzugter Antworten**: Markieren und organisieren Sie bevorzugte Antworten direkt Ã¼ber die Chat-Ãœbersicht, um das Abrufen und den Zugriff auf bevorzugte Antworten zu erleichtern.

- ğŸ“Œ **Angepinnte Chats**: UnterstÃ¼tzung fÃ¼r angepinnte Chats, sodass Sie wichtige GesprÃ¤che leicht zugÃ¤nglich behalten kÃ¶nnen.

- ğŸ” **RAG-Embedding-UnterstÃ¼tzung**: Ã„ndern Sie das Retrieval Augmented Generation (RAG)-Embedding-Modell direkt im MenÃ¼ `Admin Panel` > `Settings` > `Documents`, um die Dokumentenverarbeitung zu verbessern. Diese Funktion unterstÃ¼tzt Ollama- und OpenAI-Modelle.

- ğŸ“œ **Quellenangaben in RAG-Funktion**: Die Retrieval Augmented Generation (RAG)-Funktion ermÃ¶glicht es Benutzern, den Kontext der an LLMs Ã¼bermittelten Dokumente zu verfolgen, mit hinzugefÃ¼gten Quellenangaben als Bezugspunkte.

- ğŸŒŸ **Erweiterte RAG-Pipeline**: Eine umschaltbare hybride Suchfunktion fÃ¼r unser RAG-Embedding-Feature, die die RAG-FunktionalitÃ¤t durch `BM25` verbessert, mit einer erneuten Bewertung durch `CrossEncoder` und konfigurierbaren Relevanzschwellenwerten.

- ğŸ“¹ **YouTube-RAG-Pipeline**: Die dedizierte Retrieval Augmented Generation (RAG)-Pipeline fÃ¼r die Zusammenfassung von YouTube-Videos Ã¼ber Video-URLs ermÃ¶glicht eine nahtlose Interaktion mit Video-Transkriptionen.

- ğŸ“ **Umfassende Dokumentenabfrage**: Wechseln Sie zwischen der Abrufung ganzer Dokumente und traditionellen Snippets, um umfassende Aufgaben wie Zusammenfassungen zu ermÃ¶glichen und erweiterte Dokumentenfunktionen zu unterstÃ¼tzen.

- ğŸŒŸ **Relevanz von RAG-Zitaten**: Bewerten Sie die Genauigkeit von Zitaten mit der HinzufÃ¼gung von Relevanzanteilen in RAG-Ergebnissen.

- ğŸ—‚ï¸ **Erweiterte RAG**: Verbessern Sie die RAG-Genauigkeit mit intelligenter Vorverarbeitung des Chat-Verlaufs, um die besten Abfragen vor der Abrufung zu bestimmen.

- ğŸ“š **Inline-Zitate fÃ¼r RAG**: Profitieren Sie von nahtlosen Inline-Zitaten fÃ¼r Retrieval-Augmented-Generation (RAG)-Antworten, was die Nachverfolgbarkeit verbessert und Quellenklarheit fÃ¼r neu hochgeladene Dateien bietet.

- ğŸ“ **Umgang mit groÃŸen Texten**: Konvertieren Sie groÃŸe eingefÃ¼gte Texte optional in eine Datei, die direkt mit RAG verwendet werden kann, um die Chat-OberflÃ¤che Ã¼bersichtlicher zu halten.

- ğŸ”„ **Multi-Modale UnterstÃ¼tzung**: Interagieren Sie mÃ¼helos mit Modellen, die multimodale Interaktionen unterstÃ¼tzen, einschlieÃŸlich Bildern (z. B. `LLaVA`).

- ğŸ¤– **UnterstÃ¼tzung mehrerer Modelle**: Wechseln Sie schnell zwischen verschiedenen Modellen fÃ¼r diverse Chat-Interaktionen.

- ğŸ”€ **Antworten in Multi-Model-Chats zusammenfÃ¼hren**: Verbessert den Dialog, indem Antworten aus mehreren Modellen zu einer einzigen, kohÃ¤renten Antwort zusammengefÃ¼hrt werden.

- âœ… **Mehrfachinstanzen des gleichen Modells in Chats**: Verbesserte Multi-Model-Chats zur UnterstÃ¼tzung mehrerer Instanzen desselben Modells.

- ğŸ’¬ **TemporÃ¤re Chat-Funktion**: EinfÃ¼hrung einer temporÃ¤ren Chat-Funktion, die die alte Chatverlaufseinstellung ersetzt, um die BenutzerflexibilitÃ¤t zu erhÃ¶hen.

- ğŸ–‹ï¸ **Bearbeitung von Benutzer-Nachrichten**: Verbesserung der Benutzerchat-Bearbeitungsfunktion, um Ã„nderungen zu speichern, ohne diese zu senden.

- ğŸ’¬ **Effizientes Bearbeiten von GesprÃ¤chen**: Erstellen Sie neue Nachrichtenpaare schnell und intuitiv mit der Tastenkombination Cmd/Ctrl+Shift+Enter, um Tests der GesprÃ¤chstlÃ¤nge zu optimieren.

- ğŸ–¼ï¸ **Clientseitige Bildkompression**: Sparen Sie Bandbreite und verbessern Sie die Leistung mit clientseitiger Bildkompression. Sie kÃ¶nnen Bilder vor dem Hochladen komprimieren (Einstellungen > Schnittstelle).

- ğŸ‘¥ **'@'-Modellintegration**: Indem Benutzer nahtlos zwischen allen zugÃ¤nglichen lokalen oder externen Modellen wÃ¤hrend der GesprÃ¤che wechseln, kÃ¶nnen sie die kollektive Intelligenz mehrerer Modelle in einem einzigen Chat nutzen. Dies kann durch die Nutzung des `@`-Befehls erfolgen, um das Modell innerhalb eines Chats nach Namen zu spezifizieren.

- ğŸ·ï¸ **GesprÃ¤chstaggierung**: Kategorisieren und finden Sie tagged Chats mÃ¼helos fÃ¼r schnelle Referenzen und vereinfachte Datensammlung mit unserem effizienten `tag:`-Abfragesystem, das Ihnen ermÃ¶glicht, Ihre GesprÃ¤che zu verwalten, zu durchsuchen und zu organisieren, ohne die BenutzeroberflÃ¤che zu Ã¼berfrachten.

- ğŸ§  **Automatische Taggierung**: GesprÃ¤che kÃ¶nnen optional automatisch getaggt werden, um eine bessere Organisation zu ermÃ¶glichen, Ã¤hnlich wie auto-generierte Titel.

- ğŸ‘¶ **Chat-Klonen**: Klonen und speichern Sie ganz einfach eine Momentaufnahme eines Chats zur spÃ¤teren Verwendung oder Fortsetzung. Mit dieser Funktion kÃ¶nnen Sie dort weitermachen, wo Sie aufgehÃ¶rt haben, oder Ihre Sitzung mit anderen teilen. Um eine Kopie des Chats zu erstellen, klicken Sie einfach auf die `Klonen`-SchaltflÃ¤che in den Dropdown-Optionen des Chats. KÃ¶nnen Sie mit Ihren Klonen Schritt halten?

- â­ **Visualisierte GesprÃ¤chsverlÃ¤ufe**: Interaktives Nachrichten-Diagramm zur verbesserten Visualisierung von GesprÃ¤chsverlÃ¤ufen, was das VerstÃ¤ndnis und die Navigation bei komplexen Diskussionen fÃ¶rdert.

- ğŸ“ **Chat-Ordner**: Organisieren Sie Ihre GesprÃ¤che in Ordnern, ziehen Sie sie per Drag & Drop fÃ¼r eine einfache Verwaltung und exportieren Sie sie nahtlos zum Teilen oder zur Analyse.

- ğŸ“¤ **Einfache Chat-Importe**: Importieren Sie Chats in Ihren Arbeitsbereich, indem Sie Chat-Exporte (JSON) einfach per Drag & Drop in die Seitenleiste ziehen.

- ğŸ“œ **UnterstÃ¼tzung fÃ¼r voreingestellte Prompts**: Greifen Sie sofort auf benutzerdefinierte voreingestellte Prompts mit dem `/`-Befehl im Chat-Eingabefeld zu. Laden Sie mÃ¼helos vordefinierte GesprÃ¤chsanfÃ¤nge und beschleunigen Sie Ihre Interaktionen. Importieren Sie Prompts einfach Ã¼ber die Integration mit der [Open WebUI Community](https://openwebui.com/) oder erstellen Sie Ihre eigenen!

- ğŸ“… **UnterstÃ¼tzung fÃ¼r Prompt-Variablen**: Prompt-Variablen wie `{{CLIPBOARD}}`, `{{CURRENT_DATE}}`, `{{CURRENT_DATETIME}}`, `{{CURRENT_TIME}}`, `{{CURRENT_TIMEZONE}}`, `{{CURRENT_WEEKDAY}}`, `{{USER_NAME}}`, `{{USER_LANGUAGE}}` und `{{USER_LOCATION}}` kÃ¶nnen im System-Prompt oder Ã¼ber einen SchrÃ¤gstrichbefehl zur direkten Auswahl eines Prompts innerhalb eines Chats verwendet werden.
  - Bitte beachten Sie, dass die Prompt-Variable `{{USER_LOCATION}}` eine sichere Verbindung Ã¼ber HTTPS erfordert. Um diese spezielle Prompt-Variable zu nutzen, stellen Sie bitte sicher, dass `{{USER_LOCATION}}` im MenÃ¼ `Einstellungen` > `BenutzeroberflÃ¤che` aktiviert ist.
  - Bitte beachten Sie, dass die Prompt-Variable `{{CLIPBOARD}}` Zugriff auf die Zwischenablage Ihres GerÃ¤ts erfordert.

- ğŸ§  **Speicherfunktion**: FÃ¼gen Sie manuell Informationen hinzu, die Ihre LLMs sich merken sollen, Ã¼ber das MenÃ¼ `Einstellungen` > `Personalisierung` > `Speicher`. Speicherinhalte kÃ¶nnen hinzugefÃ¼gt, bearbeitet und gelÃ¶scht werden.

---

### ğŸ’» Modellverwaltung


- ğŸ› ï¸ **Modell-Builder**: Alle Modelle kÃ¶nnen mit einem persistenten Modell-Builder-Modus auf der Bearbeitungsseite fÃ¼r Modelle erstellt und bearbeitet werden.

- ğŸ“š **WissensunterstÃ¼tzung fÃ¼r Modelle**: Die MÃ¶glichkeit, Werkzeuge, Funktionen und Wissenssammlungen direkt von der Bearbeitungsseite eines Modells an Modelle anzuhÃ¤ngen, um die fÃ¼r jedes Modell verfÃ¼gbaren Informationen zu verbessern.

- ğŸ—‚ï¸ **Modell-Voreinstellungen**: Erstellen und verwalten Sie Modellvoreinstellungen sowohl fÃ¼r die Ollama- als auch die OpenAI-API.

- ğŸ·ï¸ **Modell-Tagging**: Der Modellarbeitsbereich ermÃ¶glicht es Benutzern, ihre Modelle mithilfe von Tags zu organisieren.

- ğŸ“‹ **Dropdown-Reihenfolge fÃ¼r Modellauswahl**: Modelle kÃ¶nnen mÃ¼helos durch Ziehen und Ablegen in gewÃ¼nschte Positionen im Modellarbeitsbereich organisiert werden, was sich dann in der Dropdown-Liste der Modelle widerspiegelt.

- ğŸ” **Dropdown zur Modellauswahl**: Finden und wÃ¤hlen Sie Ihre Modelle leicht mit unscharfer Suche und detaillierten Modellinformationen wie Modell-Tags und Beschreibungen aus.

- âŒ¨ï¸ **Modellauswahl mit Pfeiltasten**: Verwenden Sie Pfeiltasten fÃ¼r eine schnellere Modellauswahl und verbessern Sie die ZugÃ¤nglichkeit.

- ğŸ”§ **Schnellaktionen im Modellarbeitsbereich**: Verbesserte Schnellaktionen mit der Umschalttaste zum Verbergen/Anzeigen und LÃ¶schen von Modellen im Modellarbeitsbereich.

- ğŸ˜„ **Transparente Modellnutzung**: Bleiben Sie wÃ¤hrend Abfragen mit wissensgestÃ¼tzten Modellen Ã¼ber den Zustand des Systems informiert, dank sichtbarer Statusanzeigen.

- âš™ï¸ **Fein abgestimmte Kontrolle mit erweiterten Parametern**: Erhalten Sie ein tieferes MaÃŸ an Kontrolle durch die Anpassung von Modellparametern wie `seed`, `temperature`, `frequency penalty`, `context length`, `seed` und mehr.

- ğŸ”„ **Nahtlose Integration**: Kopieren Sie jeden `ollama run {model:tag}` CLI-Befehl direkt von der Seite eines Modells in der [Ollama-Bibliothek](https://ollama.com/library/) und fÃ¼gen Sie ihn in die Modellauswahl-Dropdown ein, um Modelle leicht auszuwÃ¤hlen und herunterzuladen.

- ğŸ—‚ï¸ **Erstellen einer Ollama-Modelldatei**: Um eine Modelldatei fÃ¼r Ollama zu erstellen, navigieren Sie zu `Admin-Panel` > `Einstellungen` > `Modelle` > `Modell erstellen`.

- â¬†ï¸ **Erstellen eines GGUF-Dateimodells**: Erstellen Sie Ollama-Modelle mÃ¼helos, indem Sie GGUF-Dateien direkt von Open WebUI hochladen; verfÃ¼gbar im MenÃ¼ `Admin-Einstellungen` > `Einstellungen` > `Modell` > `Experimentell`. Der Prozess wurde mit der MÃ¶glichkeit, Dateien von Ihrem GerÃ¤t hochzuladen oder GGUF-Dateien von Hugging Face herunterzuladen, optimiert.

- âš™ï¸ **Standardmodell-Einstellung**: Die StandardmodellprÃ¤ferenz fÃ¼r neue Chats kann im MenÃ¼ `Einstellungen` > `BenutzeroberflÃ¤che` auf mobilen GerÃ¤ten festgelegt werden, oder einfacher in einem neuen Chat unter der Modellauswahl-Dropdown auf Desktop-PCs und Laptops.

- ğŸ’¡ **Einblicke in LLM-Antworten**: Details zu jeder generierten Antwort kÃ¶nnen einschlieÃŸlich Einblicke in externe Model-APIs und umfassende lokale Modellinformationen angezeigt werden.

- ğŸ•’ **Modelldetails auf einen Blick**: Anzeigen von wichtigen Modelldetails wie Modell-Hash und letztem Ã„nderungszeitstempel direkt im Modellarbeitsbereich fÃ¼r eine verbesserte Nachverfolgung und Verwaltung.

- ğŸ“¥ğŸ—‘ï¸ **Modelle herunterladen/lÃ¶schen**: Modelle kÃ¶nnen direkt in Open WebUI einfach heruntergeladen oder gelÃ¶scht werden.

- ğŸ”„ **Alle Ollama-Modelle aktualisieren**: Eine praktische SchaltflÃ¤che ermÃ¶glicht es den Benutzern, alle lokal installierten Modelle in einem Vorgang zu aktualisieren und die Modellverwaltung zu vereinfachen.

- ğŸ» **Integration von TavernAI-Charakterkarten**: Erleben Sie visuelles Storytelling mit der Integration von TavernAI-Charakterkarten in unserem Modell-Builder. Benutzer kÃ¶nnen nahtlos TavernAI-Charakterkarten-PNGs direkt in ihre Modelldateien einfÃ¼gen und so ein intensiveres und ansprechenderes Benutzererlebnis schaffen.

- ğŸ² **Modellspielplatz (Beta)**: Testen Sie Modelle im Bereich `Modellspielplatz` (`Beta`), der es Benutzern ermÃ¶glicht, ModelfÃ¤higkeiten und Parameter einfach in einer Sandbox-Umgebung zu erkunden, bevor sie in einer Live-Chat-Umgebung eingesetzt werden.

---

### ğŸ‘¥ Zusammenarbeit

- ğŸ—¨ï¸ **Lokales Chat-Sharing**: Generieren und teilen Sie Chat-Links zwischen Benutzern auf effiziente und nahtlose Weise, um die Zusammenarbeit und Kommunikation zu verbessern.

- ğŸ‘ğŸ‘ **RLHF-Annotation**: VerstÃ¤rken Sie die Wirkung Ihrer Nachrichten, indem Sie diese mit einem Daumen hoch oder Daumen runter bewerten und eine Bewertung fÃ¼r die Antwort auf einer Skala von 1-10 abgeben. AnschlieÃŸend besteht die Option, ein schriftliches Feedback zu geben, um DatensÃ¤tze fÃ¼r Reinforcement Learning aus menschlichem Feedback (`RLHF`) zu erstellen. Nutzen Sie Ihre Nachrichten, um Modelle zu trainieren oder zu optimieren, wÃ¤hrend die Vertraulichkeit lokal gespeicherter Daten gewÃ¤hrleistet bleibt.

- ğŸ”§ **Umfassender Feedback-Export**: Exportieren Sie Feedback-Historie-Daten in JSON fÃ¼r eine nahtlose Integration in die RLHF-Verarbeitung und weitere Analysen, um wertvolle Einblicke fÃ¼r Verbesserungen zu erhalten.

- ğŸ¤ **Community Sharing**: Teilen Sie Ihre Chat-Sitzungen mit der [Open WebUI Community](https://openwebui.com/), indem Sie auf die SchaltflÃ¤che `In Open WebUI Community teilen` klicken. Diese Funktion ermÃ¶glicht es Ihnen, mit anderen Nutzern zusammenzuarbeiten und sich auf der Plattform auszutauschen.
  - Um diese Funktion zu nutzen, melden Sie sich bitte mit Ihrem Open WebUI Community-Konto an. Durch das Teilen Ihrer Chats fÃ¶rdern Sie eine lebhafte Community, erleichtern den Wissensaustausch und unterstÃ¼tzen die gemeinsame ProblemlÃ¶sung. Bitte beachten Sie, dass das Teilen von Chat-Sitzungen in der Community eine optionale Funktion ist. Nur Admins kÃ¶nnen diese Funktion im MenÃ¼ `Admin Einstellungen` > `Einstellungen` > `Allgemein` aktivieren oder deaktivieren.

- ğŸ† **Community-Leaderboard**: Vergleichen und verfolgen Sie Ihre Leistung in Echtzeit mit unserem Leaderboard-System, das das ELO-Bewertungssystem verwendet und optional das Teilen von Feedback-Historien erlaubt.

- âš”ï¸ **Model Evaluations-Arena**: FÃ¼hren Sie direkte A/B-Blindtests von Modellen aus den Admin-Einstellungen fÃ¼r einen echten Vergleich nebeneinander durch, um das beste Modell fÃ¼r Ihre BedÃ¼rfnisse zu finden.

- ğŸ¯ **Themenbasierte Rankings**: Entdecken Sie genauere Rankings mit unserem experimentellen themenbasierten Re-Ranking-System, das die Leaderboard-Platzierungen basierend auf TagsimilaritÃ¤t im Feedback anpasst.

- ğŸ“‚ **Einheitlicher und kollaborativer Arbeitsbereich**: Greifen Sie auf alle Ihre Modell-Dateien, Eingaben, Dokumente, Tools und Funktionen an einem praktischen Ort zu und verwalten Sie sie, wÃ¤hrend gleichzeitig mehrere Benutzer zusammenarbeiten und zu Modellen, Wissen, Eingaben oder Tools beitragen kÃ¶nnen, um Ihren Arbeitsablauf zu optimieren und Teamarbeit zu fÃ¶rdern.

---

### ğŸ“š Verlauf & Archiv

- ğŸ“œ **Chat-Verlauf**: Greifen Sie Ã¼ber die Chat-Navigationsleiste mÃ¼helos auf Ihren GesprÃ¤chsverlauf zu und verwalten Sie diesen. Deaktivieren Sie den Chat-Verlauf im MenÃ¼ `Einstellungen` > `Chats`, um zu verhindern, dass ein Chat-Verlauf durch neue Interaktionen erstellt wird.

- ğŸ”„ **Regeneration-Verlauf-Zugang**: Besuchen und erkunden Sie mÃ¼helos Ihren gesamten LLM-Antwort-Regeneration-Verlauf.

- ğŸ“¬ **Chats archivieren**: Speichern Sie abgeschlossene GesprÃ¤che mit Modellen mÃ¼helos fÃ¼r zukÃ¼nftige Referenz oder Interaktionen ab, um eine ordentliche und aufgerÃ¤umte Chat-OberflÃ¤che zu erhalten.

- ğŸ—ƒï¸ **Alle Chats archivieren**: Mit dieser Funktion kÃ¶nnen Sie schnell all Ihre Chats gleichzeitig archivieren.

- ğŸ“¦ **Alle archivierten Chats als JSON exportieren**: Diese Funktion ermÃ¶glicht es Nutzern, alle ihre archivierten Chats einfach in einer einzelnen JSON-Datei zu exportieren, die fÃ¼r Backup- oder Transferzwecke verwendet werden kann.

- ğŸ“„ **Chats als JSON/PDF/TXT herunterladen**: Laden Sie Ihre Chats einzeln in Ihrem bevorzugten Format `.json`, `.pdf` oder `.txt` herunter.

- ğŸ“¤ğŸ“¥ **Chat-Verlauf importieren/exportieren**: Bewegen Sie Ihre Chat-Daten nahtlos in und aus der Plattform Ã¼ber die Optionen `Chats importieren` und `Chats exportieren`.

- ğŸ—‘ï¸ **Alle Chats lÃ¶schen**: Diese Option ermÃ¶glicht es Ihnen, alle Ihre Chats dauerhaft zu lÃ¶schen, um einen Neustart zu gewÃ¤hrleisten.

---

### ğŸ™ï¸ Audio, Stimme und Barrierefreiheit

- ğŸ—£ï¸ **SprachunterstÃ¼tzung**: Kommunizieren Sie mit Ihrem Modell durch Sprachinteraktionen; genieÃŸen Sie die Bequemlichkeit, direkt mit Ihrem Modell zu sprechen. AuÃŸerdem kÃ¶nnen Sie die Option untersuchen, Sprachinputs automatisch nach 3 Sekunden Stille zu senden, um ein reibungsloses Erlebnis zu ermÃ¶glichen.
  - FÃ¼r den Mikrofonzugang ist eine manuelle Einrichtung einer sicheren Verbindung Ã¼ber HTTPS erforderlich, oder [manuelles Whitelisting Ihrer URL auf eigenes Risiko](https://docs.openwebui.com/troubleshooting/microphone-error).

- ğŸ˜Š **Emoji-Call**: Aktivieren Sie diese Funktion im MenÃ¼ `Einstellungen` > `Interface`, sodass LLMs Emotionen mithilfe von Emojis wÃ¤hrend SprachgesprÃ¤chen ausdrÃ¼cken kÃ¶nnen, um eine dynamischere Interaktion zu ermÃ¶glichen.
  - FÃ¼r diese Funktion ist Mikrofonzugang Ã¼ber eine sichere Verbindung per HTTPS erforderlich.

- ğŸ™ï¸ **Freisprech-SprachgesprÃ¤chsfunktion**: FÃ¼hren Sie SprachgesprÃ¤che ohne Ihre HÃ¤nde verwenden zu mÃ¼ssen, um die Interaktionen zu vereinfachen.
  - Mikrofonzugang ist erforderlich und muss Ã¼ber eine sichere Verbindung per HTTPS erfolgen, damit diese Funktion funktioniert.

- ğŸ“¹ **VideogesprÃ¤chsfunktion**: Aktivieren Sie Videoanrufe mit unterstÃ¼tzten Vision-Modellen wie LlaVA und GPT-4o, um Ihrer Kommunikation eine visuelle Dimension zu verleihen.
  - Sowohl Kamera- als auch Mikrofonzugang sind erforderlich und mÃ¼ssen Ã¼ber eine sichere Verbindung per HTTPS erfolgen, damit diese Funktion funktioniert.

- ğŸ‘† **Tippen, um zu unterbrechen**: Beenden Sie die Sprachausgabe der KI wÃ¤hrend Sprachinteraktionen mit einer einfachen BerÃ¼hrung auf mobilen GerÃ¤ten, um die Kontrolle Ã¼ber die Interaktion nahtlos zu gestalten.

- ğŸ™ï¸ **Sprachunterbrechung**: Beenden Sie die Sprachausgabe der KI wÃ¤hrend Sprachinteraktionen mit Ihrer Stimme auf mobilen GerÃ¤ten, um die Kontrolle Ã¼ber die Interaktion nahtlos zu gestalten.

- ğŸ”Š **Konfigurierbarer Text-zu-Sprache-Endpunkt**: Passen Sie Ihr Text-zu-Sprache-Erlebnis mit konfigurierbaren OpenAI-kompatiblen Endpunkten zum Vorlesen von LLM-Antworten an.

- ğŸ”— **Direkter Anrufmodus-Zugang**: Aktivieren Sie den Anrufmodus direkt Ã¼ber eine URL, um mobilen GerÃ¤tenutzern eine praktische AbkÃ¼rzung bereitzustellen.

- âœ¨ **Anpassbare Text-zu-Sprache-Funktion**: Kontrollieren Sie, wie Nachrichteninhalte fÃ¼r Text-zu-Sprache (TTS)-Anfragen segmentiert werden, um flexible Sprachausgabeoptionen zu ermÃ¶glichen.

- ğŸ”Š **Azure-Sprachdienste-Integration**: UnterstÃ¼tzt Azure Sprachdienste fÃ¼r Text-zu-Sprache (TTS) und bietet den Nutzern eine breite Palette an Sprachsynthese-Optionen.

- ğŸšï¸ **Anpassbare Audiowiedergabe**: ErmÃ¶glicht Benutzern, die Wiedergabegeschwindigkeit des Audios in Call-Modus-Einstellungen nach ihren PrÃ¤ferenzen anzupassen, wodurch die Barrierefreiheit und Benutzerfreundlichkeit verbessert werden.

- ğŸµ **Umfassende AudiokompatibilitÃ¤t**: UnterstÃ¼tzung fÃ¼r eine breite Palette von Audiotranskriptionsformaten mit RAG, einschlieÃŸlich audio/x-m4a, um die KompatibilitÃ¤t mit Audioinhalten innerhalb der Plattform zu erweitern.

- ğŸ”Š **Audiokompression**: Experimentelle Audiokompression ermÃ¶glicht es, die 25 MB-Grenze fÃ¼r die Sprach-zu-Text-Verarbeitung von OpenAI zu umgehen und erweitert die MÃ¶glichkeiten fÃ¼r Audio-basierte Interaktionen.

- ğŸ—£ï¸ **Experimentelle SpeechT5 TTS**: GenieÃŸen Sie die lokale SpeechT5-UnterstÃ¼tzung fÃ¼r verbesserte Text-zu-Sprache-Funktionen.

---

### ğŸ Code-AusfÃ¼hrung

- ğŸš€ **Vielseitiges, UI-agnostisches, OpenAI-kompatibles Plugin-Framework**: Integrieren und passen Sie nahtlos [Open WebUI Pipelines](https://github.com/open-webui/pipelines) fÃ¼r effiziente Datenverarbeitung und Modellentwicklung an, um ultimative FlexibilitÃ¤t und Skalierbarkeit zu gewÃ¤hrleisten.

- ğŸ› ï¸ **Native Python-Funktionsaufrufe**: Nutzen Sie die Leistung von Python direkt innerhalb von Open WebUI mit nativen Funktionsaufrufen. Integrieren Sie benutzerdefinierten Code, um einzigartige Funktionen wie maÃŸgeschneiderte RAG-Pipelines, Werkzeuge fÃ¼r die Websuche und sogar agentenÃ¤hnliche Aktionen Ã¼ber einen eingebauten Code-Editor nahtlos zu entwickeln und in den Arbeitsbereich `Tools` und `Functions` zu integrieren.

- ğŸ **Python-Code-AusfÃ¼hrung**: FÃ¼hren Sie Python-Code lokal im Browser Ã¼ber Pyodide aus, mit UnterstÃ¼tzung fÃ¼r eine Reihe von Bibliotheken.

- ğŸŒŠ **Mermaid-Rendering**: Erstellen Sie visuell ansprechende Diagramme und Flussdiagramme direkt in Open WebUI mithilfe des [Mermaid Diagramming und Grafiktools](https://mermaid.js.org/intro/), das das Rendering von Mermaid-Syntax unterstÃ¼tzt.

- ğŸ”— **Iframe-UnterstÃ¼tzung**: ErmÃ¶glicht das direkte Rendern von HTML in Ihre Chat-OberflÃ¤che mit Funktionen und Tools.

---

### ğŸ”’ Integration und Sicherheit

- âœ¨ **UnterstÃ¼tzung fÃ¼r mehrere OpenAI-kompatible APIs**: Nahtlose Integration und Anpassung verschiedener OpenAI-kompatibler APIs, um die Vielseitigkeit Ihrer Chat-Interaktionen zu verbessern.

- ğŸ”‘ **Vereinfachte API-SchlÃ¼sselverwaltung**: Erstellen und verwalten Sie GeheimschlÃ¼ssel problemlos, um Open WebUI mit OpenAI-Bibliotheken zu nutzen und die Integration und Entwicklung zu vereinfachen.

- ğŸŒ **HTTP/S Proxy-UnterstÃ¼tzung**: Konfigurieren Sie Netzwerkeinstellungen einfach mit der Umgebungsvariable `http_proxy` oder `https_proxy`. Diese Variablen sollten, falls gesetzt, die URLs fÃ¼r HTTP- bzw. HTTPS-Proxies enthalten.

- ğŸŒğŸ”— **Externe Ollama-Server-KonnektivitÃ¤t**: Verbindet sich nahtlos mit einem extern gehosteten Ollama-Server unter einer anderen Adresse durch Konfiguration der Umgebungsvariable.

- ğŸ›¢ï¸ **Flexible Datenbankintegration**: Nahtlose Verbindung zu benutzerdefinierten Datenbanken, darunter SQLite, Postgres und mehrere Vektordatenbanken wie Milvus, mithilfe von Umgebungsvariablen fÃ¼r flexible und skalierbare Datenverwaltung.

- ğŸŒğŸ—£ï¸ **UnterstÃ¼tzung fÃ¼r externe Sprach-zu-Text-Dienste**: Die ErgÃ¤nzung externer Sprach-zu-Text-Dienste (`STT`) bietet erhÃ¶hte FlexibilitÃ¤t und ermÃ¶glicht es Nutzern, den bevorzugten Anbieter fÃ¼r nahtlose Interaktionen auszuwÃ¤hlen.

- ğŸŒ **Remote-ChromaDB-UnterstÃ¼tzung**: Erweitern Sie die MÃ¶glichkeiten Ihrer Datenbank durch Verbindung zu entfernten ChromaDB-Servern.

- ğŸ”€ **Lastenausgleich zwischen mehreren Ollama-Instanzen**: Verteilt Chat-Anfragen mÃ¼helos Ã¼ber mehrere Ollama-Instanzen fÃ¼r hÃ¶here Leistung und ZuverlÃ¤ssigkeit.

- ğŸš€ **Fortschrittlicher Lastenausgleich und ZuverlÃ¤ssigkeit**: Nutzen Sie verbesserte Lastenausgleichsfunktionen, stateless Instanzen mit vollstÃ¤ndiger Redis-UnterstÃ¼tzung und automatisches Websocket-Wiederverbinden, um eine bessere Leistung, ZuverlÃ¤ssigkeit und Skalierbarkeit in WebUI zu fÃ¶rdern und nahtlose und ununterbrochene Interaktionen Ã¼ber mehrere Instanzen zu gewÃ¤hrleisten.

- â˜ï¸ **Experimentelle S3-UnterstÃ¼tzung**: Aktivieren Sie stateless WebUI-Instanzen mit S3-UnterstÃ¼tzung fÃ¼r verbesserte Skalierbarkeit und BewÃ¤ltigung von hohen Arbeitslasten.

- ğŸ› ï¸ **OAuth-Verwaltung fÃ¼r Benutzergruppen**: Verfeinern Sie Kontrolle und Skalierbarkeit in kollaborativen Umgebungen mit Gruppenmanagement durch OAuth-Integration.

---

### ğŸ‘‘ Administration

- ğŸ‘‘ **Super-Admin-Zuweisung**: Weist automatisch dem ersten registrierten Benutzer die Rolle des Super-Admins zu, die unverÃ¤nderlich ist und von niemand anderem, auch nicht anderen Administratoren, geÃ¤ndert werden kann.

- ğŸ›¡ï¸ **Granulare Benutzerberechtigungen**: BeschrÃ¤nken Sie Benutzeraktionen und -zugriffe mit anpassbaren rollenbasierten Berechtigungen, um sicherzustellen, dass nur autorisierte Personen bestimmte Aufgaben ausfÃ¼hren kÃ¶nnen.

- ğŸ‘¥ **Multi-Benutzer-Verwaltung**: Intuitives Admin-Panel mit Seitennavigation ermÃ¶glicht es, mehrere Benutzer nahtlos zu verwalten und die Benutzerverwaltung zu vereinfachen.

- ğŸ”§ **Admin-Panel**: Das Benutzerverwaltungssystem ist darauf ausgelegt, die EinfÃ¼hrung und Verwaltung von Benutzern zu rationalisieren und bietet die MÃ¶glichkeit, Benutzer direkt oder in groÃŸer Zahl Ã¼ber CSV-Import hinzuzufÃ¼gen.

- ğŸ‘¥ **Aktive Benutzeranzeige**: Ãœberwachen Sie die Anzahl der aktiven Benutzer und welche Modelle von wem genutzt werden, um einzuschÃ¤tzen, wann die Leistung aufgrund einer hohen Benutzerzahl beeintrÃ¤chtigt werden kÃ¶nnte.

- ğŸ”’ **Standardrolle bei Registrierung**: Legen Sie die Standardrolle fÃ¼r neue Registrierungen auf `pending`, `user` oder `admin` fest, um FlexibilitÃ¤t bei der Verwaltung von Benutzerberechtigungen und Zugriffsebenen fÃ¼r neue Benutzer zu gewÃ¤hrleisten.

- ğŸ”’ **Neue Registrierungen verhindern**: Aktivieren Sie die Option, um neue Benutzerregistrierungen zu deaktivieren, den Zugriff auf die Plattform zu beschrÃ¤nken und eine feste Benutzeranzahl beizubehalten.

- ğŸ”’ **LÃ¶schung von Chats verhindern**: Administratoren kÃ¶nnen eine Einstellung aktivieren, die verhindert, dass Benutzer ihre Chat-Nachrichten lÃ¶schen, wodurch alle Chat-Nachrichten fÃ¼r PrÃ¼f- oder Compliance-Zwecke erhalten bleiben.

- ğŸ”— **Webhook-Integration**: Abonnieren Sie neue Benutzerregistrierungsereignisse Ã¼ber Webhooks (kompatibel mit `Discord`, `Google Chat`, `Slack` und `Microsoft Teams`) und erhalten Sie Echtzeitbenachrichtigungen sowie AutomatisierungsmÃ¶glichkeiten.

- ğŸ“£ **Konfigurierbare Benachrichtigungsbanner**: Administratoren kÃ¶nnen anpassbare Banner mit Persistenz in der config.json erstellen, wobei Optionen fÃ¼r Inhalt, Hintergrundfarbe (`info`, `warning`, `error` oder `success`) und SchlieÃŸbarkeit verfÃ¼gbar sind. Banner sind nur fÃ¼r angemeldete Benutzer sichtbar, um die Vertraulichkeit sensibler Informationen zu gewÃ¤hrleisten.

- ğŸ›¡ï¸ **Modell-Whitelist**: Verbessern Sie Sicherheit und Zugangskontrolle, indem Administratoren Modelle fÃ¼r Benutzer mit der Rolle `user` auf eine Whitelist setzen, sodass nur autorisierte Modelle genutzt werden kÃ¶nnen.

- ğŸ”‘ **Administrator-Kontrolle fÃ¼r Community-Sharing**: Administratoren kÃ¶nnen das Teilen in der Community fÃ¼r alle Benutzer Ã¼ber einen Umschalter im MenÃ¼ `Admin Panel` > `Settings` aktivieren oder deaktivieren. Mit diesem Umschalter kÃ¶nnen Administratoren ZugÃ¤nglichkeit und Datenschutz verwalten und so eine sichere Umgebung gewÃ¤hrleisten. Administratoren haben die MÃ¶glichkeit, die SchaltflÃ¤che `Share on Community` fÃ¼r alle Benutzer zu aktivieren oder zu deaktivieren, was ihnen erlaubt, die Teilnahme an und Zusammenarbeit mit der Community zu steuern.

- ğŸ“§ **VertrauenswÃ¼rdige E-Mail-Authentifizierung**: Authentifizieren Sie sich optional Ã¼ber einen vertrauenswÃ¼rdigen E-Mail-Header und fÃ¼gen Sie eine zusÃ¤tzliche Sicherheitsebene hinzu, um Ihre Open WebUI-Instanz zu schÃ¼tzen.

- ğŸ”’ **Backend-Reverse-Proxy-UnterstÃ¼tzung**: ErhÃ¶hen Sie die Sicherheit durch direkte Kommunikation zwischen dem Backend von Open WebUI und Ollama. Diese wichtige Funktion eliminiert die Notwendigkeit, Ollama im lokalen Netzwerk (LAN) freizugeben. Anfragen, die an die Route `/ollama/api` von Open WebUI gesendet werden, werden nahtlos vom Backend an Ollama weitergeleitet, was die allgemeine Systemsicherheit verbessert und zusÃ¤tzlichen Schutz bietet.

- ğŸ”’ **Authentifizierung**: Bitte beachten Sie, dass Open WebUI keine nativen fÃ¶derierten Authentifizierungsmethoden wie SSO, OAuth, SAML oder OIDC unterstÃ¼tzt. Es kann jedoch so konfiguriert werden, dass die Authentifizierung an einen authentifizierenden Reverse-Proxy delegiert wird, was effektiv ein Single-Sign-On (`SSO`)-Erlebnis ermÃ¶glicht. Diese Einrichtung ermÃ¶glicht es Ihnen, die Benutzerverwaltung und -authentifizierung zu zentralisieren, was Sicherheit und Benutzerfreundlichkeit erhÃ¶ht. Durch die Integration von Open WebUI mit einem authentifizierenden Reverse-Proxy kÃ¶nnen Sie bestehende Authentifizierungssysteme nutzen und den Benutzerzugriff auf Open WebUI vereinfachen. Weitere Informationen zur Konfiguration dieses Features finden Sie in der [Dokumentation zur fÃ¶derierten AuthentifizierungsunterstÃ¼tzung](https://docs.openwebui.com/features/sso).

- ğŸ”“ **Optionale Authentifizierung**: GenieÃŸen Sie die FlexibilitÃ¤t, die Authentifizierung zu deaktivieren, indem Sie `WEBUI_AUTH` auf `False` setzen. Dies ist eine ideale LÃ¶sung fÃ¼r Neuinstallationen ohne bestehende Benutzer oder kann fÃ¼r Demonstrationszwecke nÃ¼tzlich sein.

- ğŸš« **Erweiterte API-Sicherheit**: Blockieren Sie API-Benutzer basierend auf angepassten Modellenfiltern, um Sicherheit und Kontrolle Ã¼ber den API-Zugriff zu verbessern.

- â— **Administrator-Updates**: Sorgen Sie dafÃ¼r, dass Administratoren immer auf dem neuesten Stand bleiben, indem sie beim Anmelden sofort Ã¼ber Updates informiert werden, um sie Ã¼ber die neuesten Ã„nderungen und Systemstatus auf dem Laufenden zu halten.

- ğŸ‘¥ **Benutzergruppenverwaltung**: Erstellen und verwalten Sie Benutzergruppen fÃ¼r eine nahtlose Organisation und Kontrolle.

- ğŸ” **Gruppenbasierte Zugriffssteuerung**: Legen Sie detaillierte Zugriffsrechte fÃ¼r Modelle, Wissen, Eingabeaufforderungen und Tools basierend auf Benutzergruppen fest, um kontrollierte und sichere Umgebungen zu schaffen.

- ğŸ› ï¸ **Detaillierte Benutzerberechtigungen**: Verwalten Sie Arbeitsbereichsberechtigungen problemlos, einschlieÃŸlich Datei-Uploads, -LÃ¶schungen, -Bearbeitungen und temporÃ¤ren Chats sowie Modell-, Wissens-, Eingabeaufforderungs- und Toolerstellung.

- ğŸ”‘ **LDAP-Authentifizierung**: ErhÃ¶hen Sie Sicherheit und Skalierbarkeit mit LDAP-UnterstÃ¼tzung fÃ¼r die Benutzerverwaltung.

- ğŸŒ **Anpassbare OpenAI-Verbindungen**: GenieÃŸen Sie einen reibungslosen Betrieb mit benutzerdefinierten OpenAI-Setups, einschlieÃŸlich UnterstÃ¼tzung fÃ¼r PrÃ¤fix-IDs und expliziter Modell-ID-UnterstÃ¼tzung fÃ¼r APIs.

- ğŸ” **Ollama API-SchlÃ¼sselverwaltung**: Verwalten Sie Ollama-Anmeldeinformationen, einschlieÃŸlich PrÃ¤fix-ID-UnterstÃ¼tzung, fÃ¼r einen sicheren und effizienten Betrieb.

- ğŸ”„ **Verbindungsmanagement**: Aktivieren oder deaktivieren Sie einzelne OpenAI- und Ollama-Verbindungen ganz einfach nach Bedarf.

- ğŸ¨ **Intuitive Modell-Arbeitsbereiche**: Verwalten Sie Modelle fÃ¼r Benutzer und Gruppen mit einer neu gestalteten und benutzerfreundlichen OberflÃ¤che.

- ğŸ”‘ **API-SchlÃ¼ssel-Authentifizierung**: ErhÃ¶hen Sie die Sicherheit, indem Sie die API-SchlÃ¼ssel-Authentifizierung ganz einfach aktivieren oder deaktivieren.

- ğŸ”„ **Einheitliche ModellzurÃ¼cksetzung**: Setzen Sie alle Modelle in den Admin-Einstellungen mit einer Ein-Klick-Option zurÃ¼ck und entfernen Sie sie.

- ğŸ”“ **Flexibel kontrollierter Modellzugriff**: Umgehen Sie problemlos Modellzugriffskontrollen fÃ¼r Benutzerrollen, wenn nicht erforderlich, mithilfe der Umgebungsvariable BYPASS_MODEL_ACCESS_CONTROL, und vereinfachen Sie Workflows in vertrauenswÃ¼rdigen Umgebungen.

- ğŸ”’ **Konfigurierbare API-SchlÃ¼ssel-AuthentifizierungsbeschrÃ¤nkungen**: Konfigurieren Sie flexibel EndpunktbeschrÃ¤nkungen fÃ¼r die API-SchlÃ¼ssel-Authentifizierung, die jetzt standardmÃ¤ÃŸig deaktiviert sind, fÃ¼r eine reibungslosere Einrichtung in vertrauenswÃ¼rdigen Umgebungen.

---
