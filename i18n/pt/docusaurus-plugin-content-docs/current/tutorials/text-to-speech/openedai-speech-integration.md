---
sidebar_position: 2
title: "üó®Ô∏è Openedai-speech Usando Docker"
---

:::warning
Este tutorial √© uma contribui√ß√£o da comunidade e n√£o √© suportado pela equipe Open WebUI. Ele serve apenas como demonstra√ß√£o de como personalizar o Open WebUI para seu caso de uso espec√≠fico. Quer contribuir? Confira o tutorial de contribui√ß√£o.
:::

**Integrando `openedai-speech` ao Open WebUI usando Docker**
===========================================================

**O que √© `openedai-speech`?**
-----------------------------

:::info
[openedai-speech](https://github.com/matatonic/openedai-speech) √© um servidor de texto para fala compat√≠vel com a API de √°udio/fala do OpenAI.

Ele serve o endpoint `/v1/audio/speech` e oferece uma experi√™ncia de texto para fala gratuita e privada com capacidades de clonagem de voz personalizada. Este servi√ßo n√£o possui qualquer afilia√ß√£o com OpenAI e n√£o requer uma chave de API do OpenAI.
:::

**Requisitos**
--------------

* Docker instalado em seu sistema
* Open WebUI executando em um cont√™iner Docker
* Conhecimento b√°sico sobre Docker e Docker Compose

**Op√ß√£o 1: Usando Docker Compose**
----------------------------------

**Etapa 1: Crie uma nova pasta para o servi√ßo `openedai-speech`**
----------------------------------------------------------------

Crie uma nova pasta, por exemplo, `openedai-speech-service`, para armazenar os arquivos `docker-compose.yml` e `speech.env`.

**Etapa 2: Clone o reposit√≥rio `openedai-speech` do GitHub**
----------------------------------------------------------

```bash
git clone https://github.com/matatonic/openedai-speech.git
```

Isso baixar√° o reposit√≥rio `openedai-speech` para sua m√°quina local, incluindo os arquivos Docker Compose (`docker-compose.yml`, `docker-compose.min.yml` e `docker-compose.rocm.yml`) e outros arquivos necess√°rios.

**Etapa 3: Renomeie o arquivo `sample.env` para `speech.env` (Personalize se necess√°rio)**
---------------------------------------------------------------------------------------

Na pasta do reposit√≥rio `openedai-speech`, crie um novo arquivo chamado `speech.env` com o seguinte conte√∫do:

```yaml
TTS_HOME=voices
HF_HOME=voices
#PRELOAD_MODEL=xtts
#PRELOAD_MODEL=xtts_v2.0.2
#PRELOAD_MODEL=parler-tts/parler_tts_mini_v0.1
#EXTRA_ARGS=--log-level DEBUG --unload-timer 300
#USE_ROCM=1
```

**Etapa 4: Escolha um arquivo Docker Compose**
--------------------------------------------

Voc√™ pode usar qualquer um dos seguintes arquivos Docker Compose:

* [docker-compose.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.yml): Este arquivo usa a imagem `ghcr.io/matatonic/openedai-speech` e √© constru√≠do a partir do [Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile).
* [docker-compose.min.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.min.yml): Este arquivo usa a imagem `ghcr.io/matatonic/openedai-speech-min` e √© constru√≠do a partir do [Dockerfile.min](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile.min). Esta imagem √© uma vers√£o m√≠nima que inclui apenas suporte ao Piper e n√£o requer uma GPU.
* [docker-compose.rocm.yml](https://github.com/matatonic/openedai-speech/blob/main/docker-compose.rocm.yml): Este arquivo usa a imagem `ghcr.io/matatonic/openedai-speech-rocm` e √© constru√≠do a partir do [Dockerfile](https://github.com/matatonic/openedai-speech/blob/main/Dockerfile) com suporte ao ROCm.

**Etapa 4: Construa a imagem Docker escolhida**
--------------------------------------------

Antes de executar o arquivo Docker Compose, voc√™ precisa construir a imagem Docker:

* **GPU Nvidia (suporte CUDA)**:

```bash
docker build -t ghcr.io/matatonic/openedai-speech .
```

* **GPU AMD (suporte ROCm)**:

```bash
docker build -f Dockerfile --build-arg USE_ROCM=1 -t ghcr.io/matatonic/openedai-speech-rocm .
```

* **Somente CPU, sem GPU (apenas Piper)**:

```bash
docker build -f Dockerfile.min -t ghcr.io/matatonic/openedai-speech-min .
```

**Etapa 5: Execute o comando correto `docker compose up -d`**
-----------------------------------------------------------

* **GPU Nvidia (suporte CUDA)**: Execute o seguinte comando para iniciar o servi√ßo `openedai-speech` em modo desconectado:

```bash
docker compose up -d
```

* **GPU AMD (suporte ROCm)**: Execute o seguinte comando para iniciar o servi√ßo `openedai-speech` em modo desconectado:

```bash
docker compose -f docker-compose.rocm.yml up -d
```

* **ARM64 (Apple M-series, Raspberry Pi)**: XTTS tem suporte apenas para CPU aqui e ser√° muito lento. Voc√™ pode usar a imagem Nvidia para XTTS com CPU (lento), ou usar a imagem apenas Piper (recomendado):

```bash
docker compose -f docker-compose.min.yml up -d
```

* **Somente CPU, sem GPU (apenas Piper)**: Para uma imagem Docker m√≠nima com apenas suporte Piper (< 1GB contra 8GB):

```bash
docker compose -f docker-compose.min.yml up -d
```

Isso iniciar√° o servi√ßo `openedai-speech` em modo desconectado.

**Op√ß√£o 2: Usando comandos Docker Run**
-------------------------------------


Voc√™ tamb√©m pode usar os seguintes comandos Docker run para iniciar o servi√ßo `openedai-speech` no modo desanexado:

* **Nvidia GPU (CUDA)**: Execute o seguinte comando para construir e iniciar o servi√ßo `openedai-speech`:

```bash
docker build -t ghcr.io/matatonic/openedai-speech .
docker run -d --gpus=all -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech
```

* **ROCm (AMD GPU)**: Execute o seguinte comando para construir e iniciar o servi√ßo `openedai-speech`:

> Para habilitar o suporte ao ROCm, descomente a linha `#USE_ROCM=1` no arquivo `speech.env`.

```bash
docker build -f Dockerfile --build-arg USE_ROCM=1 -t ghcr.io/matatonic/openedai-speech-rocm .
docker run -d --privileged --init --name openedai-speech -p 8000:8000 -v voices:/app/voices -v config:/app/config ghcr.io/matatonic/openedai-speech-rocm
```

* **Somente CPU, Sem GPU (Apenas Piper)**: Execute o seguinte comando para construir e iniciar o servi√ßo `openedai-speech`:

```bash
docker build -f Dockerfile.min -t ghcr.io/matatonic/openedai-speech-min .
docker run -d -p 8000:8000 -v voices:/app/voices -v config:/app/config --name openedai-speech ghcr.io/matatonic/openedai-speech-min
```

**Passo 6: Configurando o Open WebUI para usar `openedai-speech` para TTS**
---------------------------------------------------------

![openedai-tts](https://github.com/silentoplayz/docs/assets/50341825/ea08494f-2ebf-41a2-bb0f-9b48dd3ace79)

Abra as configura√ß√µes do Open WebUI e navegue para as Configura√ß√µes TTS em **Painel de Administrador > Configura√ß√µes > √Åudio**. Adicione a seguinte configura√ß√£o:

* **URL Base da API**: `http://host.docker.internal:8000/v1`
* **Chave da API**: `sk-111111111` (Observe que esta √© uma chave de API fict√≠cia, pois `openedai-speech` n√£o requer uma chave de API. Voc√™ pode usar qualquer valor para este campo, desde que esteja preenchido.)

**Passo 7: Escolha uma voz**
--------------------------

Na op√ß√£o `TTS Voice` dentro do mesmo menu de configura√ß√µes de √°udio no painel de administra√ß√£o, voc√™ pode configurar o `TTS Model` a ser usado a partir das op√ß√µes abaixo que o `openedai-speech` suporta. As vozes desses modelos s√£o otimizadas para o idioma ingl√™s.

* `tts-1` ou `tts-1-hd`: `alloy`, `echo`, `echo-alt`, `fable`, `onyx`, `nova` e `shimmer` (`tts-1-hd` √© configur√°vel; usa amostras do OpenAI por padr√£o)

**Passo 8: Pressione `Salvar` para aplicar as altera√ß√µes e come√ßar a desfrutar de vozes com som natural**
--------------------------------------------------------------------------------------------

Pressione o bot√£o `Salvar` para aplicar as altera√ß√µes nas configura√ß√µes do Open WebUI. Atualize a p√°gina para que a altera√ß√£o tenha efeito total e aproveite a integra√ß√£o do `openedai-speech` no Open WebUI para ler respostas em texto em voz natural.

**Detalhes do Modelo:**
------------------

`openedai-speech` suporta v√°rios modelos de convers√£o de texto em fala, cada um com suas pr√≥prias for√ßas e requisitos. Os seguintes modelos est√£o dispon√≠veis:

* **Piper TTS** (muito r√°pido, funciona em CPU): Use suas pr√≥prias [vozes Piper](https://rhasspy.github.io/piper-samples/) atrav√©s do arquivo de configura√ß√£o `voice_to_speaker.yaml`. Este modelo √© ideal para aplica√ß√µes que requerem baixa lat√™ncia e alto desempenho. Piper TTS tamb√©m suporta vozes [multil√≠ngues](https://github.com/matatonic/openedai-speech#multilingual).
* **Coqui AI/TTS XTTS v2** (r√°pido, mas requer cerca de 4GB de VRAM GPU e Nvidia GPU com CUDA): Este modelo usa a tecnologia de clonagem de voz XTTS v2 da Coqui AI para gerar vozes de alta qualidade. Embora exija uma GPU mais potente, oferece excelente desempenho e √°udio de alta qualidade. Coqui tamb√©m suporta vozes [multil√≠ngues](https://github.com/matatonic/openedai-speech#multilingual).
* **Suporte Beta Parler-TTS** (experimental, mais lento): Este modelo usa a estrutura Parler-TTS para gerar vozes. Embora esteja atualmente em beta, permite descrever caracter√≠sticas muito b√°sicas da voz do locutor. A voz exata ser√° ligeiramente diferente a cada gera√ß√£o, mas deve ser semelhante √† descri√ß√£o fornecida do locutor. Para inspira√ß√£o sobre como descrever vozes, consulte [Descri√ß√£o de Texto para Fala](https://www.text-description-to-speech.com/).

**Solu√ß√£o de Problemas**
-------------------

Se voc√™ encontrar problemas ao integrar `openedai-speech` com Open WebUI, siga estas etapas de solu√ß√£o de problemas:

* **Verificar o servi√ßo `openedai-speech`**: Certifique-se de que o servi√ßo `openedai-speech` esteja em execu√ß√£o e a porta especificada no arquivo docker-compose.yml esteja exposta.
* **Verifique o acesso ao host.docker.internal**: Certifique-se de que o nome de host `host.docker.internal` pode ser resolvido de dentro do cont√™iner do Open WebUI. Isso √© necess√°rio porque o `openedai-speech` est√° exposto via `localhost` no seu PC, mas o `open-webui` normalmente n√£o pode acess√°-lo de dentro de seu cont√™iner. Voc√™ pode adicionar um volume ao arquivo docker-compose.yml para montar um arquivo do host no cont√™iner, por exemplo, para um diret√≥rio que ser√° servido pelo openedai-speech.
* **Revisar a configura√ß√£o da chave da API**: Certifique-se de que a chave da API esteja configurada como um valor fict√≠cio ou efetivamente desligada, pois o `openedai-speech` n√£o requer uma chave da API.
* **Verificar a configura√ß√£o de voz**: Confirme se a voz que voc√™ est√° tentando usar para TTS existe no seu arquivo `voice_to_speaker.yaml` e se os arquivos correspondentes (por exemplo, arquivos XML de voz) est√£o presentes no diret√≥rio correto.
* **Verificar os caminhos dos modelos de voz**: Se estiver enfrentando problemas ao carregar modelos de voz, verifique se os caminhos no seu arquivo `voice_to_speaker.yaml` correspondem aos locais reais de seus modelos de voz.

**Dicas Adicionais de Solu√ß√£o de Problemas**
------------------------------------------

* Verifique os logs do `openedai-speech` para erros ou avisos que possam indicar onde est√° o problema.
* Certifique-se de que o arquivo `docker-compose.yml` est√° corretamente configurado para o seu ambiente.
* Se ainda estiver enfrentando problemas, tente reiniciar o servi√ßo `openedai-speech` ou todo o ambiente Docker.
* Se o problema persistir, consulte o reposit√≥rio GitHub do `openedai-speech` ou busque ajuda em um f√≥rum da comunidade relevante.

**FAQ**
-------

**Como posso controlar a varia√ß√£o emocional do √°udio gerado?**

N√£o h√° um mecanismo direto para controlar a sa√≠da emocional do √°udio gerado. Certos fatores, como capitaliza√ß√£o ou gram√°tica, podem afetar o √°udio de sa√≠da, mas os testes internos apresentaram resultados variados.

**Onde os arquivos de voz s√£o armazenados? E o arquivo de configura√ß√£o?**

Os arquivos de configura√ß√£o, que definem as vozes dispon√≠veis e suas propriedades, s√£o armazenados no volume de configura√ß√£o. Especificamente, as vozes padr√£o s√£o definidas em `voice_to_speaker.default.yaml`.

**Recursos Adicionais**
-----------------------

Para mais informa√ß√µes sobre como configurar o Open WebUI para usar o `openedai-speech`, incluindo como definir vari√°veis de ambiente, veja a [documenta√ß√£o do Open WebUI](https://docs.openwebui.com/getting-started/env-configuration#text-to-speech).

Para mais informa√ß√µes sobre o `openedai-speech`, visite o [reposit√≥rio do GitHub](https://github.com/matatonic/openedai-speech).

**Como adicionar mais vozes ao openedai-speech:**
[Custom-Voices-HowTo](https://github.com/matatonic/openedai-speech?tab=readme-ov-file#custom-voices-howto)

:::note
Voc√™ pode alterar o n√∫mero da porta no arquivo `docker-compose.yml` para qualquer porta aberta e utiliz√°vel, mas certifique-se de atualizar a **Base URL da API** nas configura√ß√µes de √°udio do Open WebUI Admin de acordo.
:::
