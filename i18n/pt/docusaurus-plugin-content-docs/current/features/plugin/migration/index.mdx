---
sidebar_position: 4
title: "ğŸšš Migrando Ferramentas & FunÃ§Ãµes: 0.4 para 0.5"
---

# ğŸšš Guia de MigraÃ§Ã£o: Open WebUI 0.4 para 0.5

Bem-vindo ao guia de migraÃ§Ã£o do Open WebUI 0.5! Se vocÃª estÃ¡ trabalhando em projetos existentes ou construindo novos, este guia irÃ¡ te mostrar as mudanÃ§as principais da **versÃ£o 0.4 para 0.5** e fornecer um roteiro fÃ¡cil de seguir para atualizar suas funÃ§Ãµes. Vamos tornar essa transiÃ§Ã£o o mais tranquila possÃ­vel! ğŸ˜Š

---

## ğŸ§ O que Mudou e Por quÃª?

Com o Open WebUI 0.5, reformulamos a arquitetura para tornar o projeto **mais simples, mais unificado e escalÃ¡vel**. Aqui estÃ¡ o panorama geral:

- **Arquitetura Antiga:** ğŸ¯ Anteriormente, o Open WebUI era baseado em uma **arquitetura de sub aplicativos** onde cada aplicativo (por exemplo, `ollama`, `openai`) era uma aplicaÃ§Ã£o FastAPI separada. Isso gerava fragmentaÃ§Ã£o e complexidade extra ao gerenciar aplicativos.
- **Nova Arquitetura:** ğŸš€ Com a versÃ£o 0.5, passamos para um **Ãºnico aplicativo FastAPI** com mÃºltiplos **roteadores**. Isso significa melhor organizaÃ§Ã£o, fluxo centralizado e reduÃ§Ã£o de redundÃ¢ncia.

### MudanÃ§as Principais:
Aqui estÃ¡ uma visÃ£o geral do que mudou:
1. **Os aplicativos foram movidos para Roteadores.**
   - Antes: `open_webui.apps`
   - Agora: `open_webui.routers`

2. **Estrutura principal do aplicativo simplificada.**
   - O antigo `open_webui.apps.webui` foi transformado em `open_webui.main`, tornando-se o ponto de entrada central do projeto.

3. **Endpoint de API Unificado**
   - Open WebUI 0.5 introduz uma **funÃ§Ã£o unificada**, `chat_completion`, em `open_webui.main`, substituindo funÃ§Ãµes separadas para modelos como `ollama` e `openai`. Isso oferece uma experiÃªncia de API consistente e simplificada. No entanto, o **sucessor direto** dessas funÃ§Ãµes individuais Ã© `generate_chat_completion` de `open_webui.utils.chat`. Se vocÃª prefere um pedido POST leve sem lidar com anÃ¡lises adicionais (por exemplo, arquivos, ferramentas ou outros), essa funÃ§Ã£o utilitÃ¡ria Ã© provavelmente o que vocÃª deseja.

#### Exemplo:
```python
# Fluxo completo de API com anÃ¡lise (nova funÃ§Ã£o):
from open_webui.main import chat_completion

# Pedido POST leve e direto (sucessor direto):
from open_webui.utils.chat import generate_chat_completion
```

Escolha a abordagem que melhor se encaixa no seu caso de uso!

4. **Assinaturas de FunÃ§Ã£o Atualizadas.**
   - As assinaturas de funÃ§Ã£o agora seguem um novo formato, exigindo um objeto `request`.
   - O objeto `request` pode ser obtido utilizando o parÃ¢metro `__request__` na assinatura da funÃ§Ã£o. Abaixo estÃ¡ um exemplo:

```python
class Pipe:
    def __init__(self):
        pass

    async def pipe(
        self,
        body: dict,
        __user__: dict,
        __request__: Request, # Novo parÃ¢metro
    ) -> str:
        # Escreva sua funÃ§Ã£o aqui
```

ğŸ“Œ **Por que fizemos essas mudanÃ§as?**
- Para simplificar a base de cÃ³digo, tornando-a mais fÃ¡cil de estender e manter.
- Para unificar APIs proporcionando uma experiÃªncia de desenvolvimento mais simplificada.
- Para melhorar o desempenho consolidando elementos redundantes.

---

## âœ… Guia de MigraÃ§Ã£o Passo a Passo

Siga este guia para atualizar seu projeto sem complicaÃ§Ãµes.

---

### ğŸ”„ 1. Transferindo de `apps` para `routers` 

Todos os aplicativos foram renomeados e realocados sob `open_webui.routers`. Isso afeta os imports na base de cÃ³digo.

MudanÃ§as rÃ¡pidas nos caminhos de importaÃ§Ã£o:

| **Caminho Antigo**               | **Novo Caminho**                 |
|-----------------------------------|-----------------------------------|
| `open_webui.apps.ollama`          | `open_webui.routers.ollama`       |
| `open_webui.apps.openai`          | `open_webui.routers.openai`       |
| `open_webui.apps.audio`           | `open_webui.routers.audio`        |
| `open_webui.apps.retrieval`       | `open_webui.routers.retrieval`    |
| `open_webui.apps.webui`           | `open_webui.main`                 |


### ğŸ“œ Um Exemplo Importante

Para esclarecer o caso especial do aplicativo principal (`webui`), aqui estÃ¡ uma regra simples: 

- **Estava em `webui`?** Agora estÃ¡ na raiz do projeto ou em `open_webui.main`. 
- Por exemplo: 
    - **Antes (0.4):** 
      ```python  
      from open_webui.apps.webui.models import SomeModel  
      ```  
    - **Depois (0.5):**  
      ```python  
      from open_webui.models import SomeModel  
      ```  

Em geral, **basta substituir `open_webui.apps` por `open_webui.routers`â€”exceto por `webui`, que agora Ã© `open_webui.main`!**


---

### ğŸ‘©â€ğŸ’» 2. Atualizando DeclaraÃ§Ãµes de ImportaÃ§Ã£o

Vamos ver como essa atualizaÃ§Ã£o se parece no seu cÃ³digo:

#### Antes:
```python
from open_webui.apps.ollama import main as ollama
from open_webui.apps.openai import main as openai
```

#### Depois:
```python
# ImportaÃ§Ãµes de roteadores separados
from open_webui.routers.ollama import generate_chat_completion
from open_webui.routers.openai import generate_chat_completion

# Ou use o endpoint unificado
from open_webui.main import chat_completion
```

**ğŸ’¡ Dica Pro:** Priorize o endpoint unificado (`chat_completion`) para simplicidade e compatibilidade futura.

### ğŸ“ **Nota Adicional: Escolhendo Entre `main.chat_completion` e `utils.chat.generate_chat_completion`**

Dependendo do seu caso de uso, vocÃª pode escolher entre:

1. **`open_webui.main.chat_completion`:**
    - Simula fazer uma solicitaÃ§Ã£o POST para `/api/chat/completions`.
    - Processa arquivos, ferramentas e outras tarefas diversas.
    - Ideal para quando vocÃª deseja que o fluxo completo da API seja tratado automaticamente.

2. **`open_webui.utils.chat.generate_chat_completion`:**
    - Faz diretamente uma solicitaÃ§Ã£o POST sem lidar com parsing extra ou tarefas adicionais.
    - Este Ã© o **sucessor direto** das funÃ§Ãµes anteriores `main.generate_chat_completions`, `ollama.generate_chat_completion` e `openai.generate_chat_completion` no Open WebUI 0.4.
    - Melhor para cenÃ¡rios simplificados e mais leves.

#### Exemplo:
```python
# Use isto para o fluxo completo da API com parsing:
from open_webui.main import chat_completion

# Use isto para uma solicitaÃ§Ã£o POST reduzida e direta:
from open_webui.utils.chat import generate_chat_completion
```

---

### ğŸ“‹ 3. Adaptando-se Ã s FunÃ§Ãµes Atualizadas

NÃ³s atualizamos os **assinaturas de funÃ§Ãµes** para melhor se adequar Ã  nova arquitetura. Se vocÃª estiver procurando uma substituiÃ§Ã£o direta, comece com a funÃ§Ã£o utilitÃ¡ria leve `generate_chat_completion` de `open_webui.utils.chat`. Para o fluxo completo da API, use a nova funÃ§Ã£o unificada `chat_completion` em `open_webui.main`.

#### MudanÃ§as na Assinatura de FunÃ§Ãµes:

| **Antigo**                                 | **Sucessor Direto (Novo)**             | **OpÃ§Ã£o Unificada (Novo)**               |
|-----------------------------------------|-----------------------------------------|-----------------------------------------|
| `openai.generate_chat_completion(form_data: dict, user: UserModel)` | `generate_chat_completion(request: Request, form_data: dict, user: UserModel)` | `chat_completion(request: Request, form_data: dict, user: UserModel)` |

- **Sucessor Direto (`generate_chat_completion`)**: Um substituto leve, 1:1 para os mÃ©todos anteriores do `ollama`/`openai`.  
- **OpÃ§Ã£o Unificada (`chat_completion`)**: Use isto para o fluxo completo da API, incluindo parsing de arquivos e funcionalidade adicional.

#### Exemplo:

Se vocÃª estiver usando `chat_completion`, veja como sua funÃ§Ã£o deve parecer agora:

### ğŸ› ï¸ Como Refatorar Sua FunÃ§Ã£o Personalizada
Vamos reescrever uma funÃ§Ã£o de exemplo para corresponder Ã  nova estrutura:

#### Antes (0.4):
```python
from pydantic import BaseModel
from open_webui.apps.ollama import generate_chat_completion

class User(BaseModel):
    id: str
    email: str
    name: str
    role: str

class Pipe:
    def __init__(self):
        pass

    async def pipe(self, body: dict, __user__: dict) -> str:
        # Chama o endpoint do OpenAI
        user = User(**__user__)
        body["model"] = "llama3.2:latest"
        return await ollama.generate_chat_completion(body, user)
```

#### Depois (0.5):
```python
from pydantic import BaseModel
from fastapi import Request

from open_webui.utils.chat import generate_chat_completion


class User(BaseModel):
    id: str
    email: str
    name: str
    role: str


class Pipe:
    def __init__(self):
        pass

    async def pipe(
        self,
        body: dict,
        __user__: dict,
        __request__: Request,
    ) -> str:
        # Utiliza o endpoint unificado com assinatura atualizada
        user = User(**__user__)
        body["model"] = "llama3.2:latest"
        return await generate_chat_completion(__request__, body, user)
```

### Notas Importantes:
- VocÃª deve passar um objeto `Request` (`__request__`) na nova assinatura da funÃ§Ã£o.
- Outros parÃ¢metros opcionais (como `__user__` e `__event_emitter__`) garantem flexibilidade para casos de uso mais complexos.

---

### ğŸŒŸ 4. Resumo: Conceitos-Chave em Termos Simples

Aqui estÃ¡ um resumo rÃ¡pido para lembrar:
- **Apps para Routers:** Atualize todas as importaÃ§Ãµes de `open_webui.apps` â¡ï¸ `open_webui.routers`.
- **Endpoint Unificado:** Use `open_webui.main.chat_completion` para simplicidade se `ollama` e `openai` estiverem envolvidos.
- **Adapte as Assinaturas das FunÃ§Ãµes:** Certifique-se de que suas funÃ§Ãµes passem o objeto `request` necessÃ¡rio.

---

## ğŸ‰ ParabÃ©ns! VocÃª estÃ¡ Pronto!

Ã‰ isso! VocÃª migrou com sucesso de **Open WebUI 0.4 para 0.5**. Ao refatorar suas importaÃ§Ãµes, usar o endpoint unificado e atualizar as assinaturas das funÃ§Ãµes, vocÃª estarÃ¡ totalmente preparado para aproveitar os novos recursos e melhorias na versÃ£o 0.5.

---

ğŸ’¬ **DÃºvidas ou Feedback?**
Se vocÃª encontrar algum problema ou tiver sugestÃµes, sinta-se Ã  vontade para abrir um [issue no GitHub](https://github.com/open-webui/open-webui) ou perguntar nos fÃ³runs da comunidade!

Feliz codificaÃ§Ã£o! âœ¨