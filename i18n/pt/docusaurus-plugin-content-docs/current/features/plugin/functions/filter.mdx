---
sidebar_position: 2
title: "ğŸª„ FunÃ§Ã£o de Filtro"
---

# ğŸª„ FunÃ§Ã£o de Filtro: Modifique Entradas e SaÃ­das

Bem-vindo ao guia abrangente sobre FunÃ§Ãµes de Filtro no Open WebUI! Os filtros sÃ£o um sistema de **plugin** flexÃ­vel e poderoso para modificar dados *antes de serem enviados ao Modelo de Linguagem Grande (LLM)* (entrada) ou *depois de serem retornados pelo LLM* (saÃ­da). Quer vocÃª esteja transformando entradas para obter melhor contexto ou limpando saÃ­das para melhorar a legibilidade, as **FunÃ§Ãµes de Filtro** permitem que vocÃª faÃ§a tudo.

Este guia detalharÃ¡ **o que sÃ£o os Filtros**, como funcionam, sua estrutura e tudo que vocÃª precisa saber para construir filtros poderosos e fÃ¡ceis de usar. Vamos explorar, e nÃ£o se preocupeâ€”eu utilizarei metÃ¡foras, exemplos e dicas para tornar tudo muito claro! ğŸŒŸ

---

## ğŸŒŠ O que sÃ£o Filtros no Open WebUI?

Imagine o Open WebUI como um **fluxo de Ã¡gua** passando por tubulaÃ§Ãµes:

- **Entradas do usuÃ¡rio** e **saÃ­das do LLM** sÃ£o a Ã¡gua.
- **Filtros** sÃ£o as **etapas de tratamento da Ã¡gua** que limpam, modificam e adaptam a Ã¡gua antes de chegar ao destino final.

Os filtros ficam no meio do fluxoâ€”como pontos de controleâ€”onde vocÃª decide o que precisa ser ajustado.

Aqui estÃ¡ um resumo rÃ¡pido do que os Filtros fazem:

1. **Modificar Entradas do UsuÃ¡rio (FunÃ§Ã£o de Entrada)**: Ajuste os dados de entrada antes que cheguem ao modelo de IA. Aqui vocÃª pode aprimorar a clareza, adicionar contexto, sanitizar texto ou reformular mensagens para atender a requisitos especÃ­ficos.
2. **Interceptar SaÃ­das do Modelo (FunÃ§Ã£o de Fluxo)**: Capture e ajuste as respostas do modelo de IA **enquanto sÃ£o geradas** pelo modelo. Isso Ã© Ãºtil para modificaÃ§Ãµes em tempo real, como filtrar informaÃ§Ãµes sensÃ­veis ou formatar a saÃ­da para melhor legibilidade.
3. **Modificar SaÃ­das do Modelo (FunÃ§Ã£o de SaÃ­da)**: Ajustar a resposta do modelo de IA **depois de processada**, antes de mostrÃ¡-la ao usuÃ¡rio. Isso pode ajudar a refinar, registrar ou adaptar os dados para uma experiÃªncia de usuÃ¡rio mais limpa.

> **Conceito Chave:** Os filtros nÃ£o sÃ£o modelos independentes, mas ferramentas que aprimoram ou transformam os dados que trafegam *para* e *de* modelos.

Os filtros sÃ£o como **tradutores ou editores** no fluxo de trabalho da IA: vocÃª pode interceptar e alterar a conversa sem interromper o fluxo.

---

## ğŸ—ºï¸ Estrutura de uma FunÃ§Ã£o de Filtro: O Esqueleto

Vamos comeÃ§ar com a representaÃ§Ã£o mais simples de uma FunÃ§Ã£o de Filtro. NÃ£o se preocupe se algumas partes parecerem tÃ©cnicas no comeÃ§oâ€”vamos detalhar tudo passo a passo!

### ğŸ¦´ Esqueleto BÃ¡sico de um Filtro

```python
from pydantic import BaseModel
from typing import Optional

class Filter:
    # VÃ¡lvulas: OpÃ§Ãµes de configuraÃ§Ã£o para o filtro
    class Valves(BaseModel):
        pass

    def __init__(self):
        # Inicializar vÃ¡lvulas (configuraÃ§Ã£o opcional para o Filtro)
        self.valves = self.Valves()

    def inlet(self, body: dict) -> dict:
        # Aqui vocÃª manipula entradas do usuÃ¡rio.
        print(f"inlet chamado: {body}")
        return body

    def stream(self, event: dict) -> dict:
        # Aqui vocÃª modifica pedaÃ§os transmitidos da saÃ­da do modelo.
        print(f"evento de fluxo: {event}")
        return event

    def outlet(self, body: dict) -> None:
        # Aqui vocÃª manipula saÃ­das do modelo.
        print(f"outlet chamado: {body}")
```

---

### ğŸ†• ğŸ§² Exemplo de Filtro com AlternÃ¢ncia: Adicionando Interatividade e Ãcones (Novo no Open WebUI 0.6.10)

Os filtros podem fazer mais do que simplesmente modificar textoâ€”eles podem expor alternÃ¢ncias de interface e exibir Ã­cones personalizados. Por exemplo, vocÃª pode querer um filtro que possa ser ligado/desligado com um botÃ£o de interface do usuÃ¡rio e exiba um Ã­cone especial na interface de entrada de mensagens do Open WebUI.

Aqui estÃ¡ como vocÃª poderia criar um filtro com alternÃ¢ncia:

```python
from pydantic import BaseModel, Field
from typing import Optional

class Filter:
    class Valves(BaseModel):
        pass

    def __init__(self):
        self.valves = self.Valves()
        self.toggle = True # IMPORTANTE: Isto cria uma interface de alternÃ¢ncia no Open WebUI
        # DICA: Use um URI de Dados SVG!
        self.icon = """data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGZpbGw9Im5vbmUiIHZpZXdCb3g9IjAgMCAyNCAyNCIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZT0iY3VycmVudENvbG9yIiBjbGFzcz0ic2l6ZS02Ij4KICA8cGF0aCBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGQ9Ik0xMiAxOHYtNS4yNW0wIDBhNi4wMSA2LjAxIDAgMCAwIDEuNS0uMTg5bS0xLjUuMTg5YTYuMDEgNi4wMSAwIDAgMS0xLjUtLjE4OW0zLjc1IDcuNDc4YTEyLjA2IDEyLjA2IDAgMCAxLTQuNSAwbTMuNzUgMi4zODNhMTQuNDA2IDE0LjQwNiAwIDAgMS0zIDBNMTQuMjUgMTh2LS4xOTJjMC0uOTgzLjY1OC0xLjgyMyAxLjUwOC0yLjMxNmE3LjUgNy41IDAgMSAwLTcuNTE3IDBjLjg1LjQ5MyAxLjUwOSAxLjMzMyAxLjUwOSAyLjMxNlYxOCIgLz4KPC9zdmc+Cg=="""
        pass

    async def inlet(
        self, body: dict, __event_emitter__, __user__: Optional[dict] = None
    ) -> dict:
        await __event_emitter__(
            {
                "type": "status",
                "data": {
                    "description": "Alternado!",
                    "done": True
                    "hidden": Falso,
                },
            }
        )
        retornar corpo
```

#### ğŸ–¼ï¸ O que estÃ¡ acontecendo?
- **toggle = True** cria uma interface de switch no Open WebUIâ€”os usuÃ¡rios podem ativar ou desativar manualmente o filtro em tempo real.
- **Ã­cone** (com um Data URI) aparecerÃ¡ como uma pequena imagem ao lado do nome do filtro. VocÃª pode usar qualquer SVG contanto que esteja codificado como Data URI!
- **A funÃ§Ã£o `inlet`** utiliza o argumento especial `__event_emitter__` para transmitir feedback/status Ã  interface de usuÃ¡rio, como um pequeno aviso/notificaÃ§Ã£o que diz "Alternado!"

![Toggle Filter](/images/features/plugin/functions/toggle-filter.png)

VocÃª pode usar esses mecanismos para tornar seus filtros dinÃ¢micos, interativos e visualmente Ãºnicos dentro do ecossistema de plugins do Open WebUI.

---

### ğŸ¯ Componentes-chave explicados

#### 1ï¸âƒ£ **Classe `Valves` (ConfiguraÃ§Ãµes Opcionais)**

Considere **Valves** como os botÃµes e controles deslizantes para seu filtro. Se vocÃª quiser oferecer aos usuÃ¡rios opÃ§Ãµes configurÃ¡veis para ajustar o comportamento do seu filtro, defina essas aqui.

```python
class Valves(BaseModel):
    OPTION_NAME: str = "Valor PadrÃ£o"
```

Por exemplo:  
Se vocÃª estiver criando um filtro que converte respostas em letras maiÃºsculas, pode permitir aos usuÃ¡rios configurar se cada saÃ­da serÃ¡ totalmente capitalizada por meio de uma vÃ¡lvula como `TRANSFORM_UPPERCASE: bool = True/False`.

---

#### 2ï¸âƒ£ **FunÃ§Ã£o `inlet` (PrÃ©-processamento de Entrada)**


A funÃ§Ã£o `inlet` Ã© como **preparar comida antes de cozinhar**. Imagine que vocÃª Ã© um chef: antes que os ingredientes entrem na receita (o LLM neste caso), vocÃª pode lavar os vegetais, picar cebolas ou temperar a carne. Sem essa etapa, seu prato final pode faltar sabor, conter produtos nÃ£o lavados ou simplesmente ser inconsistente.

No mundo do Open WebUI, a funÃ§Ã£o `inlet` realiza esse trabalho importante de preparaÃ§Ã£o sobre a **entrada do usuÃ¡rio** antes que seja enviada ao modelo. Ela garante que a entrada seja tÃ£o limpa, contextual e Ãºtil quanto possÃ­vel para que a IA possa lidar com ela.

ğŸ“¥ **Entrada**:  
- **`corpo`**: A entrada bruta do Open WebUI para o modelo. EstÃ¡ no formato de uma solicitaÃ§Ã£o de conclusÃ£o de chat (geralmente um dicionÃ¡rio que inclui campos como as mensagens da conversa, configuraÃ§Ãµes do modelo e outros metadados). Pense nisso como seus ingredientes de receita.

ğŸš€ **Sua Tarefa**:  
Modificar e retornar o `corpo`. A versÃ£o modificada do `corpo` Ã© o que o LLM utiliza, entÃ£o esta Ã© sua chance de trazer clareza, estrutura e contexto Ã  entrada.


##### ğŸ³ Por que vocÃª usaria o `inlet`?
1. **Adicionando Contexto**: Anexar automaticamente informaÃ§Ãµes cruciais Ã  entrada do usuÃ¡rio, especialmente se o texto dele for vago ou incompleto. Por exemplo, vocÃª pode adicionar "VocÃª Ã© um assistente amigÃ¡vel" ou "Ajude este usuÃ¡rio a resolver um problema de software."
   
2. **Formatando Dados**: Se a entrada exigir um formato especÃ­fico, como JSON ou Markdown, vocÃª pode transformÃ¡-la antes de enviÃ¡-la ao modelo.

3. **Sanitizando Entrada**: Remover caracteres indesejados, eliminar sÃ­mbolos potencialmente prejudiciais ou confusos (como espaÃ§os excessivos ou emojis) ou substituir informaÃ§Ãµes sensÃ­veis.

4. **Simplificando Entrada do UsuÃ¡rio**: Se a saÃ­da do seu modelo melhorar com orientaÃ§Ãµes adicionais, vocÃª pode usar o `inlet` para injetar instruÃ§Ãµes de esclarecimento automaticamente!


##### ğŸ’¡ Casos de Uso Exemplares: Construindo em PreparaÃ§Ã£o de Alimentos
###### ğŸ¥— Exemplo 1: Adicionando Contexto do Sistema
Digamos que o LLM seja um chef preparando um prato de cozinha italiana, mas o usuÃ¡rio nÃ£o mencionou "Isto Ã© para culinÃ¡ria italiana." VocÃª pode garantir que a mensagem seja clara ao anexar este contexto antes de enviar os dados ao modelo.

```python
def inlet(self, corpo: dict, __user__: Optional[dict] = None) -> dict:
    # Adicionar mensagem do sistema para contexto italiano na conversa
    mensagem_de_contexto = {
        "role": "system",
        "content": "VocÃª estÃ¡ ajudando o usuÃ¡rio a preparar uma refeiÃ§Ã£o italiana."
    }
    # Inserir o contexto no inÃ­cio do histÃ³rico de chat
    corpo.setdefault("messages", []).insert(0, mensagem_de_contexto)
    return corpo
```

ğŸ“– **O que Acontece?**
- Qualquer entrada do usuÃ¡rio como "Quais sÃ£o algumas boas ideias de jantar?" agora carrega o tema italiano porque definimos o contexto do sistema! Cheesecake pode nÃ£o aparecer como resposta, mas macarrÃ£o certamente aparecerÃ¡.


###### ğŸ”ª Exemplo 2: Limpando Entrada (Remover Caracteres Estranhos)
Suponha que a entrada do usuÃ¡rio pareÃ§a confusa ou inclua sÃ­mbolos indesejados como `!!!`, tornando a conversa ineficiente ou mais difÃ­cil para o modelo processar. VocÃª pode limpÃ¡-la enquanto preserva o conteÃºdo principal.

```python
def inlet(self, corpo: dict, __user__: Optional[dict] = None) -> dict:
    # Limpar a Ãºltima entrada do usuÃ¡rio (do final da lista messages)
    Ãºltima_mensagem = corpo["messages"][-1]["content"]
    corpo["messages"][-1]["content"] = Ãºltima_mensagem.replace("!!!", "").strip()
    return corpo
```

ğŸ“– **O que Acontece?**
- Antes: `"Como posso depurar este problema!!!"` â¡ï¸ Enviado ao modelo como `"Como posso depurar este problema"`

Nota: O usuÃ¡rio percebe o mesmo, mas o modelo processa uma consulta mais limpa e fÃ¡cil de entender.


##### ğŸ“Š Como `inlet` ajuda a otimizar a entrada para o LLM:
- Melhora a **precisÃ£o** ao esclarecer consultas ambÃ­guas.
- Torna a IA **mais eficiente** ao remover ruÃ­do desnecessÃ¡rio, como emojis, tags HTML ou pontuaÃ§Ã£o extra.
- Garante **consistÃªncia** ao formatar a entrada do usuÃ¡rio para corresponder aos padrÃµes ou esquemas esperados pelo modelo (como, por exemplo, JSON para um caso de uso especÃ­fico).


ğŸ’­ **Pense no `inlet` como o sous-chef na sua cozinha**â€”garantindo que tudo que entra no modelo (sua "receita" de IA) foi preparado, limpo e temperado Ã  perfeiÃ§Ã£o. Quanto melhor a entrada, melhor a saÃ­da!

---

#### ğŸ†• 3ï¸âƒ£ **Hook `stream` (Novo no Open WebUI 0.5.17)**

##### ğŸ”„ O que Ã© o Hook `stream`?
A **funÃ§Ã£o `stream`** Ã© uma nova funcionalidade introduzida no Open WebUI **0.5.17** que permite **interceptar e modificar respostas transmitidas pelo modelo** em tempo real.

Diferentemente de `outlet`, que processa uma resposta completa, o `stream` opera em **fragmentos individuais** conforme sÃ£o recebidos do modelo.

##### ğŸ› ï¸ Quando usar o Hook `stream`?
- Modificar **respostas transmitidas** antes que sejam exibidas aos usuÃ¡rios.
- Implementar **censura ou limpeza em tempo real**.
- **Monitorar dados transmitidos** para log/debug.

##### ğŸ“œ Exemplo: Registrar Fragmentos Transmitidos

Veja como inspecionar e modificar respostas transmitidas do LLM:
```python
def stream(self, event: dict) -> dict:
    print(event)  # Imprime cada fragmento recebido para inspeÃ§Ã£o
    return event
```

> **Exemplos de Eventos Transmitidos:**
```jsonl
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "Oi"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": "!"}}]}
{"id": "chatcmpl-B4l99MMaP3QLGU5uV7BaBM0eDS0jb","choices": [{"delta": {"content": " ğŸ˜Š"}}]}
```
ğŸ“– **O que acontece?**
- Cada linha representa um **pequeno fragmento** da resposta transmitida do modelo.
- O campo **`delta.content`** contÃ©m o texto gerado progressivamente.

##### ğŸ”„ Exemplo: Filtrar Emojis dos Dados Transmitidos
```python
def stream(self, event: dict) -> dict:
    for choice in event.get("choices", []):
        delta = choice.get("delta", {})
        if "content" in delta:
            delta["content"] = delta["content"].replace("ğŸ˜Š", "")  # Remove emojis
    return event
```
ğŸ“– **Antes:** `"Oi ğŸ˜Š"`  
ğŸ“– **Depois:** `"Oi"`

---

#### 4ï¸âƒ£ **FunÃ§Ã£o `outlet` (PÃ³s-processamento de saÃ­da)**

A funÃ§Ã£o `outlet` Ã© como um **revisor**: organiza a resposta da IA (ou faz alteraÃ§Ãµes finais) *depois que ela foi processada pelo LLM.*

ğŸ“¤ **Entrada**:
- **`body`**: ContÃ©m **todas as mensagens atuais** do chat (histÃ³rico do usuÃ¡rio + respostas do LLM).

ğŸš€ **Sua tarefa**: Modifique este `body`. VocÃª pode limpar, adicionar ou registrar alteraÃ§Ãµes, mas lembre-se de como cada ajuste impacta a experiÃªncia do usuÃ¡rio.

ğŸ’¡ **Melhores prÃ¡ticas**:
- Prefira registrar alteraÃ§Ãµes em vez de editar diretamente no outlet (por exemplo, para depuraÃ§Ã£o ou anÃ¡lise).
- Se forem necessÃ¡rias modificaÃ§Ãµes mais extensas (como formatar saÃ­das), considere usar a **funÃ§Ã£o pipe**.

ğŸ’¡ **Caso de uso exemplo**: Remova respostas sensÃ­veis de API que vocÃª nÃ£o quer que o usuÃ¡rio veja:
```python
def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
    for message in body["messages"]:
        message["content"] = message["content"].replace("<API_KEY>", "[REDACTED]")
    return body 
```

---

## ğŸŒŸ Filtros em aÃ§Ã£o: Criando exemplos prÃ¡ticos

Vamos criar alguns exemplos do mundo real para ver como vocÃª usaria os filtros!

### ğŸ“š Exemplo #1: Adicione contexto a cada entrada de usuÃ¡rio

Quer que o LLM sempre saiba que estÃ¡ ajudando um cliente a resolver problemas de software? VocÃª pode acrescentar instruÃ§Ãµes como **"VocÃª Ã© um assistente de soluÃ§Ã£o de problemas de software"** a cada consulta do usuÃ¡rio.

```python
class Filter:
    def inlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        context_message = {
            "role": "system", 
            "content": "VocÃª Ã© um assistente de soluÃ§Ã£o de problemas de software."
        }
        body.setdefault("messages", []).insert(0, context_message)
        return body
```

---

### ğŸ“š Exemplo #2: Destacar saÃ­das para fÃ¡cil leitura

Retornando saÃ­da em Markdown ou outro estilo formatado? Use a funÃ§Ã£o `outlet`!

```python
class Filter:
    def outlet(self, body: dict, __user__: Optional[dict] = None) -> dict:
        # Adicione "destacar" markdown para cada resposta
        for message in body["messages"]:
            if message["role"] == "assistant":  # Alvo: resposta do modelo
                message["content"] = f"**{message[content]}**"  # Destaque com Markdown
        return body
```

---

## ğŸš§ PossÃ­veis dÃºvidas: FAQ claro ğŸ›‘

### **P: Como os filtros sÃ£o diferentes das funÃ§Ãµes Pipe?**

Os filtros modificam dados **indo para** e **vindo de modelos**, mas nÃ£o interagem significativamente com a lÃ³gica fora dessas fases. Por outro lado, Pipes:
- Podem integrar **APIs externas** ou transformar significativamente como o backend lida com operaÃ§Ãµes.
- ExpÃµem lÃ³gica personalizada como "modelos" completamente novos.

### **P: Posso fazer um pÃ³s-processamento pesado dentro do `outlet`?**

VocÃª pode, mas **nÃ£o Ã© a melhor prÃ¡tica.**:
- **Filtros** sÃ£o projetados para fazer alteraÃ§Ãµes leves ou aplicar registros.
- Se forem necessÃ¡rias modificaÃ§Ãµes pesadas, considere usar uma **FunÃ§Ã£o Pipe** em vez disso.

---

## ğŸ‰ Resumo: Por que construir funÃ§Ãµes de filtro?

AtÃ© agora, vocÃª aprendeu:
1. **Inlet** manipula **entradas do usuÃ¡rio** (prÃ©-processamento).
2. **Stream** intercepta e modifica **saÃ­das do modelo transmitidas** (em tempo real).
3. **Outlet** ajusta **saÃ­das da IA** (pÃ³s-processamento).
4. Os filtros sÃ£o melhores para alteraÃ§Ãµes leves e em tempo real no fluxo de dados.
5. Com **Valves**, vocÃª capacita os usuÃ¡rios a configurar filtros dinamicamente para comportamentos personalizados.

---

ğŸš€ **Sua vez**: Comece a experimentar! Que pequeno ajuste ou adiÃ§Ã£o de contexto poderia elevar sua experiÃªncia com o Open WebUI? Os filtros sÃ£o divertidos de construir, flexÃ­veis de usar e podem levar seus modelos para o prÃ³ximo nÃ­vel!  

Feliz codificaÃ§Ã£o! âœ¨
