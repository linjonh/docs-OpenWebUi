---
sidebar_position: 400
title: "⭐ 특징"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI의 주요 특징 ⭐

- 🚀 **간편한 설치**: Docker, Kubernetes, Podman, Helm Charts(`kubectl`, `kustomize`, `podman`, `helm`)를 사용하여 간편하게 설치 가능하며, `:ollama` 이미지(Ollama 포함)와 CUDA 지원을 포함하는 `:cuda` 이미지를 지원합니다.

- 🛠️ **초기 설정 안내**: 첫 설정 과정에서 관리자 계정을 생성해야 한다는 명확한 지시를 포함하여 명확하고 완전한 설정을 완료할 수 있습니다.

- 🤝 **OpenAI API 통합**: Ollama 모델과 함께 다양한 대화를 위해 OpenAI 호환 API를 간편히 통합할 수 있습니다. Open WebUI는 API URL을 사용자 정의하여 다양한 서드파티 애플리케이션과 완벽하게 통합할 수 있습니다.

- 🛡️ **세부 권한 및 사용자 그룹 관리**: 관리자가 세부 사용자 역할, 사용자 그룹, 작업 공간 내 권한을 생성할 수 있어 안전한 사용자 환경을 보장합니다. 이러한 세부 권한 관리는 보안을 강화할 뿐만 아니라 사용자 경험을 맞춤화하여 사용자들 간 소속감과 책임감을 강화합니다.

- 📱 **반응형 디자인**: 데스크탑 PC, 노트북, 모바일 기기에서 매끄러운 사용 경험을 제공합니다.

- 📱 **모바일을 위한 프로그레시브 웹 앱**: `localhost` 또는 개인 도메인에서 오프라인 액세스를 지원하며 매끄러운 UI와 함께 모바일 기기에서 네이티브 프로그레시브 웹 애플리케이션 경험을 제공합니다. PWA를 설치하려면 안전한 컨텍스트(일반적으로 HTTPS를 통해 서비스됨)에서 제공되어야 합니다.

  :::info

  - PWA를 설정하려면 Linux, Docker 및 `Nginx`, `Caddy`, `Traefik`과 같은 리버스 프록시 기술에 대한 약간의 이해가 필요합니다. 이러한 도구를 사용하면 필요에 맞게 생성 및 배포된 PWA를 쉽게 빌드하고 배포할 수 있습니다. "원클릭 설치" 옵션은 없지만 안전하게 Open WebUI 인스턴스를 HTTPS로 배포하려면 사용자 경험이 요구되며, 이러한 리소스를 사용하여 적합한 PWA를 더 쉽게 만들고 배포할 수 있습니다.

  :::

- ✒️🔢 **완전한 Markdown 및 LaTeX 지원**: 세부적인 상호작용을 위해 Markdown, LaTex 및 리치 텍스트 기능을 포함하여 LLM 경험을 향상시키세요.

- 🧩 **모델 빌더**: Open WebUI에서 Ollama 기본 모델을 기반으로 사용자가 정의한 모델을 쉽게 생성할 수 있습니다. 커스텀 캐릭터 및 에이전트를 생성하고, 모델 요소를 커스터마이징하며, [Open WebUI 커뮤니티](https://openwebui.com/)와의 통합을 통해 쉽고 간편하게 모델을 가져올 수 있습니다.

- 📚 **로컬 및 원격 RAG 통합**: 채팅 상호작용의 미래를 탐구하고 RAG 기술을 이용해 문서를 탐색하세요. 작업공간의 `문서` 탭에 문서를 로드한 다음 쿼리 앞에 해시 키 [`#`]를 입력하거나 해시 키 [`#`] 및 URL로 시작하여 웹 페이지 콘텐츠를 통합할 수 있습니다.

- 📄 **문서 추출**: PDF, 워드 문서, 엑셀 스프레드시트, 파워포인트 프레젠테이션 등 다양한 문서 형식에서 텍스트와 데이터를 추출합니다. 고급 문서 처리 기능을 통해 지식베이스에 통합할 수 있으며 복잡한 문서에서 정확한 정보를 생성 및 검색할 때 문서의 구조와 포맷을 보존할 수 있습니다.

- 🔍 **RAG를 위한 웹 검색**: 다양한 검색 제공업체를 선택하여 웹 검색을 수행하고 결과를 로컬 RAG 경험에 직접 주입할 수 있습니다.

- 🌐 **웹 탐색 기능**: URL 뒤에 `#` 명령을 사용하여 웹사이트를 간단히 통합할 수 있습니다. 이는 웹 콘텐츠를 대화에 직접 통합하여 상호작용의 깊이와 풍부함을 더욱 강화합니다.

- 🎨 **이미지 생성 통합**: 동적 시각 콘텐츠로 대화 경험을 풍부하게 하기 위해 이미지 생성 기능을 매끄럽게 통합합니다.

- ⚙️ **동시 모델 활용**: 동시에 여러 모델을 활용하여 고유한 강점을 최적의 응답으로 활용할 수 있습니다. 다양한 모델 모달리티를 병렬로 활용하여 경험을 증진하세요.

- 🔐 **역할 기반 접근 제어(RBAC)**: 제한된 권한으로 안전한 접근을 보장합니다. 인증된 사용자만 Ollama에 접근할 수 있으며, 모델 생성 및 가져오기 권한은 관리자에게만 부여됩니다.

- 🌐🌍 **다국어 지원**: 국제화(`i18n`) 지원을 통해 선호하는 언어로 Open WebUI를 경험하세요. 지원 언어 확장에 기여하기를 환영합니다! 우리는 기여자를 적극적으로 찾고 있습니다!

- 🌟 **지속적인 업데이트**: 정기적인 업데이트, 수정 사항 및 새로운 기능으로 Open WebUI를 지속적으로 개선합니다.

## 그리고 다음과 같은 훌륭한 기능들이 추가됩니다... ⚡️

---

### 🔧 파이프라인 지원

- 🔧 **파이프라인 프레임워크**: 모듈식 플러그인 프레임워크로 Open WebUI 경험을 통합하고 커스터마이징하여 기능성을 극대화하십시오. 이 프레임워크는 AI 에이전트부터 홈 오토메이션 API까지 Python 라이브러리를 쉽게 통합할 수 있도록 사용자 지정 로직 추가를 지원합니다. (https://github.com/open-webui/pipelines)

- 📥 **파이프라인 업로드**: `관리자 패널` > `설정` > `파이프라인` 메뉴를 통해 파이프라인을 직접 업로드하여 관리 프로세스를 간소화합니다.

#### 우리의 파이프라인 프레임워크는 무한한 가능성을 제공합니다. 몇 가지 사전 제작된 파이프라인부터 시작할 수 있습니다!

- 🔗 **함수 호출**: [함수 호출](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)을 파이프라인을 통해 통합하여 고급 함수 호출 기능으로 LLM 상호 작용을 향상시킬 수 있습니다.

- 📚 **사용자 지정 RAG**: [사용자 지정 검색 증강 생성(RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) 파이프라인을 통합하여 사용자 지정 RAG 로직으로 LLM 상호 작용을 향상시킬 수 있습니다.

- 📊 **Langfuse를 통한 메시지 모니터링**: [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 파이프라인을 통해 실시간 사용 통계에서 메시지 상호 작용을 모니터링하고 분석할 수 있습니다.

- ⚖️ **사용자 비율 제한**: [비율 제한](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 파이프라인을 사용하여 요청 흐름을 효율적으로 관리하고 LLM 전달 한도를 초과하지 않도록 합니다.

- 🌍 **리브레번역 실시간 번역**: [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 파이프라인을 사용해 실시간 번역을 LLM 상호 작용에 통합하여 다언어 간의 커뮤니케이션을 지원합니다.
  - 이 파이프라인은 Docker 컨테이너의 LibreTranslate 설정이 필요합니다.

- 🛡️ **유해 메시지 필터링**: [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 파이프라인은 유해한 메시지를 자동으로 필터링하여 깨끗하고 안전한 채팅 환경을 유지합니다.

- 🔒 **LLM-Guard**: [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 파이프라인으로 안전한 LLM 상호 작용을 보장하며, 프롬프트 인젝션 스캐너를 제공해 대규모 언어 모델을 대상으로 하는 교묘한 입력 조작을 탐지하고 완화합니다. 이를 통해 데이터 유출로부터 LLM을 보호하고, 프롬프트 인젝션 공격에 대한 저항력을 추가합니다.

- 🕒 **대화 턴 제한**: [대화 턴 제한](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 파이프라인으로 상호 작용 관리를 향상시킬 수 있습니다.

- 📈 **OpenAI 생성 통계**: [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 파이프라인은 OpenAI 모델의 자세한 생성 통계를 제공합니다.

- **🚀 다중 모델 지원**: [여러 제공자](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)의 AI 모델과의 매끄러운 통합으로 선택하고 상호 작용할 수 있는 다양한 언어 모델을 제공합니다.

#### 방대한 기능과 커스터마이징 옵션 외에도 [사용할 준비가 된 예제 파이프라인 라이브러리](https://github.com/open-webui/pipelines/tree/main/examples)와 [실용적인 예제 스캐폴드 파이프라인](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py)도 제공합니다. 이러한 리소스는 개발 프로세스를 간소화하고, 파이프라인과 Python을 사용하여 강력한 LLM 상호 작용을 빠르게 생성할 수 있도록 지원합니다. 코딩을 즐기세요! 💡

---

### 🖥️ 사용자 경험

- 🖥️ **직관적인 인터페이스**: 사용자를 염두에 두고 디자인된 채팅 인터페이스는 ChatGPT의 사용자 인터페이스에서 영감을 받았습니다.

- ⚡ **신속한 응답성**: 믿을 수 있는 빠르고 반응성이 뛰어난 성능을 경험할 수 있습니다.

- 🎨 **로딩 화면**: 부드러운 사용자 경험을 위한 간단한 로딩 화면을 제공합니다.

- 🌐 **개인화된 인터페이스**: 설정 > 인터페이스에서 새롭게 디자인된 검색 시작 페이지와 기존의 채팅 UI 중 선택하여 맞춤화된 경험을 제공받으세요.

- 📦 **Pip 설치 방법**: Open WebUI는 `pip install open-webui` 명령어를 통해 설치할 수 있으며, 이는 설치 과정을 간소화하고 새로운 사용자들에게 더 쉽게 접근할 수 있는 환경을 제공합니다. 자세한 정보는 다음 링크에서 확인하세요: https://pypi.org/project/open-webui/.

- 🌈 **테마 커스터마이징**: 다양한 세련된 테마, 사용자 정의 가능한 채팅 배경 이미지, Light, Dark 또는 OLED Dark 모드 옵션을 포함한 다양한 옵션으로 Open WebUI 환경을 개인화하세요 - 또는 *Her*가 대신 선택할 수도 있습니다! ;)

- 🖼️ **사용자 정의 배경 지원**: 설정 > 인터페이스에서 사용자 정의 배경을 설정하여 환경을 개인화하세요.

- 📝 **마크다운을 활용한 배너**: 마크다운 지원을 통해 시각적으로 매력적인 공지를 만들 수 있으며, 보다 풍부하고 역동적인 콘텐츠를 제공합니다.

- 💻 **코드 구문 강조 표시**: 구문 강조 표시 기능은 코드 가독성을 향상시켜 보다 명확하고 간결한 코드를 제공합니다.

- 🗨️ **사용자 메시지의 마크다운 렌더링**: 사용자 메시지는 이제 마크다운으로 렌더링되어 가독성과 상호작용성이 향상되었습니다.

- 🎨 **유연한 텍스트 입력 옵션**: 풍부한 텍스트 입력과 기존 텍스트 영역 입력 간에 전환할 수 있어, 사용자의 선호에 따라 고급 포맷팅과 단순 텍스트 입력 중에서 선택할 수 있습니다.

- 👆 **간편한 코드 공유**: 코드 블록에 떠 있는 복사 버튼 및 코드 스팬에서 클릭-복사 기능 등 편리한 코드 복사 옵션을 통해 공유 및 협업 과정을 간소화하세요. 시간을 절약하고 스트레스를 줄여줍니다.

- 🎨 **인터랙티브 아티팩트**: 웹 콘텐츠와 SVG를 인터페이스에서 직접 렌더링하여 빠른 반복 작업과 실시간 변경을 지원하며 창의성과 생산성을 향상시킵니다.

- 🖊️ **라이브 코드 편집**: LLM 응답 내에서 직접 라이브 편집이 가능한 코드 블록은 아티팩트가 지원하는 실시간 리로드 기능과 함께 코딩 및 테스트를 간소화합니다.

- 🔍 **SVG 상호작용 강화**: 파닝 및 줌 기능을 통해 SVG 이미지(예: Mermaid 다이어그램)를 탐색하며 복잡한 개념을 더 깊이 이해할 수 있습니다.

- 🔍 **텍스트 선택 빠른 작업**: LLM 응답에서 텍스트가 강조되면 나타나는 플로팅 버튼은 '질문하기', '설명하기'와 같은 심화 상호작용을 제공하며 전반적인 사용자 경험을 향상시킵니다.

- ↕️ **양방향 채팅 지원**: 왼쪽에서 오른쪽, 오른쪽에서 왼쪽으로의 채팅 방향 간에 쉽게 전환하여 다양한 언어 선호도를 쉽게 맞출 수 있습니다.

- 📱 **모바일 접근성**: 모바일 기기에서 간단한 스와이프 제스처로 사이드바를 열고 닫을 수 있습니다.

- 🤳 **지원 기기에서의 햅틱 피드백**: 안드로이드 기기에서는 특정 상호작용 중 몰입감 있는 촉각 경험을 제공하는 햅틱 피드백을 지원합니다.

- 🔍 **사용자 설정 검색**: 설정 필드를 빠르게 검색하여 사용 편의성과 탐색성을 개선합니다.

- 📜 **오프라인 Swagger 문서**: 개발자 친화적인 Swagger API 문서에 오프라인으로 접근할 수 있어 어디서든 완벽한 접근성을 제공합니다.

- 💾 **성능 최적화**: 대형 의존성의 지연 로드 방식은 초기 메모리 사용량을 최소화하여 성능을 향상시키고 로딩 시간을 단축합니다.

- 🚀 **지속 가능하고 확장 가능한 설정**: Open WebUI 설정은 데이터베이스(webui.db)에 저장되어 무중단 로드 밸런싱, 고가용성 설정, 여러 인스턴스 간의 지속적인 설정을 가능하게 하며 설정의 접근성과 재사용성을 높입니다.

- 🔄 **이동 가능한 가져오기/내보내기**: Open WebUI 설정을 쉽게 가져오고 내보내어 여러 시스템에서 설정을 복제하는 과정을 간소화합니다.

- ❓ **문서 및 바로 가기 빠른 접근**: 메인 UI 화면의 오른쪽 하단 모서리에 있는 물음표 버튼(데스크톱 PC 및 노트북과 같은 대형 화면에서 사용 가능)은 Open WebUI 문서 페이지와 키보드 바로 가기에 쉽게 접근할 수 있는 기능을 제공합니다.

- 📜 **변경 로그 및 업데이트 확인**: 사용자는 `설정` > `정보` > `새로운 항목 보기` 메뉴에서 포괄적인 변경 로그를 확인하고 업데이트를 확인할 수 있으며, 이를 통해 최신 기능, 개선 사항 및 버그 수정 사항에 대한 빠른 개요를 파악할 수 있습니다.

---

### 💬 대화

- 💬 **진정한 비동기 채팅**: 진정한 비동기 채팅 지원으로 중단 없는 멀티태스킹을 즐길 수 있으며, 채팅을 생성하고 나갔다가 언제든지 돌아왔을 때 응답을 확인할 수 있습니다.

- 🔔 **채팅 완료 알림**: 비활성 탭에서 채팅이 완료되면 즉시 UI 알림을 통해 업데이트를 받을 수 있어 완료된 응답을 놓치지 않습니다.

- 🌐 **알림 웹훅 통합**: 구성 가능한 웹훅 알림으로 긴 채팅이나 외부 통합 요구 사항에 대한 적시에 업데이트를 받을 수 있으며, 심지어 탭이 닫혀 있어도 가능합니다.

- 📚 **채널 (베타)**: Discord/Slack 스타일의 채팅 방으로 사용자와 AI 간의 실시간 협업을 탐구하고, 채널용 봇을 빌드하며, 다중 에이전트 작업 흐름을 위한 비동기 통신을 구현하세요.

- 🖊️ **채널에서의 타이핑 표시기**: 채널에서 실시간 타이핑 표시기로 협업을 향상시키며 모두가 참여 상태와 진행 상황을 확인할 수 있습니다.

- 👤 **사용자 상태 표시기**: 채널에서 사용자 프로필 이미지를 클릭하여 사용자의 상태를 빠르게 확인하고 더 나은 조정과 가용성 통찰을 제공합니다.

- 💬 **채팅 컨트롤**: 각 채팅 세션의 매개변수를 쉽게 조정하여 상호작용을 더 정확히 제어할 수 있습니다.

- 💖 **즐겨찾기 응답 관리**: 채팅 개요에서 즐겨찾기 응답을 쉽게 표시하고 구성하여 선호하는 응답에 더 간편하게 접근하고 검색할 수 있습니다.

- 📌 **고정된 채팅**: 중요한 대화를 쉽게 접근할 수 있도록 고정된 채팅을 지원합니다.

- 🔍 **RAG 임베딩 지원**: `관리자 패널` > `설정` > `문서` 메뉴에서 검색 증강 생성(RAG) 임베딩 모델을 변경하여 문서 처리 기능을 향상시킵니다. 이 기능은 Ollama 및 OpenAI 모델을 지원합니다.

- 📜 **RAG 기능의 인용**: 검색 증강 생성(RAG) 기능을 통해 문서를 LLM에 제공할 때 추가된 인용으로 참조 포인트가 있는 문맥을 쉽게 추적할 수 있습니다.

- 🌟 **향상된 RAG 파이프라인**: RAG 임베딩 기능에 대해 `BM25`를 사용한 하이브리드 검색 하위 기능이 추가되어 기능을 향상시키며, `크로스인코더`로 지원되는 재랭킹 및 설정 가능한 적합도 점수 임계값을 제공합니다.

- 📹 **YouTube RAG 파이프라인**: YouTube 동영상 URL을 사용하여 동영상을 요약하는 전용 검색 증강 생성(RAG) 파이프라인으로 동영상 대본과의 부드러운 상호작용을 가능하게 합니다.

- 📁 **포괄적인 문서 검색**: 전체 문서 검색과 전통적인 스니펫 간의 전환이 가능하여 요약 같은 포괄적인 작업을 지원하고 문서 기능을 강화합니다.

- 🌟 **RAG 인용의 적합성**: RAG 결과에 적합성 백분율 추가로 인용 정확도를 쉽게 평가할 수 있습니다.

- 🗂️ **고급 RAG**: 검색 전 채팅 기록을 스마트하게 사전 처리하여 최적의 쿼리를 확인함으로써 RAG 정확도를 개선합니다.

- 📚 **RAG를 위한 인라인 인용**: 검색 증강 생성(RAG) 응답에 원활한 인라인 인용을 도입하여 추적 가능성을 개선하고 새로 업로드된 파일의 출처 명확성을 제공합니다.

- 📁 **큰 텍스트 처리**: 큰 텍스트를 파일 업로드 형식으로 변환하는 옵션을 제공하여 RAG과 직접 사용할 수 있도록 하고, 채팅 인터페이스를 더 깔끔하게 유지합니다.

- 🔄 **멀티모달 지원**: 이미지(`예: LLaVA`)를 포함한 멀티모달 상호작용을 지원하는 모델과 쉽게 소통할 수 있습니다.

- 🤖 **다중 모델 지원**: 다양한 채팅 상호작용을 위해 여러 모델 간에 빠르게 전환할 수 있습니다.

- 🔀 **다중 모델 채팅에서 응답 병합**: 여러 모델의 응답을 병합하여 단일하고 일관성 있는 답변을 생성함으로써 대화를 향상시킵니다.

- ✅ **채팅에서 동일 모델의 다중 인스턴스**: 다중 모델 채팅을 강화하여 동일 모델의 여러 인스턴스를 추가할 수 있습니다.

- 💬 **임시 채팅 기능**: 사용자 상호작용의 유연성을 강화하기 위해 오래된 채팅 기록 설정을 폐기하고 임시 채팅 기능을 도입했습니다.

- 🖋️ **사용자 메시지 편집**: 메시지를 전송하지 않고도 변경 내용을 저장할 수 있도록 사용자 채팅 편집 기능을 개선했습니다.

- 💬 **효율적인 대화 편집**: Cmd/Ctrl+Shift+Enter 바로 가기를 사용하여 새 메시지 쌍을 빠르고 직관적으로 생성하고 대화 길이 테스트를 간소화합니다.

- 🖼️ **클라이언트 측 이미지 압축**: 클라이언트 측 이미지 압축으로 업로드 전 이미지를 압축하여 대역폭을 절약하고 성능을 향상할 수 있습니다. 설정 > 인터페이스에서 이를 구성할 수 있습니다.

- 👥 **'@' 모델 통합**: 대화 중에 로컬 또는 외부 모델로 원활하게 전환하여 단일 채팅에서 여러 모델의 집단 지능을 활용할 수 있습니다. 채팅 내에서 '@' 명령어를 사용하여 모델 이름으로 지정할 수 있습니다.

- 🏷️ **대화 태그 지정**: 효율적인 'tag:' 쿼리 시스템으로 태그가 지정된 채팅을 손쉽게 분류 및 검색하고 데이터 수집을 간소화하며, 인터페이스를 어지럽히지 않고 대화를 관리하고 조직화할 수 있습니다.

- 🧠 **자동 태그 지정**: 자동 생성된 제목과 같은 효율성을 반영하여 대화를 자동으로 태그할 수 있는 옵션을 제공합니다.

- 👶 **채팅 복제**: 아무 채팅을 쉽게 복제하고 스냅숏을 저장하여 나중에 참고하거나 계속 이어나갈 수 있습니다. 이 기능으로 중단한 곳에서 다시 시작하거나 다른 사람과 세션을 공유할 수 있습니다. 채팅의 드롭다운 옵션에서 `복제` 버튼을 클릭하여 채팅 복제를 만들 수 있습니다. 복제를 따라갈 수 있나요?

- ⭐ **시각화된 대화 흐름**: 대화 흐름을 보다 잘 이해하고 복잡한 논의를 탐색할 수 있도록 상호작용 메시지 다이어그램을 제공합니다.

- 📁 **채팅 폴더**: 채팅을 폴더로 정리하고 드래그 앤 드롭으로 쉽게 관리하며, 이를 원활하게 내보내서 공유하거나 분석할 수 있습니다.

- 📤 **간편한 채팅 가져오기**: 사이드바로 채팅 내보내기(JSON)를 간단히 드래그 앤 드롭하여 작업 공간에 채팅을 가져올 수 있습니다.

- 📜 **프롬프트 프리셋 지원**: 채팅 입력창에서 `/` 명령어를 사용하여 즉시 사용자 정의 프리셋 프롬프트에 액세스할 수 있습니다. 사전 정의된 대화 시작점을 손쉽게 불러와 상호작용을 빠르게 진행하세요. [Open WebUI Community](https://openwebui.com/) 통합을 통해 프롬프트를 손쉽게 가져오거나 직접 생성하세요!

- 📅 **프롬프트 변수 지원**: `{{CLIPBOARD}}`, `{{CURRENT_DATE}}`, `{{CURRENT_DATETIME}}`, `{{CURRENT_TIME}}`, `{{CURRENT_TIMEZONE}}`, `{{CURRENT_WEEKDAY}}`, `{{USER_NAME}}`, `{{USER_LANGUAGE}}`, `{{USER_LOCATION}}`과 같은 프롬프트 변수를 시스템 프롬프트에서 사용하거나 채팅 내에서 바로 프롬프트를 선택하여 사용할 수 있습니다.
  - `{{USER_LOCATION}}` 프롬프트 변수를 사용하려면 HTTPS를 통한 보안 연결이 필요합니다. 해당 프롬프트 변수를 활용하려면 `설정` > `인터페이스` 메뉴에서 `{{USER_LOCATION}}`을 활성화했는지 확인하세요.
  - `{{CLIPBOARD}}` 프롬프트 변수는 기기 클립보드 액세스 권한이 필요합니다.

- 🧠 **메모리 기능**: `설정` > `개인화` > `메모리` 메뉴를 통해 LLM이 기억해야 할 정보를 수동으로 추가할 수 있습니다. 메모리는 추가, 수정, 삭제가 가능합니다.

---

### 💻 모델 관리


- 🛠️ **모델 빌더**: 모든 모델은 모델 수정 페이지 내에서 지속적인 모델 빌더 모드를 통해 생성하고 수정할 수 있습니다.

- 📚 **모델 지식 지원**: 모델 수정 페이지에서 도구, 함수 및 지식 컬렉션을 직접 모델에 연결하여 각 모델이 사용할 수 있는 정보를 확장할 수 있습니다.

- 🗂️ **모델 프리셋**: Ollama 및 OpenAI API를 위한 모델 프리셋을 생성하고 관리하세요.

- 🏷️ **모델 태그**: 모델 작업 공간에서 태그를 사용하여 모델을 정리할 수 있습니다.

- 📋 **모델 선택 드롭다운 정렬**: 모델 작업 공간에서 드래그 앤 드롭을 통해 모델을 원하는 위치에 정렬하면 모델 드롭다운 메뉴에 반영됩니다.

- 🔍 **모델 선택 드롭다운**: 퍼지 검색 및 모델 태그 및 설명을 포함한 세부 정보로 모델을 간편히 찾아 선택하세요.

- ⌨️ **화살표 키 모델 선택**: 화살표 키를 사용하여 더 빠른 모델 선택이 가능하며 접근성이 향상됩니다.

- 🔧 **모델 작업 공간에서 빠른 동작**: Shift 키를 활용한 모델 숨기기/표시 및 삭제와 같은 향상된 빠른 동작을 제공합니다.

- 😄 **투명한 모델 사용**: 지식이 증강된 모델의 상태를 쿼리 중에 확인할 수 있도록 상태 표시가 보입니다.

- ⚙️ **고급 매개변수로 미세 조정 컨트롤**: `seed`, `temperature`, `frequency penalty`, `context length`, `seed` 등 모델 매개변수를 조정하여 더 깊이 있는 컨트롤을 할 수 있습니다.

- 🔄 **원활한 통합**: [Ollama 라이브러리](https://ollama.com/library/)의 모델 페이지에서 `ollama run {model:tag}` CLI 명령어를 복사하여 모델 드롭다운에 붙여서 모델을 쉽게 선택하고 불러올 수 있습니다.

- 🗂️ **Ollama 모델 파일 생성**: Ollama용 모델 파일을 생성하려면 `관리자 패널` > `설정` > `모델` > `모델 생성` 메뉴로 이동하세요.

- ⬆️ **GGUF 파일 모델 생성**: GGUF 파일을 Open WebUI에서 직접 업로드하여 Ollama 모델을 쉽게 생성하세요. 이 과정은 기기에서 파일을 업로드하거나 Hugging Face에서 GGUF 파일을 다운로드할 수 있는 옵션으로 간소화되었습니다.

- ⚙️ **기본 모델 설정**: 기본 모델 선호도를 모바일 기기에서는 `설정` > `인터페이스` 메뉴에서 설정할 수 있으며, 데스크톱 PC 및 랩톱에서는 모델 선택 드롭다운에서 쉽게 설정할 수 있습니다.

- 💡 **LLM 응답 인사이트**: 생성된 모든 응답의 자세한 정보를 외부 모델 API 인사이트 및 포괄적인 로컬 모델 정보를 포함하여 확인할 수 있습니다.

- 🕒 **모델 세부 정보 간략 조회**: 모델 해시와 마지막 수정 타임스탬프를 포함한 주요 모델 세부 정보를 모델 작업 공간에서 바로 확인하여 추적 및 관리를 개선합니다.

- 📥🗑️ **모델 다운로드/삭제**: Open WebUI에서 모델을 쉽게 다운로드하거나 삭제할 수 있습니다.

- 🔄 **모든 Ollama 모델 업데이트**: 사용자가 한 번의 작업으로 로컬에 설치된 모든 모델을 업데이트할 수 있는 편리한 버튼이 제공되어 모델 관리가 간소화됩니다.

- 🍻 **TavernAI 캐릭터 카드 통합**: 모델 빌더에서 TavernAI 캐릭터 카드 통합을 통해 시각적 스토리텔링을 향상하십시오. 사용자는 모델 파일에 직접 TavernAI 캐릭터 카드 PNG를 포함하여 더욱 몰입감 있고 매력적인 사용자 경험을 창출할 수 있습니다.

- 🎲 **모델 플레이그라운드 (베타)**: 모델 플레이그라운드 영역에서 모델을 테스트하고 탐색하세요 (`베타`). 사용자가 라이브 채팅 환경에서 배포 전에 간편하게 모델 기능 및 매개변수를 탐색할 수 있습니다.

---

### 👥 협업

- 🗨️ **로컬 채팅 공유**: 사용자 간 채팅 링크를 효율적이고 매끄럽게 생성 및 공유하여 협업 및 의사소통을 강화하세요.

- 👍👎 **RLHF Annotation**: 사용자 메시지에 대해 좋아요 또는 싫어요로 평가하고 1-10의 척도를 기준으로 응답에 점수를 부여한 다음 텍스트 피드백을 제공할 수 있는 옵션을 통해 인간 피드백을 이용한 강화 학습(`RLHF`)을 위한 데이터셋 생성에 도움을 줍니다. 로컬에 저장된 데이터 기밀성을 유지하며, 사용자의 메시지를 이용해 모델을 훈련하거나 미세 조정할 수 있습니다.

- 🔧 **종합 피드백 내보내기**: JSON 형식으로 피드백 기록 데이터를 내보내 RLHF 처리 및 추가 분석과 통합해 개선에 유용한 통찰력을 제공합니다.

- 🤝 **커뮤니티 공유**: [Open WebUI 커뮤니티](https://openwebui.com/)와 채팅 세션을 공유하려면 `Open WebUI 커뮤니티에 공유` 버튼을 클릭합니다. 이 기능을 통해 다른 사용자들과 교류하며 플랫폼에서 공동 작업을 수행할 수 있습니다.
  - 이 기능을 사용하려면 Open WebUI 커뮤니티 계정에 로그인해야 합니다. 채팅을 공유하면 활기찬 커뮤니티를 증진시키고 지식 공유와 공동의 문제 해결을 촉진할 수 있습니다. 채팅 세션의 커뮤니티 공유는 선택적 기능입니다. 관리자만 `관리 설정` > `설정` > `일반` 메뉴를 통해 이 기능을 켜거나 끌 수 있습니다.

- 🏆 **커뮤니티 리더보드**: ELO 점수 시스템을 활용한 리더보드 시스템으로 실시간으로 성능을 추적하고, 피드백 기록 공유를 선택적으로 할 수 있습니다.

- ⚔️ **모델 평가 경기장**: 관리자 설정에서 직접 모델의 블라인드 A/B 테스트를 실행하여 측면 비교를 통해 필요에 가장 적합한 모델을 찾기가 더욱 쉬워집니다.

- 🎯 **주제별 랭킹**: 피드백의 태그 유사성을 기반으로 리더보드 순위를 조정하는 실험적 주제별 재랭킹 시스템으로 더욱 정확한 순위를 확인하십시오.

- 📂 **통합 및 협업 작업 공간** : 한 장소에서 모든 모델 파일, 프롬프트, 문서, 도구 및 기능을 액세스하고 관리하며, 여러 사용자가 모델, 지식, 프롬프트 또는 도구에 협력하고 기여할 수 있도록 하여 작업 흐름을 간소화하고 팀워크를 향상시킵니다.

---

### 📚 기록 및 보관

- 📜 **채팅 기록**: 채팅 네비게이션 사이드바를 통해 대화 기록에 쉽게 액세스하고 관리할 수 있습니다. `설정` > `채팅` 메뉴에서 채팅 기록 생성을 방지하기 위해 채팅 기록을 비활성화할 수 있습니다.

- 🔄 **재생성 기록 액세스**: LLM 응답 재생성 기록을 쉽게 다시 방문하고 탐색할 수 있습니다.

- 📬 **채팅 보관**: 모델과 완료된 대화를 간단하게 저장하여 향후 참조나 상호작용 가능성을 유지하면서 깔끔한 채팅 인터페이스를 유지합니다.

- 🗃️ **모든 채팅 보관**: 이 기능은 모든 채팅을 한 번에 빠르게 보관할 수 있도록 합니다.

- 📦 **보관된 모든 채팅을 JSON으로 내보내기**: 이 기능은 모든 보관된 채팅을 단일 JSON 파일로 쉽게 내보내 백업이나 전송 목적으로 사용할 수 있도록 합니다.

- 📄 **채팅을 JSON/PDF/TXT로 다운로드**: `.json`, `.pdf`, 또는 `.txt` 형식으로 선호하는 형식으로 개별 채팅을 쉽게 다운로드하세요.

- 📤📥 **채팅 기록 가져오기 및 내보내기**: `채팅 가져오기` 및 `채팅 내보내기` 옵션을 통해 플랫폼의 채팅 데이터를 원활하게 이동할 수 있습니다.

- 🗑️ **모든 채팅 삭제**: 이 옵션은 모든 채팅을 영구적으로 삭제해 새로 시작할 수 있도록 합니다.

---

### 🎙️ 오디오, 음성 및 접근성

- 🗣️ **음성 입력 지원**: 모델과 음성으로 상호작용하며 직접 말하는 편리함을 누리세요. 또한 자동화된 경험을 위해 3초의 침묵 후 음성 입력을 자동으로 전송하는 옵션을 탐색하세요.
  - 마이크 액세스는 HTTPS를 통한 안전한 연결을 수동적으로 설정하거나 [사용자 위험 하에 URL을 수동적으로 허용](https://docs.openwebui.com/troubleshooting/microphone-error)해야 합니다.

- 😊 **이모지 호출**: `설정` > `인터페이스` 메뉴에서 이 기능을 활성화해 LLM이 음성 호출 동안 이모지를 사용해 감정을 표현할 수 있도록 하여 더욱 역동적인 상호작용을 제공합니다.
  - 마이크 액세스는 이 기능이 작동하기 위해 HTTPS를 통한 안전한 연결이 필요합니다.

- 🎙️ **핸즈프리 음성 통화 기능**: 손을 사용하지 않고 음성 통화를 시작하여 상호작용을 더욱 원활하게 만듭니다.
  - 마이크 액세스는 이 기능이 작동하기 위해 HTTPS를 통한 안전한 연결이 필요합니다.

- 📹 **영상 통화 기능**: LlaVA 및 GPT-4o와 같은 지원되는 비전 모델과 영상 통화를 활성화하여 커뮤니케이션에 시각적인 차원을 추가합니다.
  - 이 기능이 작동하려면 HTTPS를 통한 안전한 연결을 통해 카메라 및 마이크 액세스가 필요합니다.

- 👆 **터치로 중단**: 모바일 기기에서 간단히 터치하여 음성 대화 중 AI의 발화를 중지시켜 상호작용을 원활하게 제어할 수 있습니다.

- 🎙️ **음성 중단**: 모바일 기기에서 음성을 통해 음성 대화 중 AI의 발화를 중지시켜 상호작용을 원활하게 제어할 수 있습니다.

- 🔊 **구성 가능한 텍스트 음성 변환 엔드포인트**: LLM 응답을 크게 읽을 수 있는 OpenAI 호환 엔드포인트를 구성하여 텍스트 음성 변환 경험을 사용자 정의하세요.

- 🔗 **다이렉트 통화 모드 액세스**: URL을 통해 직접 통화 모드를 활성화하여 모바일 기기 사용자를 위한 편리한 바로가기를 제공합니다.

- ✨ **사용자 정의 가능한 텍스트-음성 변환**: 메시지 내용을 텍스트-음성 변환(TTS) 생성 요청에 적합하게 나눌 수 있어 유연한 음성 출력 옵션을 제공합니다.

- 🔊 **Azure 음성 서비스 통합**: Azure 음성 서비스를 텍스트-음성 변환(TTS)에 지원하여 사용자들에게 다양한 음성 합성 옵션을 제공합니다.

- 🎚️ **사용자 정의 가능한 오디오 재생**: 사용자가 Call 모드 설정에서 오디오 재생 속도를 자신의 선호도에 맞게 조정할 수 있어 접근성과 사용성을 향상시킵니다.

- 🎵 **광범위한 오디오 호환성**: 플랫폼 내에서 다양한 오디오 파일 형식(RAG 포함 동작, 'audio/x-m4a' 등)을 지원하여 오디오 콘텐츠의 호환성을 확장합니다.

- 🔊 **오디오 압축**: 실험적인 오디오 압축을 통해 OpenAI의 음성-텍스트 처리 25MB 제한을 우회하여 오디오 기반 상호작용의 가능성을 넓힙니다.

- 🗣️ **실험적 SpeechT5 TTS**: 로컬 SpeechT5 지원으로 텍스트-음성 변환 기능을 향상시킵니다.

---

### 🐍 코드 실행

- 🚀 **다양한 UI 비종속 오픈AI 호환 플러그인 프레임워크**: 데이터 처리와 모델 훈련을 효율적으로 수행하기 위해 [Open WebUI Pipelines](https://github.com/open-webui/pipelines)를 원활하게 통합 및 사용자 정의하여 최고의 유연성과 확장성을 보장합니다.

- 🛠️ **네이티브 Python 함수 호출**: Open WebUI 내에서 Python의 강력한 기능에 직접 접근할 수 있습니다. 내장된 코드 편집기를 통해 `Tools`와 `Functions` 작업 공간 내에서 맞춤 RAG 파이프라인, 웹 검색 도구, 심지어 에이전트와 같은 작업을 수행하는 데 필요한 코드 개발 및 통합을 간편하게 진행할 수 있습니다.

- 🐍 **Python 코드 실행**: Pyodide를 통해 브라우저 내부에서 현지 Python 코드를 실행할 수 있으며 Pyodide가 지원하는 다양한 라이브러리를 활용할 수 있습니다.

- 🌊 **Mermaid 렌더링**: [Mermaid Diagramming and Charting Tool](https://mermaid.js.org/intro/)을 이용해 Open WebUI 내에서 시각적으로 매력적인 다이어그램과 흐름도를 만들어낼 수 있습니다.

- 🔗 **Iframe 지원**: 함수와 도구를 사용하여 HTML을 채팅 인터페이스에 직접 렌더링할 수 있습니다.

---

### 🔒 통합 및 보안

- ✨ **다중 OpenAI 호환 API 지원**: 다양한 OpenAI 호환 API를 원활하게 통합 및 사용자 정의하여 채팅 상호작용의 다양성을 향상시킵니다.

- 🔑 **간소화된 API 키 관리**: OpenAI 라이브러리로 Open WebUI를 활용하기 위해 비밀 키를 손쉽게 생성 및 관리할 수 있어 통합 및 개발 과정을 간소화합니다.

- 🌐 **HTTP/S 프록시 지원**: `http_proxy` 또는 `https_proxy` 환경 변수를 사용하여 네트워크 설정을 손쉽게 구성할 수 있습니다. 설정된 경우, 이러한 변수는 HTTP 및 HTTPS 프록시에 대한 URL을 포함해야 합니다.

- 🌐🔗 **외부 Ollama 서버 연결**: 환경 변수를 구성하여 다른 주소에 호스팅된 외부 Ollama 서버에 원활하게 연결할 수 있습니다.

- 🛢️ **유연한 데이터베이스 통합**: SQLite, Postgres, Milvus와 같은 여러 벡터 데이터베이스를 포함하여 사용자 정의 데이터베이스에 원활하게 연결할 수 있어 유연하고 확장 가능한 데이터 관리를 제공합니다.

- 🌐🗣️ **외부 음성-텍스트 변환 지원**: 외부 음성-텍스트(`STT`) 서비스를 추가함으로써 사용자가 선호하는 제공자를 선택하여 원활한 상호작용을 가능하게 만듭니다.

- 🌐 **원격 ChromaDB 지원**: 원격 ChromaDB 서버에 연결하여 데이터베이스의 기능을 확장합니다.

- 🔀 **다중 Ollama 인스턴스 부하 분산**: 채팅 요청을 여러 Ollama 인스턴스에 효율적으로 분산시켜 성능과 신뢰성을 향상시킵니다.

- 🚀 **고급 부하 분산 및 신뢰성**: 웹 소켓 자동 재연결 및 Redis를 완전히 지원하는 상태 비저장 인스턴스와 같은 향상된 부하 분산 기능을 활용하여 웹UI의 성능, 신뢰성 및 확장성을 개선하고 다중 인스턴스 간 원활하고 중단 없는 상호작용을 보장합니다.

- ☁️ **실험적 S3 지원**: 상태 비저장 WebUI 인스턴스를 S3 지원과 함께 활성화하여 확장성을 높이고 무거운 작업 부하를 균형있게 처리할 수 있게 합니다.

- 🛠️ **사용자 그룹을 위한 OAuth 관리**: OAuth 통합을 통해 그룹 수준 관리를 통해 협업 환경에서 제어 및 확장성을 향상시킵니다.

---

### 👑 관리

- 👑 **슈퍼 관리자 지정**: 처음 등록한 사용자를 슈퍼 관리자로 자동 지정하며, 이 권한은 다른 관리자도 변경할 수 없는 고정된 역할로 설정됩니다.

- 🛡️ **세분화된 사용자 권한**: 역할 기반의 사용자 정의 권한으로 사용자 작업과 접근을 제한하여, 허가된 사람만 특정 작업을 수행할 수 있도록 합니다.

- 👥 **다중 사용자 관리**: 페이지네이션을 포함한 직관적인 관리자 패널을 통해 여러 사용자 기록을 관리하고, 사용자의 생애 주기 관리를 간소화할 수 있습니다.

- 🔧 **관리자 패널**: 사용자 관리 시스템은 사용자의 가입 및 관리를 간소화하기 위해 설계되었으며, 사용자를 직접 추가하거나 CSV 가져오기를 통해 대량으로 추가할 수 있는 옵션을 제공합니다.

- 👥 **활성 사용자 지표**: 성능이 높은 사용자 수로 인해 영향을 받을 수 있는 시점을 측정하기 위해 활성 사용자 수와 어떤 모델이 사용되고 있는지를 실시간으로 모니터링하세요.

- 🔒 **기본 가입 역할**: 새 가입 사용자에 대한 기본 역할을 `pending`, `user`, 또는 `admin`으로 설정하여 사용자 권한 및 접근 수준을 유연하게 관리하세요.

- 🔒 **새 가입 제한**: 새 사용자 가입을 비활성화하는 옵션을 활성화하여 플랫폼 접근을 제한하고 고정된 사용자 수를 유지하세요.

- 🔒 **채팅 삭제 방지**: 모든 사용자가 자신의 채팅 메시지를 삭제하지 못하도록 설정을 관리자 권한으로 전환하여 모든 채팅 메시지가 감사 또는 규정 준수를 위해 유지될 수 있도록 합니다.

- 🔗 **웹훅 통합**: `Discord`, `Google Chat`, `Slack` 및 `Microsoft Teams`와 호환되는 웹훅을 통해 새 가입 이벤트를 구독하여 실시간 알림 및 자동화 기능을 제공합니다.

- 📣 **구성 가능한 알림 배너**: 관리자는 config.json에서 지속성을 가진 사용자 지정 배너를 생성할 수 있습니다. 콘텐츠, 배경 색상(`info`, `warning`, `error`, 또는 `success`) 및 해제 가능 여부를 포함한 다양한 옵션이 제공됩니다. 배너는 로그인한 사용자만 접근 가능해 민감한 정보의 기밀성을 보장합니다.

- 🛡️ **모델 허용 목록**: 관리자가 `user` 역할을 가진 사용자가 접근할 수 있는 모델을 허용 목록으로 지정하여 보안과 접근 제어를 강화합니다.

- 🔑 **커뮤니티 공유에 대한 관리자 제어**: 관리자는 `관리자 패널` > `설정` 메뉴의 토글 기능을 사용하여 모든 사용자에게 커뮤니티 공유를 활성화 또는 비활성화할 수 있습니다. 이 토글을 통해 관리자들은 접근성과 개인정보를 관리하고 안전한 환경을 유지할 수 있습니다. 관리자는 모든 사용자들에게 `커뮤니티에 공유` 버튼을 활성화 또는 비활성화할 옵션을 제공하여 커뮤니티 참여 및 협업을 제어할 수 있습니다.

- 📧 **신뢰할 수 있는 이메일 인증**: 신뢰할 수 있는 이메일 헤더를 사용하여 선택적으로 인증을 수행함으로써 Open WebUI 인스턴스를 보호하기 위한 추가적인 보안 및 인증 계층을 제공합니다.

- 🔒 **백엔드 역방향 프록시 지원**: Open WebUI의 백엔드와 Ollama 간의 직접 통신을 통해 보안을 강화합니다. 이 주요 기능은 Ollama를 로컬 네트워크(LAN)에 노출시키지 않아도 됩니다. Open WebUI의 `/ollama/api` 경로로 이루어진 요청은 백엔드를 통해 Ollama로 원활하게 리디렉션되며, 전체적인 시스템 보안을 강화하고 추가적인 보호 계층을 제공합니다.

- 🔒 **인증**: Open WebUI는 SSO, OAuth, SAML, OIDC와 같은 연합 인증 방식을 기본적으로 지원하지 않습니다. 그러나 인증 역방향 프록시를 통해 인증을 위임하도록 설정할 수 있어 사실상 Single Sign-On(`SSO`) 환경을 구현할 수 있습니다. 이를 통해 사용자 인증과 관리를 중앙 집중화하고 보안과 사용자 편의를 강화할 수 있습니다. Open WebUI를 인증 역방향 프록시와 통합하여 기존 인증 시스템을 활용하고 Open WebUI에 대한 사용자 접근을 간소화할 수 있습니다. 이 기능을 설정하는 방법에 대한 자세한 내용은 [연합 인증 지원](https://docs.openwebui.com/features/sso)을 참조하세요.

- 🔓 **선택적 인증**: `WEBUI_AUTH`를 `False`로 설정하여 인증을 비활성화할 수 있는 유연성을 제공합니다. 이는 기존 사용자가 없는 새 설치의 경우 이상적인 솔루션이며 시연 목적에도 유용합니다.

- 🚫 **고급 API 보안**: 맞춤형 모델 필터를 기반으로 API 사용자를 차단하여 API 접근에 대한 보안과 제어를 강화하세요.

- ❗ **관리자 업데이트**: 관리자가 로그인할 때 즉각적인 업데이트 알림을 받아 최신 변경 사항과 시스템 상태를 알려드립니다.

- 👥 **사용자 그룹 관리**: 원활한 조직화와 제어를 위해 사용자 그룹을 생성하고 관리하세요.

- 🔐 **그룹 기반 접근 제어**: 사용자 그룹에 따라 모델, 지식, 프롬프트 및 도구에 대한 세부적인 접근을 설정하여 더욱 제어된 안전한 환경을 제공합니다.

- 🛠️ **세부 사용자 권한**: 파일 업로드, 삭제, 편집, 임시 채팅을 포함하여 작업 공간 권한을 쉽게 관리하며 모델, 지식, 프롬프트, 도구 생성 권한을 관리하세요.

- 🔑 **LDAP 인증**: LDAP 지원을 통해 보안성과 확장성을 강화하여 사용자 관리를 간소화하세요.

- 🌐 **맞춤형 OpenAI 연결**: API를 위한 접두사 ID 지원 및 명시적인 모델 ID 지원을 포함하여 OpenAI 맞춤 설정으로 원활한 작동을 누리세요.

- 🔐 **Ollama API 키 관리**: Ollama 인증 정보 관리, 접두사 ID 지원을 포함하여 안전하고 효율적인 작업을 보장합니다.

- 🔄 **연결 관리**: 필요에 따라 개별 OpenAI 및 Ollama 연결을 쉽게 활성화하거나 비활성화합니다.

- 🎨 **직관적인 모델 작업 공간**: 사용자 및 그룹 전반에 걸친 모델을 관리하기 위한 사용자가 친화적인 인터페이스를 제공합니다.

- 🔑 **API 키 인증**: API 키 인증을 쉽게 활성화하거나 비활성화하여 보안을 강화하세요.

- 🔄 **통합 모델 초기화**: 관리자 설정에서 모든 모델을 일괄적으로 초기화 및 제거할 수 있는 원클릭 옵션 제공.

- 🔓 **유연한 모델 접근 제어**: 신뢰할 수 있는 환경에서 워크플로우를 단순화하기 위해 필요하지 않을 때 사용자 역할의 모델 접근 제어를 쉽게 우회할 수 있도록 하는 BYPASS_MODEL_ACCESS_CONTROL 환경 변수를 활용.

- 🔒 **구성 가능한 API 키 인증 제한**: 신뢰할 수 있는 환경에서 더 부드러운 설정을 위해 기본적으로 비활성화된 API 키 인증을 위한 엔드포인트 제한을 유연하게 구성 가능.

---
