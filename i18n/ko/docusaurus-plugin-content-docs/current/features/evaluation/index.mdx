---
sidebar_position: 6
title: "📝 평가"
---


## 왜 모델을 평가해야 하나요?

**Alex**를 만나보세요. 중간 규모 회사의 머신 러닝 엔지니어입니다. Alex는 수많은 AI 모델(GPTs, LLaMA 등)이 존재한다는 것을 알고 있지만, 어떤 모델이 현재 업무에 가장 적합할까요? 문서로는 모든 모델이 인상적으로 보이지만, Alex는 단순히 공개 리더보드에 의지할 수 없습니다. 모델은 상황에 따라 다르게 동작하며, 일부 모델은 평가 데이터셋으로 훈련되어 결과에 영향을 줄 수 있습니다(교묘하게!). 게다가 모델의 작성 방식이 가끔은 ... 어색하게 느껴질 수 있습니다.

이럴 때 Open WebUI가 도움이 됩니다. 이것은 Alex와 그의 팀이 실제 필요를 기준으로 모델을 평가할 수 있는 간단한 방법을 제공합니다. 복잡한 수학은 필요 없습니다. 힘든 작업도 없습니다. 단지 모델과 상호작용하며 좋아요 또는 싫어요 나타내주면 됩니다.

### 간단 요약

- **평가가 중요한 이유**: 너무 많은 모델이 있지만 모든 모델이 특정 요구에 적합하지는 않습니다. 일반 공개 리더보드를 항상 신뢰할 수는 없습니다.
- **해결 방법**: Open WebUI는 내장된 평가 시스템을 제공합니다. 모델 응답에 좋아요/싫어요를 표시하여 평가하세요.
- **뒤에서 벌어지는 일**: 평가 점수가 개인화된 리더보드를 조정하고 평가된 채팅의 스냅샷이 향후 모델 미세 조정에 사용됩니다!
- **평가 옵션**:
  - **Arena Model**: 비교할 모델을 임의로 선택합니다.
  - **일반 상호작용**: 평소처럼 채팅하고 응답을 평가하세요.

---

### 공개 평가만으로 충분하지 않은 이유는 무엇일까요?

- 공개 리더보드는 **귀하의** 특정 사용 사례에 맞게 조정되지 않았습니다.
- 일부 모델은 평가 데이터셋으로 훈련되어 결과의 공정성을 저해할 수 있습니다.
- 한 모델이 전반적으로 잘 작동할 수 있지만, 그 커뮤니케이션 스타일이나 응답이 원하는 “느낌”에 맞지 않을 수 있습니다.

### 솔루션: Open WebUI를 활용한 개인화된 평가

Open WebUI는 내장된 평가 기능을 제공하여 귀하와 팀이 특정 요구에 가장 적합한 모델을 찾을 수 있도록 돕습니다. 그러면서도 모델과 상호작용할 수 있습니다.

방법은 간단합니다!

- **채팅 중** 응답이 마음에 들면 좋아요를 표시하고, 마음에 들지 않으면 싫어요를 표시하세요. 메시지에 **형제 메시지**(재생성된 응답 또는 병렬 모델 비교의 일부)가 있는 경우, 여러분은 **개인 리더보드**를 구축하게 됩니다.
- **리더보드**는 관리 섹션에서 쉽게 접근 가능하며, 팀의 요구에 따라 어떤 모델이 가장 잘 수행되고 있는지 추적할 수 있습니다.

흥미로운 기능은? **응답을 평가할 때마다**, 시스템이 해당 대화의 **스냅샷**을 캡처하여 나중에 모델 개선 또는 향후 모델 학습에 사용됩니다. (참고로 이 기능은 아직 개발 중입니다!)

---

### AI 모델을 평가하는 두 가지 방법

Open WebUI는 AI 모델 평가를 위한 두 가지 간단한 접근 방식을 제공합니다.

### **1. Arena Model**

**Arena Model**은 사용 가능한 모델에서 무작위로 선택하며, 평가의 공정성 및 편견 없는 방식이 보장됩니다. 이는 잠재적 결함인 **생태학적 타당성**을 제거하는 데 도움이 됩니다 – 여러분이 의도적으로든 무의식적으로든 한 모델을 선호하지 않도록 합니다.

사용 방법:
- Arena Model 선택기에서 모델을 선택합니다.
- 일반적으로 사용하듯이 작동하지만, 이제 “아레나 모드”로 전환됩니다.
  
피드백이 리더보드에 영향을 미치려면 **형제 메시지**가 필요합니다. 형제 메시지가 무엇일까요? 형제 메시지는 동일한 쿼리로 생성된 대체 응답(메시지 재생성 또는 병렬 모델 생성을 생각해보세요)입니다. 이렇게 하면 응답을 **직접 비교**할 수 있습니다.

- **점수 팁**: 한 응답에 좋아요를 표시하면 다른 응답은 자동으로 싫어요가 됩니다. 따라서 신중하게 판단하고 진정으로 최고라고 믿는 메시지만 좋아요를 눌러야 합니다!
- 응답을 평가한 후, 리더보드를 확인하여 모델이 어떻게 쌓이고 있는지 볼 수 있습니다.

다음은 Arena Model 인터페이스가 작동하는 방식의 미리 보기입니다:

![Arena Model Example](/images/evaluation/arena.png)

더 깊이 탐구하고 싶으세요? [**Chatbot Arena**](https://lmarena.ai/) 스타일 설정을 복제할 수도 있습니다!

![Chatbot Arena Example](/images/evaluation/arena-many.png)

### **2. 일반 상호작용**

“아레나 모드”로 전환할 필요가 없습니다. Open WebUI를 일반적으로 사용하면서 일상 운영에서 AI 모델 응답을 평가할 수 있습니다. 모델 응답에 좋아요/싫어요를 표시하면 됩니다. 하지만 **피드백을 리더보드의 랭킹에 사용하려면**, **모델을 교체하고 다른 모델과 상호작용해야** 합니다. 이는 비교할 **형제 응답**을 보장하기 위함이며 – 두 모델간의 비교만이 순위에 영향을 미칩니다.

예를 들어, 일반 상호작용 중 평가하는 방법은 다음과 같습니다:

![Normal Model Rating Interface](/images/evaluation/normal.png)

그리고 아레나와 유사한 다중 모델 비교를 설정하는 예는 다음과 같습니다:

![Multi-Model Comparison](/images/evaluation/normal-many.png)

---

## 리더보드

평가 후, 관리 패널 아래의 **리더보드**를 확인하세요. 여기서 **Elo 평점 시스템**(체스 랭킹을 생각해보세요!)을 사용하여 모델들이 어떻게 성능을 발휘하는지 시각적으로 볼 수 있으며, 평가 중에 진정으로 두각을 나타내는 모델을 확인할 수 있습니다.

다음은 리더보드 레이아웃 샘플입니다:

![리더보드 예시](/images/evaluation/leaderboard.png)

### 주제 기반 재정렬

대화를 평가할 때 **주제로 태그를 추가**하여 더 세분화된 통찰을 얻을 수 있습니다. 이는 **고객 서비스, 창의적 글쓰기, 기술 지원** 등의 다양한 도메인에서 작업할 때 특히 유용합니다.

#### 자동 태그 지정
Open WebUI는 **대화 주제 기반으로 자동 태그 지정**을 시도합니다. 그러나 사용 중인 모델에 따라 자동 태그 지정 기능이 **때때로 실패하거나** 대화를 오해할 수 있습니다. 이런 일이 발생하면 보다 정확한 피드백을 위해 **대화를 수동으로 태그 지정**하는 것이 최선의 방법입니다.

- **수동 태그 지정 방법**: 응답을 평가할 때 대화의 맥락에 맞게 자신만의 태그를 추가할 수 있는 옵션이 제공됩니다.
  
이 단계를 건너뛰지 마세요! 태그 지정은 매우 강력한 도구로, 특정 주제를 기반으로 모델을 **재정렬**할 수 있도록 합니다. 예를 들어, 기술 지원 질문에 대한 답변을 제공하는 데 더 우수한 모델과 일반적인 고객 문의에 답변하는 모델을 비교할 수 있습니다.

이것이 재정렬이 어떻게 보이는지에 대한 예시입니다:

![주제별 리더보드 재정렬 예시](/images/evaluation/leaderboard-reranked.png)

---

### 부가 사항: 모델 미세 조정을 위한 대화 스냅샷

모델의 응답을 평가할 때마다 Open WebUI는 *그 대화의 스냅샷을 캡처*합니다. 이러한 스냅샷은 나중에 **사용자 정의 모델을 미세 조정**하는 데 사용할 수 있으므로 평가가 AI의 지속적인 개선에 기여하게 됩니다.

*(이 기능은 현재 개발 중이니 계속 업데이트를 기대해주세요!)*

---

## 요약

**간단히 말하면**, Open WebUI의 평가 시스템은 두 가지 뚜렷한 목표를 가지고 있습니다:
1. 모델을 **쉽게 비교할 수 있도록** 돕는 것.
2. 궁극적으로 개인적인 필요에 가장 적합한 모델을 찾는 것.

이 시스템의 핵심은 AI 모델 평가를 모든 사용자에게 **간단하고, 투명하며, 사용자 정의 가능**하게 만드는 것입니다. Arena Model과 Normal Chat Interaction을 통해 **본인의 구체적인 용도에 가장 적합한 AI 모델을 결정하는 데** 전적인 통제권을 부여합니다!

**항상 그렇듯이**, 모든 데이터는 **사용자의 인스턴스**에 안전하게 저장되며, 커뮤니티 공유를 명시적으로 **옵트인하지 않으면** 아무것도 공유되지 않습니다. 사용자의 프라이버시와 데이터 자율권은 항상 우선시됩니다.