---

sidebar_position: 4  
title: "🌐 OpenAI 호환 서버 시작하기"

---

## 개요

Open WebUI는 OpenAI/Ollama/Llama.cpp만을 위한 것이 아닙니다—로컬 또는 원격에서 실행되는 **OpenAI 호환 API를 구현하는 모든 서버**를 연결할 수 있습니다. 이는 다양한 언어 모델을 실행하거나 이미 선호하는 백엔드나 생태계를 가지고 있는 경우에 적합합니다. 이 가이드는 다음을 보여줍니다:

- OpenAI 호환 서버 설정 (몇 가지 인기 있는 옵션 포함)
- Open WebUI에 서버 연결
- 즉시 채팅 시작

## 1단계: OpenAI 호환 서버 선택

OpenAI 호환 API를 제공하는 많은 서버와 도구가 있습니다. 다음은 몇 가지 인기 있는 예입니다:

- [Llama.cpp](https://github.com/ggml-org/llama.cpp): 매우 효율적이며 CPU와 GPU에서 실행
- [Ollama](https://ollama.com/): 매우 사용자 친화적이며 크로스 플랫폼 지원
- [LM Studio](https://lmstudio.ai/): Windows/Mac/Linux용 풍부한 데스크탑 앱
- [Lemonade (ONNX TurnkeyML)](https://github.com/onnx/turnkeyml): NPU/iGPU 가속이 포함된 빠른 ONNX 기반 백엔드

자신에게 맞는 것을 선택하세요!

---

#### 🍋 Lemonade (ONNX TurnkeyML) 시작하기

Lemonade는 플러그앤플레이 ONNX 기반 OpenAI 호환 서버입니다. Windows에서 사용하려면:

1. [최신 `.exe` 다운로드](https://github.com/onnx/turnkeyml/releases)
2. `Lemonade_Server_Installer.exe` 실행
3. Lemonade 설치 프로그램을 사용하여 모델 설치 및 다운로드
4. 실행되면 API 엔드포인트는 다음과 같습니다:

   ```
   http://localhost:8000/api/v0
   ```

![Lemonade Server](/images/getting-started/lemonade-server.png)

[문서](https://github.com/onnx/turnkeyml)를 참조하세요.

---

## 2단계: Open WebUI에 서버 연결

1. 브라우저에서 Open WebUI를 엽니다.
2. ⚙️ **관리 설정** → **연결** → **OpenAI 연결**로 이동합니다.
3. ➕ **연결 추가**를 클릭합니다.

   - **URL**: 서버의 API 엔드포인트를 사용합니다 (예: Ollama에는 `http://localhost:11434/v1`, 또는 본인의 Llama.cpp 서버 주소).
   - **API Key**: 필요하지 않으면 공란으로 둡니다.

4. 저장을 클릭합니다.

*팁: Open WebUI를 Docker에서 실행하고 모델 서버를 호스트 머신에서 실행하는 경우, `http://host.docker.internal:<your-port>/v1`를 사용하세요.*

##### **Lemonade:** Lemonade 추가 시 URL로 `http://localhost:8000/api/v0`를 사용하세요.

![Lemonade Connection](/images/getting-started/lemonade-connection.png)

---

## 3단계: 채팅 시작!

채팅 메뉴에서 연결된 서버의 모델을 선택하고 시작하세요!

이것으로 끝입니다! Llama.cpp, Ollama, LM Studio 또는 Lemonade를 선택하든 관계없이 Open WebUI에서 여러 모델 서버를 쉽게 실험하고 관리할 수 있습니다.

--- 

🚀 나만의 완벽한 로컬 AI 환경을 구축하세요!