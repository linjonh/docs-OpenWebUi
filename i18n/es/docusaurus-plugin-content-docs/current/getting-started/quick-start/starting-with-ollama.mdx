---
sidebar_position: 1
title: "👉 Empezando con Ollama"
---

## Resumen

Open WebUI facilita la conexión y gestión de tu instancia de **Ollama**. Esta guía te llevará paso a paso por la configuración de la conexión, gestión de modelos y cómo comenzar.

---

## Paso 1: Configurando la Conexión con Ollama

Una vez que Open WebUI esté instalado y en funcionamiento, intentará automáticamente conectarse a tu instancia de Ollama. Si todo funciona correctamente, estarás listo para gestionar y usar modelos de inmediato.

Sin embargo, si encuentras problemas de conexión, la causa más común es una mala configuración de red. Puedes consultar nuestra [guía de resolución de problemas de conexión](/troubleshooting/connection-error) para obtener ayuda y solucionar estos problemas.

---

## Paso 2: Gestionando Tu Instancia de Ollama

Para gestionar tu instancia de Ollama en Open WebUI, sigue estos pasos:

1. Ve a **Configuraciones de Administrador** en Open WebUI.
2. Navega a **Conexiones > Ollama > Gestionar** (haz clic en el ícono de llave inglesa).
   Desde aquí, puedes descargar modelos, configurar ajustes y gestionar tu conexión con Ollama.

Así es como se ve la pantalla de gestión:

![Pantalla de Gestión de Ollama](/images/getting-started/quick-start/manage-ollama.png)

![Pantalla de Gestión de Ollama](/images/getting-started/quick-start/manage-modal-ollama.png)


## Una Forma Rápida y Eficiente de Descargar Modelos

Si buscas una opción más rápida para comenzar, puedes descargar modelos directamente desde el **Selector de Modelos**. Simplemente escribe el nombre del modelo que deseas y, si aún no está disponible, Open WebUI te pedirá que lo descargues desde Ollama.

Aquí tienes un ejemplo de cómo funciona:

![Solicitud de Descarga de Ollama](/images/getting-started/quick-start/selector-ollama.png)

Este método es perfecto si deseas evitar navegar por el menú de Configuraciones de Administrador y empezar a usar tus modelos de inmediato.

---

## ¡Todo Listo!

¡Eso es todo! Una vez que la conexión esté configurada y tus modelos descargados, estarás listo para empezar a usar Ollama con Open WebUI. Ya sea que estés explorando nuevos modelos o ejecutando los existentes, Open WebUI hace que todo sea simple y eficiente.

Si encuentras algún problema o necesitas más orientación, consulta nuestra [sección de ayuda](/troubleshooting) para soluciones detalladas. ¡Disfruta usando Ollama! 🎉