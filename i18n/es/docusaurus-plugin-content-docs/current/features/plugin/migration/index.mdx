---
sidebar_position: 4
title: "ğŸšš Migrando Herramientas y Funciones: 0.4 a 0.5"
---

# ğŸšš GuÃ­a de MigraciÃ³n: Open WebUI 0.4 a 0.5

Â¡Bienvenido a la guÃ­a de migraciÃ³n a Open WebUI 0.5! Si estÃ¡s trabajando en proyectos existentes o construyendo nuevos, esta guÃ­a te explicarÃ¡ los cambios clave de la **versiÃ³n 0.4 a la 0.5** y te proporcionarÃ¡ una hoja de ruta fÃ¡cil de seguir para actualizar tus funciones. Â¡Hagamos esta transiciÃ³n lo mÃ¡s fluida posible! ğŸ˜Š

---

## ğŸ§ Â¿QuÃ© ha cambiado y por quÃ©?

Con Open WebUI 0.5, hemos rediseÃ±ado la arquitectura para hacer el proyecto **mÃ¡s simple, unificado y escalable**. AquÃ­ tienes la visiÃ³n general:

- **Arquitectura anterior:** ğŸ¯ Anteriormente, Open WebUI estaba construido sobre una **arquitectura de subaplicaciones** donde cada aplicaciÃ³n (por ejemplo, `ollama`, `openai`) era una aplicaciÃ³n FastAPI separada. Esto causaba fragmentaciÃ³n y complejidad adicional al gestionar aplicaciones.
- **Nueva Arquitectura:** ğŸš€ Con la versiÃ³n 0.5, hemos pasado a una **Ãºnica aplicaciÃ³n FastAPI** con mÃºltiples **routers**. Esto significa mejor organizaciÃ³n, flujo centralizado y menor redundancia.

### Cambios Clave:
AquÃ­ tienes un resumen de lo que ha cambiado:
1. **Las aplicaciones se han convertido en Routers.**
   - Anteriormente: `open_webui.apps`
   - Ahora: `open_webui.routers`

2. **Estructura principal simplificada.**
   - La antigua `open_webui.apps.webui` se ha transformado en `open_webui.main`, convirtiÃ©ndose en el punto de entrada central del proyecto.

3. **Endpoint de API Unificado**
   - Open WebUI 0.5 introduce una **funciÃ³n unificada**, `chat_completion`, en `open_webui.main`, reemplazando funciones separadas para modelos como `ollama` y `openai`. Esto ofrece una experiencia de API consistente y optimizada. Sin embargo, el **sucesor directo** de estas funciones individuales es `generate_chat_completion` de `open_webui.utils.chat`. Si prefieres una solicitud POST ligera sin manejar anÃ¡lisis adicionales (por ejemplo, archivos, herramientas o extras), esta funciÃ³n utilitaria es probablemente lo que necesitas.

#### Ejemplo:
```python
# Flujo completo de API con anÃ¡lisis (nueva funciÃ³n):
from open_webui.main import chat_completion

# Solicitud POST ligera y directa (sucesor directo):
from open_webui.utils.chat import generate_chat_completion
```

Â¡Elige el enfoque que mejor se adapte a tu caso de uso!

4. **Firmas de funciones actualizadas.**
   - Las firmas de funciones ahora se adhieren a un nuevo formato, requiriendo un objeto `request`.
   - El objeto `request` se puede obtener usando el parÃ¡metro `__request__` en la firma de la funciÃ³n. A continuaciÃ³n, un ejemplo:

```python
class Pipe:
    def __init__(self):
        pass

    async def pipe(
        self,
        body: dict,
        __user__: dict,
        __request__: Request, # Nuevo parÃ¡metro
    ) -> str:
        # Escribe tu funciÃ³n aquÃ­
```

ğŸ“Œ **Â¿Por quÃ© hicimos estos cambios?**
- Para simplificar la base de cÃ³digo, haciÃ©ndola mÃ¡s fÃ¡cil de extender y mantener.
- Para unificar las API y ofrecer una experiencia mÃ¡s optimizada para desarrolladores.
- Para mejorar el rendimiento consolidando elementos redundantes.

---

## âœ… GuÃ­a de MigraciÃ³n Paso a Paso

Sigue esta guÃ­a para actualizar tu proyecto sin problemas.

---

### ğŸ”„ 1. Cambiando de `apps` a `routers` 

Todas las aplicaciones han sido renombradas y reubicadas bajo `open_webui.routers`. Esto afecta las importaciones en tu base de cÃ³digo.

Cambios rÃ¡pidos para las rutas de importaciÃ³n:

| **Ruta Antigua**                       | **Nueva Ruta**                      |
|---------------------------------------|-------------------------------------|
| `open_webui.apps.ollama`              | `open_webui.routers.ollama`         |
| `open_webui.apps.openai`              | `open_webui.routers.openai`         |
| `open_webui.apps.audio`               | `open_webui.routers.audio`          |
| `open_webui.apps.retrieval`           | `open_webui.routers.retrieval`      |
| `open_webui.apps.webui`               | `open_webui.main`                   |


### ğŸ“œ Un Ejemplo Importante  

Para clarificar el caso especial de la aplicaciÃ³n principal (`webui`), aquÃ­ hay una regla simple:

- **Â¿Estaba en `webui`?** Ahora estÃ¡ en la raÃ­z del proyecto o en `open_webui.main`.  
- Por ejemplo:  
    - **Antes (0.4):**  
      ```python  
      from open_webui.apps.webui.models import SomeModel  
      ```  
    - **DespuÃ©s (0.5):**  
      ```python  
      from open_webui.models import SomeModel  
      ```  

En general, **solo reemplaza `open_webui.apps` por `open_webui.routers`, Â¡excepto `webui`, que ahora es `open_webui.main`!**


---

### ğŸ‘©â€ğŸ’» 2. Actualizando Declaraciones de ImportaciÃ³n

Veamos cÃ³mo se verÃ¡ esta actualizaciÃ³n en tu cÃ³digo:

#### Antes:
```python
from open_webui.apps.ollama import main as ollama
from open_webui.apps.openai import main as openai
```

#### DespuÃ©s:
```python
# Importaciones de routers separadas
from open_webui.routers.ollama import generate_chat_completion
from open_webui.routers.openai import generate_chat_completion

# O usa el endpoint unificado
from open_webui.main import chat_completion
```

**ğŸ’¡ Consejo Pro:** Prioriza el endpoint unificado (`chat_completion`) por simplicidad y compatibilidad futura.

### ğŸ“ **Nota adicional: Elegir entre `main.chat_completion` y `utils.chat.generate_chat_completion`**

Dependiendo de su caso de uso, puede elegir entre:

1. **`open_webui.main.chat_completion`:**
    - Simula realizar una solicitud POST a `/api/chat/completions`.
    - Procesa archivos, herramientas y otras tareas diversas.
    - Lo mejor cuando desea que el flujo completo de API se maneje automÃ¡ticamente.

2. **`open_webui.utils.chat.generate_chat_completion`:**
    - Realiza directamente una solicitud POST sin manejar anÃ¡lisis adicionales o tareas.
    - Este es el **sucesor directo** de las funciones anteriores `main.generate_chat_completions`, `ollama.generate_chat_completion` y `openai.generate_chat_completion` en Open WebUI 0.4.
    - Ideal para escenarios simplificados y mÃ¡s livianos.

#### Ejemplo:
```python
# Ãšselo para el flujo completo de API con anÃ¡lisis:
from open_webui.main import chat_completion

# Ãšselo para una solicitud POST simplificada y directa:
from open_webui.utils.chat import generate_chat_completion
```

---

### ğŸ“‹ 3. Adaptarse a Firmas de FunciÃ³n Actualizadas  

Hemos actualizado las **firmas de funciÃ³n** para adaptarse mejor a la nueva arquitectura. Si busca un reemplazo directo, comience con la funciÃ³n utilitaria liviana `generate_chat_completion` de `open_webui.utils.chat`. Para el flujo completo de API, use la nueva funciÃ³n unificada `chat_completion` en `open_webui.main`.

#### Cambios en la Firma de FunciÃ³n:  

| **Anterior**                                 | **Sucesor Directo (Nuevo)**             | **OpciÃ³n Unificada (Nueva)**               |
|---------------------------------------------|------------------------------------------|-------------------------------------------|
| `openai.generate_chat_completion(form_data: dict, user: UserModel)` | `generate_chat_completion(request: Request, form_data: dict, user: UserModel)` | `chat_completion(request: Request, form_data: dict, user: UserModel)` |

- **Sucesor Directo (`generate_chat_completion`)**: Un reemplazo ligero y directo 1:1 para los mÃ©todos anteriores de `ollama`/`openai`.  
- **OpciÃ³n Unificada (`chat_completion`)**: Ãšselo para el flujo completo de API, incluyendo anÃ¡lisis de archivos y funcionalidad adicional.  

#### Ejemplo:

Si utiliza `chat_completion`, asÃ­ deberÃ­a verse ahora su funciÃ³n:

### ğŸ› ï¸ CÃ³mo Refactorizar Su FunciÃ³n Personalizada
Reescribamos una funciÃ³n de ejemplo para que coincida con la nueva estructura:

#### Antes (0.4):
```python
from pydantic import BaseModel
from open_webui.apps.ollama import generate_chat_completion

class User(BaseModel):
    id: str
    email: str
    name: str
    role: str

class Pipe:
    def __init__(self):
        pass

    async def pipe(self, body: dict, __user__: dict) -> str:
        # Llama al endpoint de OpenAI
        user = User(**__user__)
        body["model"] = "llama3.2:latest"
        return await ollama.generate_chat_completion(body, user)
```

#### DespuÃ©s (0.5):
```python
from pydantic import BaseModel
from fastapi import Request

from open_webui.utils.chat import generate_chat_completion


class User(BaseModel):
    id: str
    email: str
    name: str
    role: str


class Pipe:
    def __init__(self):
        pass

    async def pipe(
        self,
        body: dict,
        __user__: dict,
        __request__: Request,
    ) -> str:
        # Usa el endpoint unificado con firma actualizada
        user = User(**__user__)
        body["model"] = "llama3.2:latest"
        return await generate_chat_completion(__request__, body, user)
```

### Notas Importantes:
- Debe pasar un objeto `Request` (`__request__`) en la nueva firma de funciÃ³n.
- Otros parÃ¡metros opcionales (como `__user__` y `__event_emitter__`) aseguran flexibilidad para casos de uso mÃ¡s complejos.

---

### ğŸŒŸ 4. Resumen: Conceptos Clave en TÃ©rminos Simples

AquÃ­ tiene un resumen rÃ¡pido para recordar:
- **Apps ahora son Routers:** Actualice todas las importaciones de `open_webui.apps` â¡ï¸ `open_webui.routers`.
- **Endpoint Unificado:** Use `open_webui.main.chat_completion` para mayor simplicidad si involucra tanto `ollama` como `openai`.
- **Adapte las Firmas de FunciÃ³n:** AsegÃºrese de que sus funciones pasen el objeto `request` requerido.

---

## ğŸ‰ Â¡Hurra! Â¡EstÃ¡ Listo!

Â¡Eso es todo! Ha migrado exitosamente de **Open WebUI 0.4 a 0.5**. Al refactorizar sus importaciones, usar el endpoint unificado y actualizar las firmas de funciÃ³n, estarÃ¡ completamente equipado para aprovechar las Ãºltimas caracterÃ­sticas y mejoras en la versiÃ³n 0.5.

---

ğŸ’¬ **Â¿Preguntas o Comentarios?**
Si encuentra algÃºn problema o tiene sugerencias, no dude en abrir un [issue de GitHub](https://github.com/open-webui/open-webui) o preguntar en los foros de la comunidad.

Â¡Feliz programaciÃ³n! âœ¨