---
sidebar_position: 3
title: "🧠 排查 RAG (检索增强生成) 问题"
---

检索增强生成 (RAG) 使语言模型能够通过检索相关信息并将其输入模型来对外部内容（文档、知识库等）进行推理。但如果事情并未按预期工作（例如，模型“幻觉”或遗漏相关信息），通常这并不是模型的问题，而是上下文问题。

让我们分解常见原因和解决方案，让你的 RAG 准确性得到提升！🚀

## 常见 RAG 问题及解决方法 🛠️

### 1. 模型“看不到”你的内容 👁️❌

这是最常见的问题——通常是由于内容摄取过程中的问题导致的。模型并不是因为错误而“幻觉”，而是因为它从未接收到正确的内容。

✅ 解决方法：检查你的内容提取设置

- 导航到：**管理设置 > 文档**。
- 确保使用了强大的内容提取引擎，例如：
  - Apache Tika
  - Docling
  - 自定义提取器（取决于你的文档类型）

📌 提示：尝试上传文档并预览提取的内容。如果是空白或关键部分缺失，则需要调整提取器设置或使用不同的引擎。

---

### 2. 仅使用了文档的一小部分 📄➡️✂️

Open WebUI 默认设计用于支持具有有限上下文窗口的模型。例如，许多本地模型（如 Ollama 的默认模型）限制在 2048 个标记内。因此，Open WebUI 会积极裁剪检索的内容以适应假设的可用空间。

✅ 解决方法：

- 前往 **管理设置 > 文档**
- 可以选择：
  - 💡 启用“绕过嵌入和检索”——将完整内容直接发送，而不施加严格的检索过滤。
  - 🔍 打开“完整上下文模式”——将更全面的内容注入模型提示。

📌 警告：注意上下文限制——如果模型无法处理更多的标记，仍然会被截断。

---

### 3. 标记限制过短 ⏳

即使检索有效，模型可能仍无法处理接收到的所有内容——因为它处理能力有限。

默认情况下，许多模型（特别是 Ollama 托管的 LLM）限制在 2048 个标记的上下文窗口。这意味着你检索的数据中只有一部分会被使用。

✅ 解决方法：

- 🛠️ 扩展模型的上下文长度：
  - 导航到 **模型编辑器或聊天控制**
  - 修改上下文长度（例如，增加到 8192+ 个标记，如果支持）

ℹ️ 注意：默认的 2048 个标记是一个主要限制。为了获得更好的 RAG 结果，我们建议使用支持更长上下文的模型。

✅ 替代方法：使用具有更大上下文容量的外部 LLM

- 尝试 GPT-4、GPT-4o、Claude 3、Gemini 1.5 或 Mixtral，它们支持 8k+ 的上下文
- 与 Ollama 进行性能比较——注意当可以注入更多内容时的准确性差异！

📌 提示：为生产使用场景中的更好 RAG 性能，建议使用外部模型。

---

### 4. 嵌入模型质量低或不匹配 📉🧠

糟糕的嵌入 = 糟糕的检索。如果你的内容的向量表示质量很差，检索器无法拉取正确的内容——无论你的 LLM 多么强大。

✅ 解决方法：

- 更换为高质量的嵌入模型（例如 all-MiniLM-L6-v2、Instructor X 或 OpenAI 嵌入）
- 前往：**管理设置 > 文档**
- 更换模型后，确保：
  - ⏳ 重新索引所有现有文档，使新嵌入生效。

📌 记住：嵌入质量直接影响检索的内容。

---

### 5. ❌ 400: 'NoneType' 对象没有 'encode' 属性

此错误表明嵌入模型配置错误或缺失。当 Open WebUI 尝试创建嵌入但没有加载有效的模型时，它无法处理文本——结果就是这个难以理解的错误。

💥 原因：
- 嵌入模型设置不正确。
- 可能未完全下载。
- 或者如果你使用外部嵌入模型，可能无法访问。

✅ 解决方法：

- 前往：**管理设置 > 文档 > 嵌入模型**
- 再次保存嵌入模型，即使它已经被选中。这会强制重新检查/下载。
- 如果你使用远程/外部嵌入工具，请确保它正在运行且可被 Open WebUI 访问。

📌 提示：修复配置后，尝试重新嵌入文档并验证日志中无错误显示。

---

## 🧪 专家提示：尝试使用 GPT-4o 或 GPT-4

如果你不确定问题出在检索、标记限制还是嵌入上——可以临时尝试使用 GPT-4o（例如，通过 OpenAI API）。如果结果突然变得更准确，这强烈表明你的本地模型上下文限制（Ollama 默认 2048 个标记）是瓶颈。

- GPT-4o 可处理更大的输入（128k 个标记！）
- 提供了一个良好的基准，用于评估系统的 RAG 可靠性

---

## 总结清单 ✅

| 问题 | 解决方法 |
|--------|------|
| 🤔 模型无法“看见”内容 | 检查文档提取器设置 |
| 🧹 只使用了部分内容 | 启用全文上下文模式或跳过嵌入 |
| ⏱ 被2048个令牌限制 | 增大模型上下文长度或使用大上下文LLM |
| 📉 检索不准确 | 切换到更好的嵌入模型，然后重新建立索引 |
| 仍然困惑？ | 使用GPT-4o进行测试并比较输出结果 |

---

通过优化这些领域——提取、嵌入、检索和模型上下文——可以显著提升LLM处理文档的准确性。不要让2048令牌窗口或弱检索流程限制你的AI的能力 🎯。
