---
sidebar_position: 400
title: "⭐ 功能"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能 ⭐

- 🚀 **轻松安装**: 使用 Docker、Kubernetes、Podman、Helm Charts (`kubectl`, `kustomize`, `podman` 或 `helm`) 无缝安装，支持 `:ollama` 图像（包含 Ollama）和 `:cuda`（支持 CUDA），提供顺畅的使用体验。

- 🛠️ **引导式初始设置**: 在首次设置过程中清晰展示，包括明确提示创建管理员账号的步骤。

- 🤝 **OpenAI API 集成**: 无缝集成与 OpenAI 兼容的 API，可与 Ollama 模型一起进行多样化对话。OpenAI API URL 可以定制，从而无缝将 Open WebUI 集成至各种第三方应用。

- 🛡️ **细化的权限和用户组管理**: 允许管理员创建详细的用户角色、用户组和工作区权限，我们为所有用户提供了一个安全的使用环境。这种细化不仅增强了安全性，还支持个性化用户体验，培育用户的责任感和归属感。

- 📱 **响应式设计**: 在台式电脑、笔记本电脑和移动设备上享受无缝体验。

- 📱 **适用于移动端的渐进式 Web 应用 (PWA)**: 在移动设备上体验本地渐进式 Web 应用程序，支持离线访问 `localhost` 或个人域，并提供流畅的用户界面。要在设备上安装我们的 PWA，它必须在安全环境中传输，通常需要通过 HTTPS 提供服务。

  :::info

  - 要设置 PWA，您需要了解一些技术，例如 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）。利用这些工具可以简化根据需求定制和部署 PWA 的过程。虽无“一键安装”功能，而通过 HTTPS 安全部署您的 Open WebUI 实例需要用户经验，但使用这些资源可以更轻松地创建和部署符合您需求的 PWA。

  :::

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**: 提升您的 LLM 体验，支持全面的 Markdown、LaTeX 和富文本功能，增强交互效果。

- 🧩 **模型构建器**: 直接在 Open WebUI 上从基础 Ollama 模型轻松创建自定义模型。创建和添加自定义角色与代理，定制模型元素，并通过 [Open WebUI 社区](https://openwebui.com/) 集成轻松导入模型。

- 📚 **本地和远程 RAG 集成**: 借助最先进的检索增强生成 (RAG) 技术，探索聊天互动的未来并处理您的文档。在工作区的 `Documents` 标签中加载文档后，可通过查询前加井号键 [`#`] 或提示开始时加井号键 [`#`] 和 URL 集成网页内容。

- 📄 **文档提取**: 从各种文档格式中提取文本和数据，包括 PDF、Word 文档、Excel 表格、PowerPoint 演示等。我们的高级文档处理功能支持无缝集成您的知识库，确保从复杂文档中精确提取和生成内容，同时保留其结构和格式。

- 🔍 **RAG 的网页搜索**: 通过选择多种搜索提供商进行网页搜索，并将结果直接注入您的本地检索增强生成 (RAG) 体验。

- 🌐 **网页浏览功能**: 使用 `#` 命令加上 URL，将网站无缝集成到您的聊天体验中。这种功能直接将网页内容融入您的对话，增强您互动的丰富性和深度。

- 🎨 **图像生成集成**: 无缝整合图像生成功能，以动态视觉内容丰富您的聊天体验。

- ⚙️ **并发模型利用**: 同时轻松与多个模型互动，充分利用它们的独特优势以获得最佳响应。并行利用多种模型模式，提升用户体验。

- 🔐 **基于角色的访问控制 (RBAC)**: 确保通过权限限制实现安全访问。只有授权用户可以访问您的 Ollama，而模型创建和拉取权限仅供管理员使用。

- 🌐🌍 **多语言支持**: 通过我们的国际化 (`i18n`) 支持，以您偏好的语言体验 Open WebUI。我们邀请您加入我们，扩展所支持的语言！我们正在积极寻找贡献者！

- 🌟 **持续更新**: 我们致力于通过定期更新、修复和新增功能来改进 Open WebUI。

## 还有许多其他卓越的功能，包括... ⚡️

---

### 🔧 支持管道

- 🔧 **管道框架**: 通过我们模块化的插件框架无缝集成和定制您的 Open WebUI 体验，以增强自定义和功能性 (https://github.com/open-webui/pipelines)。该框架可以轻松添加自定义逻辑并集成 Python 库，从 AI 代理到家庭自动化 API。

- 📥 **上传管道**: 可以直接通过 `管理面板` > `设置` > `管道` 菜单上传管道，简化管道管理流程。

#### 我们的管道框架的可能性是无限的，而且无限广阔。从几个预构建的管道开始，帮助您起步！

- 🔗 **功能调用**: 通过管道无缝集成 [功能调用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，以增强您的 LLM 交互和高级功能调用能力。

- 📚 **自定义 RAG**: 集成 [自定义检索增强生成 (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag) 管道，以增强您的 LLM 交互和自定义 RAG 逻辑。

- 📊 **使用 Langfuse 进行消息监控**: 通过 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管道实时监控和分析消息交互统计数据。

- ⚖️ **用户限流**: 使用 [速率限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 管道高效管理 API 使用，通过控制发送到 LLM 的请求流量防止超出速率限制。

- 🌍 **实时 LibreTranslate 翻译**: 使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管道将实时翻译集成到您的 LLM 交互中，实现跨语言通信。
  - 请注意，这个管道需要在 Docker 容器中进行 LibreTranslate 的进一步设置才能正常工作。

- 🛡️ **过滤有害消息**: 我们的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管道会自动过滤有害消息，以保持干净安全的聊天环境。

- 🔒 **LLM 护卫**: 使用带有 [LLM 护卫](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管道的提示注入扫描器确保安全的 LLM 交互，检测并减轻针对大型语言模型的复杂输入操作。这为您的 LLM 提供数据泄漏保护，并增加抵御提示注入攻击的能力。

- 🕒 **对话回合限制**: 使用 [对话回合限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 管道设置对话回合限制，改善交互管理。

- 📈 **OpenAI 生成统计**: 我们的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管道提供详细的 OpenAI 模型生成统计信息。

- **🚀 多模型支持**: 与各种 AI 模型的无缝集成 (https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers)，扩展选择范围并与多种语言模型交互。

#### 除了广泛的功能和定制选项，我们还提供 [一系列示例管道](https://github.com/open-webui/pipelines/tree/main/examples) 和 [一个实践示例脚手架管道](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) 帮助您起步。这些资源将简化您的开发流程，并让您快速创建强大的 LLM 交互，用管道和 Python 进行开发。编码愉快！ 💡

---

### 🖥️ 用户体验

- 🖥️ **直观界面**: 聊天界面以用户为中心，借鉴了 ChatGPT 的用户界面设计。

- ⚡ **快速响应**: 享受可靠快速的响应性能。

- 🎨 **启动画面**: 一个简单的加载启动画面，提升用户体验。

- 🌐 **个性化界面**: 从设置 > 界面中选择全新设计的搜索首页或经典聊天界面，实现个性化体验。

- 📦 **Pip 安装方法**: 通过命令 `pip install open-webui` 安装 Open WebUI，简化了安装过程，使新用户更容易上手。更多信息请访问：https://pypi.org/project/open-webui/。

- 🌈 **主题自定义**: 通过多种选择个性化您的 Open WebUI 使用体验，包括丰富而精致的主题、可自定义的聊天背景图片和三种模式选项：浅色模式、深色模式或 OLED 深色模式 - 或者让*她*为您选择！;)

- 🖼️ **自定义背景支持**: 从“设置 > 界面”中设置自定义背景，个性化您的体验。

- 📝 **支持 Markdown 的丰富横幅**: 通过支持 Markdown 的横幅创建更具视觉吸引力的公告，实现更丰富和动感的内容显示。

- 💻 **代码语法高亮显示**: 我们的语法高亮功能增强了代码的可读性，使您的代码清晰明了。

- 🗨️ **用户消息中的 Markdown 渲染**: 用户消息现在支持 Markdown 渲染，提升了可读性和交互性。

- 🎨 **灵活的文本输入选项**: 根据用户偏好在富文本输入和传统文本区域输入之间切换，为聊天提供高级格式或简单文本输入的选择。

- 👆 **轻松分享代码**: 通过便捷的代码复制选项简化分享与协作，包括代码块中的悬浮复制按钮和代码片段的点击复制功能，节省时间并减少麻烦。

- 🎨 **交互式工件**: 直接在界面中渲染网页内容和 SVG，支持快速迭代和实时更改，提升创造力与生产力。

- 🖊️ **实时代码编辑**: 增强的代码块支持在 LLM 响应中直接进行实时编辑，并支持工件的实时重载，从而简化编码和测试流程。

- 🔍 **增强的 SVG 交互**: 对 SVG 图像（包括 Mermaid 图表）提供平移和缩放功能，让用户能够深入探索和理解复杂概念。

- 🔍 **文本选择快捷操作**: 在 LLM 响应中选择文本时会显示浮动按钮，提供“提问”或“解释”等深度交互选项，提升整体用户体验。

- ↕️ **双向聊天支持**: 您可以轻松切换左到右和右到左的聊天方向，以适应各种语言偏好。

- 📱 **移动设备适配性**: 在移动设备上可以通过简单的滑动手势打开和关闭侧边栏。

- 🤳 **支持设备的触觉反馈**: Android 设备支持触觉反馈，在某些交互中提供沉浸式的触觉体验。

- 🔍 **用户设置搜索**: 快速搜索设置字段，提升使用和导航的便利性。

- 📜 **离线 Swagger 文档**: 离线访问对开发者友好的 Swagger API 文档，确保无论身处何地都能完全访问。

- 💾 **性能优化**: 延迟加载大型依赖项以最小化初始内存使用，提高性能并减少加载时间。

- 🚀 **持久且可扩展的配置**: Open WebUI 的配置存储在数据库（webui.db）中，支持无缝负载均衡、高可用性设置，以及跨多个实例持久的配置，方便访问和重用您的配置。

- 🔄 **便携的导入/导出功能**: 轻松导入和导出 Open WebUI 配置，简化在多个系统之间复制设置的过程。

- ❓ **快速访问文档与快捷键**: 主界面屏幕右下角的问号按钮（适用于更大的屏幕，如台式电脑和笔记本）让用户可以轻松访问 Open WebUI 文档页面和可用的键盘快捷键。

- 📜 **更新日志与检查更新**: 用户可通过“设置 > 关于 > 查看新内容”菜单访问全面的更新日志并检查更新，快速了解最新功能、改进和错误修复，同时可以检查是否有新版本。

---

### 💬 会话

- 💬 **真正的异步聊天**: 支持真正的异步聊天功能，让您享受不中断的多任务操作，随时创建聊天、切换页面并返回查看已准备好的响应。

- 🔔 **聊天完成通知**: 当聊天在非活动选项卡中完成时，通过即时的 UI 通知保持更新，确保您不会错过完成的响应。

- 🌐 **通知 Webhook 集成**: 支持长时间运行聊天的及时通知或满足外部集成需求，即使您的标签页已关闭，也能获取可配置的 Webhook 通知。

- 📚 **频道（测试版）**: 探索用户与 AI 之间的实时协作，类似 Discord/Slack 风格的聊天室，创建频道机器人，解锁异步通信，支持多代理主动工作流程。

- 🖊️ **频道中的打字指示器**: 通过频道中的实时打字指示器增强协作性，让每个人都保持参与和了解。

- 👤 **用户状态指示器**: 通过点击频道中的用户头像快速查看用户状态，提供更好的协调与可用性洞察。

- 💬 **聊天控制**: 轻松调整每次聊天会话的参数，为您的互动提供更精确的控制。

- 💖 **收藏回复管理**: 直接从聊天概览中轻松标记和组织收藏的回复，提升检索和访问偏好回复的便利性。

- 📌 **固定聊天**: 支持固定聊天，让您轻松访问重要对话。

- 🔍 **RAG嵌入支持**: 可以在`管理员面板` > `设置` > `文档`菜单中直接更改检索增强生成（RAG）嵌入模型，提升文档处理功能。此功能支持Ollama和OpenAI模型。

- 📜 **RAG功能中的引文**: 检索增强生成（RAG）功能加入引用，使用户能够轻松追踪提供给LLM的文档上下文和参考点。

- 🌟 **增强的RAG流水线**: 我们的RAG嵌入功能新增可切换的混合搜索子功能，通过`BM25`以及`CrossEncoder`驱动的重新排序来提升RAG功能，同时具有可配置的相关性分数阈值。

- 📹 **YouTube RAG流水线**: 专用的检索增强生成（RAG）流水线，可以通过视频URL总结YouTube视频，直接与视频转录文件进行顺畅互动。

- 📁 **全面的文档检索**: 在全文文件检索和传统的片段检索间切换，支持总结等任务并提升文档处理能力。

- 🌟 **RAG引文相关性**: RAG结果中新增相关性百分比，能轻松评估引文的准确性。

- 🗂️ **高级RAG**: 通过智能预处理聊天历史来确定最佳查询，从而改善RAG的准确性。

- 📚 **RAG中内嵌引文**: 为检索增强生成（RAG）回复提供无缝的内嵌引文，改善可追溯性并为新上传的文件提供来源清晰度。

- 📁 **处理大段文本**: 可选择将粘贴的大段文本转换为文件上传，直接用于RAG，保持聊天界面更整洁。

- 🔄 **多模态支持**: 可轻松与支持多模态交互的模型进行互动，包括图像（例如，LLaVA）。

- 🤖 **多模型支持**: 快速切换不同模型以实现多样化的聊天互动。

- 🔀 **合并多模型聊天回复**: 将多个模型的回复合并为单一连贯回复，以增强对话质量。

- ✅ **聊天中支持同一模型的多个实例**: 增强的多模型聊天功能支持添加同一模型的多个实例。

- 💬 **临时聊天功能**: 推出了临时聊天功能，取代旧的聊天历史设置，以增强用户互动的灵活性。

- 🖋️ **用户消息编辑**: 改进用户聊天编辑功能，允许保存更改而不发送。

- 💬 **高效的对话编辑**: 使用Cmd/Ctrl+Shift+Enter快捷键快速直观地创建新的消息对，简化对话长度测试。

- 🖼️ **客户端图片压缩**: 通过客户端图片压缩节省带宽并提升性能，用户可在设置 > 界面中选择上传前压缩图片。

- 👥 **@模型集成**: 在聊天中通过无缝切换至任何可访问的本地或外部模型，用户可以利用多个模型的集体智能。只需在聊天中使用`@`命令指定模型名称即可完成。

- 🏷️ **会话标签**: 使用高效的`tag:`查询系统轻松分类和定位带标签的聊天，方便快速参考和简化数据收集，同时无需在界面中制造混乱。

- 🧠 **自动标记**: 聊天内容可以选择自动标记，以提高组织效率，与自动生成标题相类似。

- 👶 **聊天克隆**: 可以轻松克隆和保存任何聊天的快照供未来参考或继续。此功能使您可以轻松从中断点继续或与他人共享会话。只需点击聊天下拉选项中的`克隆`按钮即可创建聊天副本。您的克隆跟得上吗？

- ⭐ **可视化的对话流程**: 交互式消息图表改进了对对话流程的可视化，增强对复杂讨论的理解和导航。

- 📁 **聊天文件夹**: 将聊天整理到文件夹中，拖放管理更方便，并能无缝导出以便分享或分析。

- 📤 **便捷的聊天导入**: 通过拖放聊天导出文件（JSON）到侧边栏将聊天导入工作区。

- 📜 **提示预设支持**: 使用聊天输入框中的`/`命令即时访问自定义的预设提示。轻松加载预定义的对话启动器，加速您的交互。通过[Open WebUI Community](https://openwebui.com/)集成导入提示，或创建自己的提示！

- 📅 **提示变量支持**: 可以在系统提示中使用提示变量如`{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}`和`{{USER_LOCATION}}`，或通过斜杠命令直接在聊天中选择提示。
  - 请注意，`{{USER_LOCATION}}`提示变量需要通过HTTPS的安全连接。要使用此特定提示变量，请确保在`设置` > `界面`菜单中启用了`{{USER_LOCATION}}`。
  - 请注意，`{{CLIPBOARD}}`提示变量需要访问您设备的剪贴板。

- 🧠 **记忆功能**: 通过`设置` > `个性化` > `记忆`菜单手动添加您希望LLMs记住的信息。记忆可以被添加、编辑和删除。

---

### 💻 模型管理


- 🛠️ **模型构建器**: 所有模型都可以在模型编辑页面中以持续的模型构建器模式进行构建和编辑。

- 📚 **模型知识支持**: 能够在模型的编辑页面直接附加工具、功能和知识集合，以增强每个模型可用的信息。

- 🗂️ **模型预设**: 为Ollama和OpenAI API创建和管理模型预设。

- 🏷️ **模型标签**: 模型工作区允许用户通过标签对模型进行组织。

- 📋 **模型选择器下拉排序**: 可以通过拖放模型到模型工作区的所需位置来轻松组织它们，这些更改将在模型下拉菜单中反映。

- 🔍 **模型选择器下拉菜单**: 使用模糊搜索和详细的模型信息（如模型标签和描述）轻松查找和选择模型。

- ⌨️ **方向键模型选择**: 使用方向键更快地选择模型，增强可访问性。

- 🔧 **模型工作区中的快捷操作**: 加强了Shift键快捷操作以隐藏/显示和删除模型。

- 😄 **透明模型使用**: 通过可见状态显示，在查询使用知识增强模型时，了解系统的状态。

- ⚙️ **具有高级参数的精细控制**: 通过调整模型参数（如`seed`、`temperature`、`frequency penalty`、`context length`等等）来获得更深层次的控制。

- 🔄 **无缝集成**: 直接从[Ollama library](https://ollama.com/library/)的模型页面复制任何`ollama run {model:tag}` CLI命令，并将其粘贴到模型下拉菜单中以便轻松选择和拉取模型。

- 🗂️ **创建Ollama模型文件**: 要为Ollama创建模型文件，请导航到`管理面板` > `设置` > `模型` > `创建模型`菜单。

- ⬆️ **GGUF文件模型创建**: 通过`管理设置` > `设置` > `模型` > `实验性`菜单，从Open WebUI直接上传GGUF文件，轻松创建Ollama模型。通过从您的设备上传或从Hugging Face下载GGUF文件，流程已简化。

- ⚙️ **默认模型设置**: 新聊天的默认模型偏好可在移动设备的`设置` > `界面`菜单中设置，或更轻松地在新的聊天中通过PC和笔记本电脑选择器下拉菜单设置。

- 💡 **LLM响应洞察**: 可查看每个生成响应的详细信息，包括外部模型API洞察和详尽的本地模型信息。

- 🕒 **模型详情一目了然**: 在模型工作区中直接查看关键模型详情，包括模型哈希值和最后修改时间戳，以便于跟踪和管理。

- 📥🗑️ **下载/删除模型**: 可以轻松地直接从Open WebUI下载或删除模型。

- 🔄 **更新所有Ollama模型**: 一个便捷的按钮允许用户一次性更新所有本地安装的模型，从而简化了模型管理。

- 🍻 **TavernAI角色卡片集成**: 在模型构建器中通过TavernAI角色卡片集成实现增强的视觉故事讲述。用户可以将TavernAI角色卡片PNG无缝整合到其模型文件中，创造更具沉浸感和吸引力的用户体验。

- 🎲 **模型试验场（Beta）**: 使用模型试验场（`Beta`）试验模型，可让用户在正式应用到实时聊天环境前，在沙盒环境中轻松测试和探索模型能力及参数。

---

### 👥 协作

- 🗨️ **本地聊天共享**: 生成并分享用户之间的聊天链接，高效且无缝地增强协作和通信。

- 👍👎 **RLHF标注**：通过给消息进行点赞或差评及以1至10的分数评级来提升消息的质量，并提供文字反馈，促进创建基于人类反馈的强化学习（`RLHF`）数据集。使用您的消息来训练或微调模型，同时确保本地保存数据的保密性。

- 🔧 **全面的反馈导出**：以JSON格式导出反馈历史数据，为RLHF处理及进一步分析提供无缝集成，从而提供有价值的改进建议。

- 🤝 **社区共享**：通过点击`共享到Open WebUI社区`按钮，与[Open WebUI社区](https://openwebui.com/)分享您的聊天会话。此功能使您可以与其他用户互动并在平台上协作。
  - 要使用此功能，请登录您的Open WebUI社区账户。分享您的聊天会话可以促进充满活力的社区氛围，鼓励知识共享，促进协同解决问题。请注意，社区共享聊天会话是一个可选功能，仅管理员可在`管理员设置` > `设置` > `常规`菜单中打开或关闭此功能。

- 🏆 **社区排行榜**：通过我们的排行榜系统实时参与竞争并追踪您的表现，该系统采用ELO评级系统并允许可选共享反馈历史。

- ⚔️ **模型评估竞技场**：直接在管理员设置中进行模型的盲测A/B测试，进行真实的并排比较，使您更容易找到最适合您需求的模型。

- 🎯 **基于主题的排名**：通过我们的实验性主题重排系统发现更准确的排名，该系统根据反馈中的标签相似性调整排行榜排名。

- 📂 **统一和协作工作空间**：在一个方便的位置访问和管理所有模型文件、提示、文档、工具和功能，同时支持多个用户协作及贡献模型、知识、提示或工具，简化您的工作流程并提升团队协作能力。

---

### 📚 历史与存档

- 📜 **聊天历史**：通过聊天导航侧边栏轻松访问和管理您的对话历史。在`设置` > `聊天`菜单中关闭聊天历史，以防止与新交互创建聊天历史。

- 🔄 **重新生成历史访问**：轻松访问并探索所有LLM响应重新生成的历史记录。

- 📬 **存档聊天**：轻松存储与模型完成的对话，以供将来参考或互动，保持整洁且无杂乱的聊天界面。

- 🗃️ **存档所有聊天**：此功能允许您快速存档所有聊天记录。

- 📦 **将所有存档聊天导出为JSON**：此功能使用户能够轻松将所有存档聊天导出为单个JSON文件，可用于备份或传输。

- 📄 **下载聊天为JSON/PDF/TXT**：根据您的偏好格式，轻松单独下载您的聊天记录，支持`.json`、`.pdf`或`.txt`格式。

- 📤📥 **导入/导出聊天历史**：通过`导入聊天`和`导出聊天`选项无缝移动您的聊天数据进出平台。

- 🗑️ **删除所有聊天**：此选项允许您永久删除所有聊天记录，确保一个新的开始。

---

### 🎙️ 音频、语音与无障碍

- 🗣️ **语音输入支持**：通过语音互动与您的模型交流；享受直接对模型说话的便利。此外，探索在3秒静音后自动发送语音输入的选项，以实现流畅体验。
  - 麦克风访问需要通过HTTPS手动设置安全连接才能正常工作，或者[在您自己的风险下手动将您的URL列入白名单](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情调用**：可以从`设置` > `界面`菜单中开启此功能，允许LLM在语音通话中使用表情符号表达情感，使互动更加生动有趣。
  - 该功能需要通过HTTPS建立安全连接才能正常工作。

- 🎙️ **免操作语音通话功能**：无需使用双手即可发起语音通话，使交互更方便流畅。
  - 麦克风访问需要通过HTTPS安全连接才能正常工作。

- 📹 **视频通话功能**：启用视频通话，与支持视觉模型的LlaVA和GPT-4o通信，为您的交流增添视觉元素。
  - 使用该功能需要摄像头和麦克风访问，并通过HTTPS建立安全连接。

- 👆 **点击中断**：在移动设备上简单点击即可停止AI在语音聊天中的讲话，确保您对互动的无缝控制。

- 🎙️ **语音中断**：在移动设备上通过语音即可停止AI在语音聊天中的讲话，确保您对互动的无缝控制。

- 🔊 **可配置的文本转语音端点**：自定义您的文本转语音体验，使用兼容OpenAI的端点来朗读LLM的响应内容。

- 🔗 **直接呼叫模式访问**：通过URL直接激活呼叫模式，为移动设备用户提供方便快捷的选项。

- ✨ **可定制文本到语音**：控制消息内容在文本到语音（TTS）生成请求中的分段方式，提供灵活的语音输出选项。

- 🔊 **Azure语音服务集成**：支持Azure语音服务进行文本到语音（TTS），为用户提供更多语音合成选项。

- 🎚️ **可定制音频播放**：允许用户在通话模式设置中调整音频播放速度，以提升可访问性和用户体验。

- 🎵 **广泛的音频兼容性**：支持多种音频文件格式的转录，包括audio/x-m4a，以增强平台内音频内容的兼容性。

- 🔊 **音频压缩**：实验性的音频压缩方案，用于绕过OpenAI的25MB限制，从而扩展基于音频的交互可能。

- 🗣️ **实验性SpeechT5文本到语音**：享受本地SpeechT5支持，以提高文本到语音能力。

---

### 🐍 代码执行

- 🚀 **多功能、与用户界面无关且兼容OpenAI的插件框架**：无缝集成和定制[Open WebUI Pipelines](https://github.com/open-webui/pipelines)，用于高效的数据处理和模型训练，确保超强的灵活性和可扩展性。

- 🛠️ **原生Python函数调用**：在Open WebUI内直接使用Python的强大功能，通过内置代码编辑器轻松集成自定义代码，构建独特功能（如定制的RAG管道、网页搜索工具，甚至类似代理的动作），并在`工具`和`功能`工作区中无缝开发和集成函数代码。

- 🐍 **Python代码执行**：通过Pyodide在浏览器中本地执行Python代码，并支持Pyodide的多种库。

- 🌊 **Mermaid渲染**：使用[Mermaid图表和流程图工具](https://mermaid.js.org/intro/)在Open WebUI内直接创建视觉效果佳的图表和流程图，并支持Mermaid语法渲染。

- 🔗 **Iframe支持**：使用功能和工具可以将HTML直接渲染到您的聊天界面中。

---

### 🔒 集成与安全

- ✨ **支持多个OpenAI兼容API**：无缝集成和定制各种OpenAI兼容API，增强聊天交互的多样性。

- 🔑 **简化API密钥管理**：轻松生成和管理密钥以利用Open WebUI与OpenAI库，简化集成与开发。

- 🌐 **HTTP/S代理支持**：通过设置`http_proxy`或`https_proxy`环境变量轻松配置网络设置。这些变量（如设定）应包含HTTP和HTTPS代理的URL。

- 🌐🔗 **外部Ollama服务器连接**：通过配置环境变量无缝连接到托管在不同地址上的外部Ollama服务器。

- 🛢️ **灵活的数据库集成**：无缝连接到定制数据库，包括SQLite、Postgres以及多个向量数据库（如Milvus），使用环境变量进行灵活和可扩展的数据管理。

- 🌐🗣️ **外部语音转文字支持**：添加外部语音转文字（`STT`）服务，提供更强灵活性，允许用户选择首选服务提供商以实现无缝互动。

- 🌐 **远程ChromaDB支持**：通过连接远程ChromaDB服务器扩展数据库功能。

- 🔀 **多个Ollama实例负载均衡**：轻松分配聊天请求到多个Ollama实例，以提高性能和可靠性。

- 🚀 **先进的负载均衡和可靠性**：利用增强的负载均衡能力、支持Redis的无状态实例以及自动WebSocket重新连接功能，提升WebUI的性能、可靠性和可扩展性，确保在多个实例之间无缝和不间断的交互。

- ☁️ **实验性S3支持**：通过支持S3启用无状态WebUI实例，以增强大规模工作负载的可扩展性和平衡能力。

- 🛠️ **用户组的OAuth管理**：通过OAuth集成增强协作环境中的组级管理，提升控制和可扩展性。

---

### 👑 管理

- 👑 **超级管理员分配**：自动将首次注册的用户分配为超级管理员，其角色无法更改，也不会被其他管理员修改。

- 🛡️ **细粒度用户权限**：通过定制基于角色的权限来限制用户操作和访问，确保只有授权人员才能执行特定任务。

- 👥 **多用户管理**：直观的管理员面板带分页功能，可以轻松管理多个用户，简化用户管理和生命周期管理。

- 🔧 **管理面板**：用户管理系统旨在简化用户的注册和管理，提供直接添加用户或批量通过CSV导入用户的选项。

- 👥 **活跃用户指示器**: 监控活跃用户数量以及哪些模型被谁使用，以帮助评估何时因用户数量多而可能影响性能。

- 🔒 **默认注册角色**: 指定新用户注册的默认角色为 `pending`(待处理)、`user`(普通用户) 或 `admin`(管理员)，为管理新用户的权限和访问级别提供灵活性。

- 🔒 **禁止新用户注册**: 启用选项以禁用新用户注册，限制对平台的访问并维持固定的用户数量。

- 🔒 **防止聊天消息删除**: 管理员可以切换设置，防止所有用户删除他们的聊天消息，确保所有聊天记录保留以用于审核或合规目的。

- 🔗 **Webhook集成**: 通过Webhook订阅新用户注册事件（与 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams` 兼容），提供实时通知和自动化能力。

- 📣 **可配置通知横幅**: 管理员可以在 config.json 中创建可自定义的横幅，支持内容、背景颜色（`info` 信息、`warning` 警告、`error` 错误 或 `success` 成功），以及可关闭性。横幅仅对登录用户可见，确保敏感信息的机密性。

- 🛡️ **模型白名单**: 通过允许管理员为具有 `user` 角色的用户设置模型白名单，提高安全性和访问控制，确保只有授权的模型可以访问。

- 🔑 **社区共享管理员控制**: 管理员可以通过 `管理面板` > `设置` 菜单中的切换按钮为所有用户启用或禁用社区共享功能。此切换按钮允许管理员管理访问和隐私，确保安全环境。管理员可以选择启用或禁用所有用户的 `在社区共享` 按钮，从而控制社区互动和协作。

- 📧 **可信电子邮件认证**: 可选择使用可信电子邮件头进行认证，为保护您的开放WebUI实例增加额外的安全层。

- 🔒 **后端反向代理支持**: 通过开放WebUI后端与Ollama之间的直接通信加强安全性。此关键功能无需通过局域网（LAN）暴露Ollama。来自开放WebUI对 `/ollama/api` 路径的请求会从后端无缝重定向到Ollama，从而提高整体系统安全性并提供额外的保护层。

- 🔒 **认证**: 请注意，开放WebUI本身并不原生支持联合认证方案，例如SSO、OAuth、SAML或OIDC。然而，可以将其配置为委托认证给验证反向代理，从而有效实现单点登录（`SSO`）体验。此设置允许集中用户认证和管理，提高安全性和用户便利性。通过将开放WebUI与验证反向代理集成，您可以利用现有认证系统并简化用户对开放WebUI的访问。有关配置此功能的更多信息，请参阅 [联合认证支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可选认证**: 通过将 `WEBUI_AUTH` 设置为 `False`，享受禁用认证的灵活性。这是没有现有用户的新安装的理想解决方案，也可以用于演示目的。

- 🚫 **高级API安全性**: 根据自定义模型过滤器阻止API用户，增强API访问的安全性和控制。

- ❗ **管理员更新**: 确保管理员在登录时立即收到更新通知，帮助其了解最新的变更和系统状态。

- 👥 **用户组管理**: 创建和管理用户组，实现轻松组织和控制。

- 🔐 **基于用户组的访问控制**: 根据用户组设置模型、知识库、提示和工具的细粒度访问权限，打造更加受控和安全的环境。

- 🛠️ **细粒度用户权限**: 轻松管理工作空间权限，包括上传文件、删除、编辑、临时聊天，以及创建模型、知识库、提示和工具。

- 🔑 **LDAP认证**: 通过支持LDAP，提升安全性和可扩展性进行用户管理。

- 🌐 **可自定义的OpenAI连接**: 享受自定义OpenAI设置的流畅操作，包括前缀ID支持和API模型ID支持。

- 🔐 **Ollama API密钥管理**: 管理Ollama凭证，包括前缀ID支持，以实现安全高效的操作。

- 🔄 **连接管理**: 根据需要轻松启用或禁用单个OpenAI和Ollama连接。

- 🎨 **直观的模型工作空间**: 利用重新设计的用户友好界面，在用户和组之间管理模型。

- 🔑 **API密钥认证**: 通过轻松启用或禁用API密钥认证来加强安全性。

- 🔄 **统一模型重置**: 通过一键选项在管理员设置中重置并移除所有模型。

- 🔓 **灵活的模型访问控制**: 当不需要时，可以轻松绕过用户角色的模型访问控制，通过使用BYPASS_MODEL_ACCESS_CONTROL环境变量，简化受信环境中的工作流程。

- 🔒 **可配置的API密钥认证限制**: 灵活配置API密钥认证的端点限制，现在默认关闭，使得在受信环境中的设置更加顺畅。

---
