---
sidebar_position: 400
title: "⭐ 功能特色"
---

import { TopBanners } from "@site/src/components/TopBanners";

<TopBanners />

## Open WebUI 的主要功能 ⭐

- 🚀 **輕鬆安裝**：使用 Docker、Kubernetes、Podman、Helm Charts (`kubectl`、`kustomize`、`podman` 或 `helm`) 無縫安裝，支持 `:ollama` (包含 Ollama) 和 `:cuda` (CUDA 支持) 圖像，確保輕鬆上手。

- 🛠️ **引導式初始設置**：初次設置過程清晰明了，包括明確提示創建管理員帳戶。

- 🤝 **OpenAI API 集成**：簡單整合與 OpenAI 相容的 API，與 Ollama 模型一同進行靈活對話，OpenAI API URL 可自訂以便與各類第三方應用程序無縫整合。

- 🛡️ **細化的權限與使用者群組**：允許管理員創建詳細的使用者角色、群組和權限，確保所有使用者的安全環境。這種細緻程度不僅增強了安全性，還能提供自訂的使用體驗，增強使用者的所有權和責任感。

- 📱 **響應式設計**：在桌上型電腦、筆記型電腦和行動設備上都能享受流暢體驗。

- 📱 **行動設備的漸進式網頁應用程序**：在行動設備上享受原生的漸進式網頁應用程序體驗，並支持在 `localhost` 或個人域名上離線使用，提供流暢的使用者介面。為了使 PWA 可安裝到您的設備上，必須通過安全通信（通常是 HTTPS 提供）。

  :::info

  - 要設置 PWA，您需要對 Linux、Docker 和反向代理（如 `Nginx`、`Caddy` 或 `Traefik`）有一定的了解。使用這些工具可以簡化構建和部署符合需求的 PWA 的過程。雖然目前沒有「一鍵安裝」選項，並且將 Open WebUI 實例安全部署到 HTTPS 所需的選項需要用戶經驗，但利用這些資源可以更輕鬆地創建和部署量身訂製的 PWA。

  :::

- ✒️🔢 **完整的 Markdown 和 LaTeX 支持**：透過全面的 Markdown、LaTex 和富文本功能提升 LLM 體驗，提供更豐富的互動。

- 🧩 **模型生成工具**：直接從 Open WebUI 中易於根據 Ollama 基礎模型創建自訂模型，並新增自訂角色和代理人，自定義模型元素，並通過 [Open WebUI 社群](https://openwebui.com/) 集成輕鬆導入模型。

- 📚 **本地與遠端 RAG 集成**：使用前沿的檢索增強生成（RAG）技術在聊天中探討文件的未來互動。文件可加載到工作區的 `Documents` 分頁中，之後可使用井號 [`#`] 查詢訪問，或以井號 [`#`] 開始提示，後接網址進行網頁內容整合。

- 📄 **文件提取**：從包括 PDFs、Word 文件、Excel 試算表、PowerPoint 簡報等多種格式的文件中提取文本和數據。我們的先進文檔處理能力能與您的知識庫無縫集成，支持從複雜文件中準確檢索和生成資訊，同時保留其結構和格式。

- 🔍 **RAG 的網頁搜索**：您可以使用多種搜索提供商進行網頁搜索，並將結果直接注入到本地的檢索增強生成 (RAG) 體驗中。

- 🌐 **網頁瀏覽功能**：使用 `#` 命令後接網址，在聊天中無縫整合網站，此功能使您能將網頁內容直接引入對話中，提升互動的豐富性和深度。

- 🎨 **圖像生成集成**：無縫集成圖像生成功能，為您的聊天體驗帶來豐富的視覺內容。

- ⚙️ **同時使用多模型**：輕鬆同時利用多個模型，發揮其各自的優勢以獲得最佳回應。並行使用多樣的模型模式以增強您的體驗。

- 🔐 **基於角色的訪問控制 (RBAC)**：確保安全訪問與受限權限。僅授權人員可訪問 Ollama，而模型創建和拉取權限僅限於管理員。

- 🌐🌍 **多語言支持**：使用我們的國際化 (`i18n`) 支持以您偏好的語言體驗 Open WebUI。我們邀請您與我們共同擴展支持的語言！我們正在積極尋找貢獻者！

- 🌟 **持續更新**：我們致力於透過例行更新、修復與新增功能來改進 Open WebUI。

## 還有更多令人驚艷的功能，包括... ⚡️

---

### 🔧 管線支援

- 🔧 **管線框架**：透過我們的模組化插件框架，無縫整合並自訂您的 Open WebUI 體驗，提升自訂化及功能性（https://github.com/open-webui/pipelines）。該框架允許輕鬆添加自訂邏輯以及整合 Python 庫，從 AI 代理到家居自動化 APIs。

- 📥 **上傳管線**：管線可以直接從 `管理面板` > `設定` > `管線` 菜單上傳，簡化管線管理流程。

#### 利用我們的管線框架，可能性無窮且幾乎無限制。從一些預建管線開始以幫助您入門！

- 🔗 **功能調用**：透過管線無縫整合 [功能調用](https://github.com/open-webui/pipelines/blob/main/examples/filters/function_calling_filter_pipeline.py)，提升您的 LLM 互動並具備進階功能調用能力。

- 📚 **自訂 RAG**：透過管線無縫整合 [自訂檢索輔助生成 (RAG)](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/rag)，以自訂 RAG 邏輯提升您的 LLM 互動。

- 📊 **使用 Langfuse 進行訊息監測**：透過 [Langfuse](https://github.com/open-webui/pipelines/blob/main/examples/filters/langfuse_filter_pipeline.py) 管線，監測並分析訊息互動的即時使用統計資料。

- ⚖️ **使用者流量限制**：透過 [流量限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/rate_limit_filter_pipeline.py) 管線有效管理 API 使用率，以 控制發送給 LLM 的請求流量避免超出速率限制。

- 🌍 **即時 LibreTranslate 翻譯**：使用 [LibreTranslate](https://github.com/open-webui/pipelines/blob/main/examples/filters/libretranslate_filter_pipeline.py) 管線整合即時翻譯至您的 LLM 互動中，實現跨語言溝通。
  - 請注意，此管線需要進一步設置 LibreTranslate 並在 Docker 容器中運行。

- 🛡️ **有害訊息過濾**：我們的 [Detoxify](https://github.com/open-webui/pipelines/blob/main/examples/filters/detoxify_filter_pipeline.py) 管線會自動過濾掉有害訊息，以保持一個清晰且安全的聊天環境。

- 🔒 **LLM-Guard**：使用 [LLM-Guard](https://github.com/open-webui/pipelines/blob/main/examples/filters/llmguard_prompt_injection_filter_pipeline.py) 管線確保 LLM 的安全互動，具有提示注入掃描器以識別並減輕針對大型語言模型的技能輸入操作。這防止了 LLM 中的數據泄漏並為抵禦提示注入攻擊添加了一層防護。

- 🕒 **對話輪數限制**：透過 [對話輪數限制](https://github.com/open-webui/pipelines/blob/main/examples/filters/conversation_turn_limit_filter.py) 管線改善互動管理。

- 📈 **OpenAI 生成統計**：我們的 [OpenAI](https://github.com/open-webui/pipelines/blob/main/examples/pipelines/providers/openai_manifold_pipeline.py) 管線提供詳細的 OpenAI 模型生成統計資料。

- 🚀 **多模型支援**：我們與多個 AI 模型提供商的 [各種提供者](https://github.com/open-webui/pipelines/tree/main/examples/pipelines/providers) 的無縫整合擴展了您的選擇與互動範圍。

#### 除了廣泛的功能和自訂選項之外，我們還提供 [一系列可供使用的示例管線](https://github.com/open-webui/pipelines/tree/main/examples) 和 [一個實用的示例支架管線](https://github.com/open-webui/pipelines/blob/main/examples/scaffolds/example_pipeline_scaffold.py) 幫助您入門。這些資源將簡化您的開發過程，並使您能夠快速使用管線和 Python 創建強大的 LLM 互動。祝您編程愉快！💡

---

### 🖥️ 使用者體驗

- 🖥️ **直觀界面**：聊天界面以使用者為核心進行設計，從 ChatGPT 的使用者界面中汲取靈感。

- ⚡ **快速響應性**：享受可靠快速且響應迅速的性能。

- 🎨 **啟動畫面**：簡單的載入啟動畫面，提供更加流暢的使用者體驗。

- 🌐 **個性化界面**：在設定 > 界面中選擇設計完善的搜索登錄頁面或經典聊天 UI，提供量身定制的體驗。

- 📦 **Pip 安裝方式**：可透過指令 `pip install open-webui` 安裝 Open WebUI，簡化安裝流程，使新手更易上手。詳細資訊請造訪：https://pypi.org/project/open-webui/。

- 🌈 **主題自定義**：透過多種選項個性化您的 Open WebUI 體驗，包括精美主題、自定義聊天背景圖片，以及三種模式選擇：明亮模式、暗色模式或 OLED 暗色模式——或者讓*她*為您選擇！;)

- 🖼️ **支援自定義背景**：可在設置 > 介面中設定自定義背景，讓您的使用體驗更加個性化。

- 📝 **使用 Markdown 的豐富橫幅**：在橫幅中使用 Markdown 創建視覺吸引力更高的公告，提供更豐富和充滿活力的內容。

- 💻 **程式碼語法高亮顯示**：語法高亮功能增強程式碼可讀性，提供清晰且簡潔的程式碼視圖。

- 🗨️ **用戶訊息的 Markdown 渲染**：用戶訊息現在支援 Markdown 渲染，提高可讀性及互動性。

- 🎨 **靈活的文字輸入選項**：可在富文本輸入與舊式文字區輸入間切換，滿足用戶需求，並提供進階格式與簡單文字輸入之間的選擇。

- 👆 **快速程式碼分享**：透過方便的程式碼複製選項簡化分享和協作流程，包括程式碼區塊的浮動複製按鈕以及程式碼範圍的點擊即複製功能，有效節省時間並減少煩惱。

- 🎨 **互動式工件**：直接在介面中渲染網頁內容和 SVG，支援快速迭代和即時更改，提升創造力及生產力。

- 🖊️ **即時程式碼編輯**：超強化程式碼區塊，允許在 LLM 回應中直接進行即時編輯，並透過工件支援即時重載，簡化程式碼編寫及測試流程。

- 🔍 **強化 SVG 互動功能**：SVG 圖像（包括 Mermaid 圖表）支援平移及縮放功能，深入探索及理解複雜概念。

- 🔍 **文字選擇快速操作**：在 LLM 回應中突顯文字時顯示浮動按鈕，提供「提問」或「解釋」等深入互動選項，提升整體用戶體驗。

- ↕️ **雙向聊天支援**：可輕鬆在左至右及右至左聊天方向間切換，以適應多種語言偏好。

- 📱 **行動裝置可用性**：在行動裝置上可透過簡單的滑動手勢開啟或關閉側列。

- 🤳 **支援觸感回饋裝置**：Android 裝置支援一定互動的觸感回饋，提供沉浸式的觸感使用體驗。

- 🔍 **用戶設置搜尋**：快速搜尋設置欄位，提高使用方便性及導航效率。

- 📜 **離線 Swagger 文件**：可離線存取對開發者友好的 Swagger API 文件，確保無論身處何處均可使用。

- 💾 **性能優化**：延遲載入大型依賴項，將初始記憶體使用量降至最低，提高性能並縮短載入時間。

- 🚀 **持久且可擴展的配置**：Open WebUI 配置儲存於資料庫（webui.db）中，支援無縫負載均衡、高可用性設置，以及多實例間的持久設置，使訪問和重複使用您的配置變得簡單。

- 🔄 **可攜式匯入/匯出**：輕鬆匯入及匯出 Open WebUI 配置，簡化跨系統復制設置的流程。

- ❓ **快速存取文件及快捷鍵**：主介面底部右側的問號按鈕（適用於桌上型電腦及筆記本等較大螢幕）可讓用戶快速存取 Open WebUI 文件頁以及可用的鍵盤快捷鍵。

- 📜 **更新紀錄及檢查更新**：用戶可在 `設置` > `關於` > `查看最新動態` 菜單中存取全面更新紀錄以及檢查更新功能，快速概覽最新功能改進及缺陷修復，也可檢查更新。

---

### 💬 對話

- 💬 **真正的異步聊天**：享受不中斷的多任務處理，支援真正的異步聊天，能建立聊天、離開並在任何時間返回，回應始終準備就緒。

- 🔔 **聊天完成通知**：在非活動標籤中完成聊天時，透過即時介面通知保持更新，確保您不會錯過任何已完成的回應。

- 🌐 **通知 Webhook 整合**：透過可配置的 webhook 通知接收即時更新，滿足長時間運行聊天及外部整合需求，即使標籤頁已關閉。

- 📚 **頻道（Beta）**：探索用戶與 AI 之間的即時協作，提供類似 Discord/Slack 的聊天房，建立頻道機器人，並解鎖多代理的非同步通信，以進行主動的多任務工作流程。

- 🖊️ **頻道中的輸入指示**：透過頻道的即時輸入指示提高協作能力，保持所有人參與並掌握狀況。

- 👤 **使用者狀態指示器**：透過點擊頻道中使用者的個人資料圖片快速查看使用者的狀態，提供更好的協調和可用性洞察。

- 💬 **聊天控制**：輕鬆調整每個聊天會話的參數，提供更精確的互動控制。

- 💖 **收藏回應管理**：在聊天概覽中輕鬆標記和整理收藏的回應，增強檢索和偏好回應的便利性。

- 📌 **固定聊天**：支援固定聊天功能，讓您可以輕鬆存取重要的對話。

- 🔍 **RAG 嵌入支援**：直接在 `管理面板` > `設定` > `文件` 裡更換可擷取式增強生成（RAG）的嵌入模型，增強文件處理能力。此功能支援 Ollama 和 OpenAI 模型。

- 📜 **RAG 功能中的引用**：可擷取式增強生成（RAG）功能讓使用者透過新增引用點輕鬆追蹤輸入給 LLM 的文件上下文。

- 🌟 **增強 RAG 管線**：為 RAG 嵌入功能新增可切換的混合搜索子功能，增強 RAG 功能，使用 `BM25`進行重新排序，並透過 `CrossEncoder` 提供可配置的相關性分數門檻。

- 📹 **YouTube RAG 管線**：專用的可擷取式增強生成（RAG）管線，透過影片 URL 為 YouTube 影片提供摘要功能，讓您可直接與影片轉錄內容互動。

- 📁 **全面的文件檢索**：在完整文件檢索和傳統片段之間切換，支持全面的任務如摘要生成及增強文件功能。

- 🌟 **RAG 引用的相關性**：在 RAG 結果中新增相關性百分比，輕鬆評估引用的準確性。

- 🗂️ **進階 RAG**：透過智能預處理聊天歷史來決定檢索之前最優的查詢，提升 RAG 的準確性。

- 📚 **RAG 的內嵌引用**：享受可擷取式增強生成（RAG）的無縫內嵌引用，提升追溯能力並為新上傳檔案提供來源清晰度。

- 📁 **大文本處理**：可選擇將大量貼上的文本轉換為文件上傳，直接用於 RAG，保持聊天界面整潔。

- 🔄 **多模態支援**：與支援多模態互動的模型輕鬆互動，包括影像（如 `LLaVA`）。

- 🤖 **多模型支援**：快速切換不同的模型以進行多樣化聊天互動。

- 🔀 **多模型聊天中的合併回應**：透過合併多個模型的回應成單一、連貫的回答來增強對話。

- ✅ **同模型多实例支持**：增強的多模型聊天功能支持在對話中新增相同模型的多個实例。

- 💬 **臨時聊天功能**：引入臨時聊天功能，廢止舊的聊天歷史設定，增強使用者互動靈活性。

- 🖋️ **用户消息编辑**：改进用户聊天编辑功能，支持保存更改而无需发送。

- 💬 **効率会話編集**：使用 Cmd/Ctrl+Shift+Enter 快捷键快速直观创建新的消息对，简化会话长度测试。

- 🖼️ **客户端图像压缩**：通过客户端图像压缩节省带宽并提高性能，可在设置 > 界面中将图像压缩后再上传。

- 👥 **'@'模型整合**：通过在对话中无缝切换至任何可访问的本地或外部模型，用户可在单一聊天中利用多个模型的集体智慧。只需在聊天中使用 `@` 指令指定模型名称即可完成此操作。

- 🏷️ **会话标记**：通过我们高效的 'tag:' 查询系统轻松分类和定位已标记的聊天记录，从而快速参考和简化数据收集，同时不使界面混乱。

- 🧠 **自动标记**：会话可选择自动标记以改进组织效率，类似于自动生成标题的功能。

- 👶 **聊天克隆**：轻松克隆并保存任何聊天的快照以供未来参考或继续。此功能可方便您从停下的位置继续或与他人分享您的会话。要创建聊天副本，只需点击聊天下拉选项中的 `克隆` 按钮。您能跟上您的克隆進度嗎？

- ⭐ **可视化会话流程**：交互式消息图表用于改进会话流程的可视化，增强对复杂讨论的理解和导航。

- 📁 **聊天文件夹**：将您的聊天分类到文件夹中，通过拖放轻松管理，并无缝导出以便分享或分析。

- 📤 **轻松聊天导入**：通过将聊天导出（JSON）拖放到侧边栏中即可将聊天导入工作区。

- 📜 **提示預設支援**：使用聊天輸入中的 `/` 指令，立即存取自訂的提示預設。輕鬆載入預定義的交談啟動，快速加速互動。透過 [Open WebUI 社群](https://openwebui.com/) 整合匯入提示，或自行建立提示！

- 📅 **提示變數支援**：提示變數如 `{{CLIPBOARD}}`、`{{CURRENT_DATE}}`、`{{CURRENT_DATETIME}}`、`{{CURRENT_TIME}}`、`{{CURRENT_TIMEZONE}}`、`{{CURRENT_WEEKDAY}}`、`{{USER_NAME}}`、`{{USER_LANGUAGE}}` 和 `{{USER_LOCATION}}` 可以在系統提示中使用，也可透過斜槓指令直接選擇提示以用於聊天。
  - 請注意，`{{USER_LOCATION}}` 提示變數需要透過 HTTPS 安全連接。若需使用此提示變數，請確保在 `設置` > `介面` 菜單中啟用 `{{USER_LOCATION}}`。
  - 請注意，`{{CLIPBOARD}}` 提示變數需要存取您的設備剪貼簿。

- 🧠 **記憶功能**：透過 `設置` > `個性化` > `記憶` 菜單手動新增您希望 LLMs 記住的資訊。記憶可以新增、編輯與刪除。

---

### 💻 模型管理


- 🛠️ **模型建構工具**：所有模型都可以在模型編輯頁面內透過持續性模型建構工具模式進行建構與編輯。

- 📚 **模型知識支援**：在模型編輯頁面中可直接向模型附加工具、函數與知識集合，提升每個模型可用的資訊。

- 🗂️ **模型預設**：建立並管理適用於 Ollama 和 OpenAI API 的模型預設。

- 🏷️ **模型標籤**：模型工作空間讓使用者可以透過標籤來組織模型。

- 📋 **模型選擇下拉排序**：模型可以在模型工作空間中輕鬆拖放以整理至想要的位置，其變更會反映在模型下拉選單中。

- 🔍 **模型選擇下拉選單**：透過模糊搜尋與模型標籤及詳細的模型描述輕鬆找到並選擇模型。

- ⌨️ **箭頭鍵模型選擇**：使用箭頭鍵進行更快速的模型選擇，提升使用便利性。

- 🔧 **模型工作空間快速操作**：增強的 Shift 鍵快速操作功能，用於隱藏/顯示以及刪除模型。

- 😄 **透明模型使用情況**：透過可見的狀態顯示，了解系統在查詢過程中使用具知識增強的模型的狀態。

- ⚙️ **進階參數的精細控制**：透過調整模型參數如 `seed`、`temperature`、`frequency penalty`、`context length` 等，獲得更深層的控制。

- 🔄 **無縫整合**：直接從 [Ollama library](https://ollama.com/library/) 的模型頁面複製任意 `ollama run {model:tag}` CLI 命令，並將其貼到模型下拉選單中以輕鬆選擇並載入模型。

- 🗂️ **建立 Ollama 模型文件**：要為 Ollama 建立模型文件，請前往 `管理面板` > `設置` > `模型` > `建立模型` 菜單。

- ⬆️ **GGUF 文件模型創建**：透過 `管理設置` > `設置` > `模型` > `實驗性` 菜單，直接從 Open WebUI 上傳 GGUF 文件以快速創建 Ollama 模型。過程已簡化，可選擇從您的設備上傳或從 Hugging Face 下載 GGUF 文件。

- ⚙️ **預設模型設置**：新聊天的預設模型偏好可以在行動裝置上的 `設置` > `介面` 菜單中設置，或更簡易地在桌面電腦及筆記本上於新聊天的模型選擇下拉菜單中設置。

- 💡 **LLM 回應洞察**：可以查看每次生成回應的詳細資料，包括外部模型 API 洞察和全面的本地模型資訊。

- 🕒 **快速查看模型詳細資訊**：在模型工作空間中直接查看重要的模型詳細資訊，包括模型哈希值及最後修改時間戳，以加強跟踪與管理。

- 📥🗑️ **下載/刪除模型**：可以直接從 Open WebUI 輕鬆下載或刪除模型。

- 🔄 **更新所有 Ollama 模型**：一個便利的按鈕使得使用者可以一次更新所有本地安裝的模型，簡化模型管理。

- 🍻 **TavernAI 角色卡整合**：透過模型建構工具體驗更豐富的視覺敘事。在模型文件中無縫整合 TavernAI 角色卡 PNG，打造更具沉浸感和吸引力的使用體驗。

- 🎲 **模型遊樂場 (Beta)**：在模型遊樂場區域（`Beta`）試用模型，讓使用者可以在正式部署到聊天環境之前先在沙盒環境中輕鬆測試和探索模型的能力與參數。

---

### 👥 合作

- 🗨️ **本地聊天共享**：生成並共享聊天連結，讓用戶之間的協作和交流更加高效順暢。

- 👍👎 **RLHF標註**：透過點讚或反對功能，提升您的消息影響力，並在1-10的等級範圍內為回應提供評分，再附上文字反饋，協助建立基於人類反饋的強化學習(`RLHF`)數據集。同時確保本地保存數據的保密性，利用您的消息訓練或微調模型。

- 🔧 **全面反饋匯出**：將反饋歷史數據匯出為JSON格式，方便與RLHF處理無縫集成與深入分析，提供有價值的改進見解。

- 🤝 **社群分享**：點擊`分享至Open WebUI Community`按鈕，將您的聊天會話分享至[Open WebUI社群](https://openwebui.com/)。此功能讓您可以與其他用戶互動並在平台合作。
  - 使用此功能需登入您的Open WebUI社群帳戶。分享您的聊天促進活躍的社群，鼓勵知識分享並促進共同解決問題。請注意：聊天會話社群分享屬於選擇性功能，僅管理員可以在`管理員設置` > `設定` > `一般`菜單中開啟或關閉此功能。

- 🏆 **社群排行榜**：透過排名系統即時競爭與追蹤您的表現。我們採用ELO排名系統，並允許選擇性分享反饋歷史。

- ⚔️ **模型評估競技場**：透過管理員設定進行盲測A/B測試，實現真正的並排比較，讓您更容易尋找符合需求的最佳模型。

- 🎯 **基於主題的排名**：探索更準確的排名，我們的實驗性基於主題的重排系統，根據反饋中的標籤相似度調整排行榜排名。

- 📂 **統一與協作的工作空間**：在一個方便的位置訪問和管理您的模型文件、提示、文檔、工具及功能，同時允許多位用戶協作並為模型、知識、提示或工具貢獻，簡化工作流程並提升團隊合作效率。

---

### 📚 歷史與存檔

- 📜 **聊天歷史**：透過聊天導航側欄方便地訪問和管理您的對話歷史。可以在`設定` > `聊天`菜單中關閉聊天歷史功能，以防止新交互創建聊天歷史。

- 🔄 **回應歷史存取**：輕鬆回訪並探索您完整的LLM回應重生成歷史。

- 📬 **存檔聊天**：方便地存儲已完成的與模型的對話，以備將來參考或再次交互，保持整潔無雜的聊天介面。

- 🗃️ **全部聊天存檔**：此功能允許您一次性快速存檔所有聊天。

- 📦 **將所有已存檔的聊天匯出為JSON**：此功能使用戶可以輕鬆地將所有已存檔的聊天匯出為單一的JSON文件，用於備份或轉移用途。

- 📄 **下載聊天為JSON/PDF/TXT**：輕鬆地以您偏好的格式（`.json`、`.pdf`或`.txt`格式）分別下載聊天記錄。

- 📤📥 **導入/匯出聊天歷史**：通過`導入聊天`和`匯出聊天`選項，無縫地遷移您的聊天數據進出平台。

- 🗑️ **刪除所有聊天**：此選項允許您永久刪除所有聊天，確保全新的開始。

---

### 🎙️ 音頻、語音與便利性

- 🗣️ **語音輸入支持**：通過語音交互與您的模型互動；享受直接與模型交流的便利。此外，探索在3秒寂靜後自動發送語音輸入的選項，體驗更流暢的交互。
  - 麥克風訪問需要手動配置HTTPS安全連接才能正常工作，或者[在用戶自擔風險下手動列入白名單](https://docs.openwebui.com/troubleshooting/microphone-error)。

- 😊 **表情符號呼叫**：在`設定` > `介面`菜單中打開此功能，允許LLM在語音呼叫期間使用表情符號表達情感，讓交互更加生動。
  - 麥克風訪問需要HTTPS安全連接才能使此功能正常工作。

- 🎙️ **免手語音呼叫功能**：無需使用雙手即可發起語音呼叫，使交互更加流暢。
  - 麥克風訪問需要使用HTTPS安全連接以使此功能正常工作。

- 📹 **視頻呼叫功能**：啟用支持視覺模型（例如LlaVA和GPT-4o）的視頻呼叫，為您的通信增添視覺維度。
  - 鏡頭和麥克風訪問均需使用HTTPS安全連接以使此功能正常工作。

- 👆 **點擊以中斷**：在移動設備上簡單點擊即可停止AI在語音對話中的說話，確保交互的流暢控制。

- 🎙️ **語音中斷**：在移動設備上使用語音即可停止AI在語音對話中的說話，確保交互的流暢控制。

- 🔊 **可配置的文字轉語音端點**：使用可配置的OpenAI兼容端點定制您的文字轉語音體驗以朗讀LLM回應。

- 🔗 **直接呼叫模式接入**：通過URL啟動呼叫模式，為移動設備用戶提供便捷的快捷方式。

- ✨ **可自訂文字轉語音**：控制訊息內容如何分段以進行文字轉語音（TTS）生成請求，提供靈活的語音輸出選項。

- 🔊 **Azure 語音服務整合**：支援 Azure 語音服務進行文字轉語音（TTS），提供使用者更多語音合成選擇。

- 🎚️ **可自訂音頻播放**：允許使用者在通話模式設定中調整音頻播放速度，提升可及性和使用便利性。

- 🎵 **廣泛的音頻相容性**：支援多種音頻檔案格式的轉錄，包括audio/x-m4a，擴展平台上音頻內容的相容性。

- 🔊 **音頻壓縮**：實驗性音頻壓縮可繞過 OpenAIs 語音轉文字處理的 25MB 限制，拓展基於音頻的互動可能性。

- 🗣️ **實驗性 SpeechT5 TTS**：享受本地 SpeechT5 支援，提升文字轉語音功能。

---

### 🐍 程式碼執行

- 🚀 **多功能、UI無關、OpenAI兼容的外掛框架**：無縫整合並自訂 [Open WebUI Pipelines](https://github.com/open-webui/pipelines)，以進行高效的資料處理和模型訓練，確保極大的靈活性和可擴展性。

- 🛠️ **原生 Python 函數調用**：直接在 Open WebUI 中使用原生函數調用及 Python 功能。輕鬆整合自訂程式碼，打造獨特功能，例如自訂 RAG 管道、網頁搜尋工具，甚至代理型操作，通過內建的程式碼編輯器在 `工具` 和 `功能` 工作區中無縫開發和整合函數程式碼。

- 🐍 **Python 程式碼執行**：通過 Pyodide 在本地瀏覽器執行 Python 程式碼，支援 Pyodide 的多種函式庫。

- 🌊 **Mermaid 渲染**：利用 [Mermaid 圖表及流程製作工具](https://mermaid.js.org/intro/) 在 Open WebUI 中直接創建美觀的圖表和流程圖，支援 Mermaid 語法渲染。

- 🔗 **Iframe 支援**：使用功能和工具將 HTML 直接渲染到聊天介面中。

---

### 🔒 整合與安全

- ✨ **支援多個 OpenAI 兼容 API**：無縫整合並自訂多種 OpenAI 兼容的 API，增強聊天互動的多功能性。

- 🔑 **簡化 API 金鑰管理**：輕鬆生成並管理密鑰，以便使用 OpenAI 函式庫運行 Open WebUI，簡化整合和開發過程。

- 🌐 **HTTP/S 代理支援**：使用 `http_proxy` 或 `https_proxy` 環境變數輕鬆配置網絡設定。這些變數（如果設定）應包含 HTTP 和 HTTPS 代理 URL。

- 🌐🔗 **外部 Ollama 伺服器連接**：通過設定環境變數無縫連接到位於不同地址的外部 Ollama 伺服器。

- 🛢️ **靈活的資料庫整合**：通過環境變數與自訂資料庫（如 SQLite、Postgres 和多個向量資料庫例如 Milvus）無縫連接，實現靈活且可擴展的資料管理。

- 🌐🗣️ **外部語音轉文字支援**：新增外部語音轉文字（`STT`）服務，提供更高的靈活性，允許使用者選擇喜愛的提供商，以實現無縫互動。

- 🌐 **遠程 ChromaDB 支援**：通過連接到遠程 ChromaDB 伺服器擴展資料庫功能。

- 🔀 **多個 Ollama 實例負載平衡**：輕鬆分配聊天請求到多個 Ollama 實例以提高效能和可靠性。

- 🚀 **先進的負載平衡和可靠性**：利用改進的負載平衡功能、完全支援 Redis 的無狀態實例、以及自動 Web Socket 重新連接，提高 WebUI 的效能、可靠性和可擴展性，確保多實例間的無縫和不中斷互動。

- ☁️ **實驗性 S3 支援**：啟用帶有 S3 支援的無狀態 WebUI 實例以應對繁重的工作負載，提升可擴展性。

- 🛠️ **用戶群的 OAuth 管理**：透過 OAuth 整合提供群組級管理以提升協作環境中的控制和可擴展性。

---

### 👑 管理

- 👑 **超級管理員指派**：自動將首次註冊使用者設置為超級管理員，其角色無法被其他管理員或任何人修改。

- 🛡️ **細緻化的用戶許可權**：通過可自訂的基於角色的許可權限制用戶行動和訪問，確保只有授權人員才能執行特定任務。

- 👥 **多用戶管理**：直觀的管理員面板具有分頁功能，使您可以流暢地管理多位用戶，簡化用戶生命周期管理。

- 🔧 **管理員面板**：用戶管理系統旨在簡化用戶啟用和管理，提供直接添加或通過 CSV 匯入批量添加用戶的選項。

- 👥 **活躍用戶指標**：監控活躍用戶數量以及哪個模型正在被何人使用，以協助評估當用戶數量過多時性能可能受到的影響。

- 🔒 **預設註冊角色**：指定新註冊用戶的預設角色為 `pending`、`user` 或 `admin`，提供管理新用戶權限和訪問級別的靈活性。

- 🔒 **阻止新註冊**：啟用禁用新用戶註冊的選項，限制訪問平台並保持用戶數量固定。

- 🔒 **阻止聊天刪除**：管理員可以切換設置以防止所有用戶刪除他們的聊天消息，確保所有聊天消息保留以用於審計或合規目的。

- 🔗 **Webhook 整合**：通過 webhook 訂閱新用戶註冊事件（兼容 `Discord`、`Google Chat`、`Slack` 和 `Microsoft Teams`），提供實時通知和自動化功能。

- 📣 **可配置通知橫幅**：管理員可以在 config.json 中創建可定制的持久性橫幅，包括內容設置、背景顏色（`info`、`warning`、`error` 或 `success`）和是否可關閉選項。橫幅僅供登錄用戶訪問，確保敏感信息的保密性。

- 🛡️ **模型白名單**：通過允許管理員為 `user` 角色的用戶設置模型白名單，以加強安全性和訪問控制，確保僅授權模型可被訪問。

- 🔑 **社群分享管理**：在 `管理員面板` > `設置` 菜單中，管理員可通過切換開關為所有用戶啟用或禁用社群分享。此切換允許管理員管理可訪問性和隱私，確保安全環境。管理員可以選擇啟用或禁用所有用戶的 `分享至社群` 按鈕，以控制社群參與和協作。

- 📧 **信任的電子郵件身份驗證**：可選擇使用信任的電子郵件標頭進行身份驗證，添加額外的安全層以保護您的 Open WebUI 實例。

- 🔒 **後端反向代理支持**：通過 Open WebUI 的後端與 Ollama 之間的直接通信，加強安全性。此關鍵功能消除了在局域網（LAN）上暴露 Ollama 的需求。從 Open WebUI 發送至 `/ollama/api` 路徑的請求將無縫重定向至 Ollama 後端，提升整體系統安全性並提供額外保護層。

- 🔒 **身份驗證**：請注意，Open WebUI 原生不支持聯邦身份驗證方案，如 SSO、OAuth、SAML 或 OIDC。然而，它可以配置為將身份驗證委託給身份驗證反向代理，有效實現單一登錄（`SSO`）體驗。此設置允許集中化用戶身份驗證和管理，增強安全性及用戶便利性。通過將 Open WebUI 整合於身份驗證反向代理中，您可以利用現有身份驗證系統並簡化用戶對 Open WebUI 的訪問。關於配置此功能的更多信息，請參考 [聯邦身份驗證支持](https://docs.openwebui.com/features/sso)。

- 🔓 **可選身份驗證**：通過將 `WEBUI_AUTH` 設置為 `False`，享受禁用身份驗證的靈活性。這是沒有現有用戶情況下的新安裝的理想解決方案，或者可用於演示目的。

- 🚫 **高級 API 安全性**：根據自定義模型過濾器阻止 API 用戶，增強 API 訪問的安全性和控制。

- ❗ **管理員更新**：確保管理員在登錄後即刻收到更新通知，使其了解最新變更和系統狀態。

- 👥 **用戶群組管理**：創建並管理用戶群組，用以實現無縫的組織和控制。

- 🔐 **基於群組的訪問控制**：根據用戶群組設置對模型、知識、提示和工具的細粒度訪問，營造更加受控和安全的環境。

- 🛠️ **細粒度用戶權限**：輕鬆管理工作區權限，包括文件上傳、刪除、編輯及臨時聊天，以及模型、知識、提示和工具的創建。

- 🔑 **LDAP 身份驗證**：通過 LDAP 支持，用以增強用戶管理的安全性和可擴展性。

- 🌐 **可定制的 OpenAI 連接**：享受順暢操作，包括 API 的前綴 ID 支持和明確模型 ID 支持在內的自定義 OpenAI 設置。

- 🔐 **Ollama API 密鑰管理**：管理 Ollama 憑證（包括前綴 ID 支持），以確保安全及高效運行。

- 🔄 **連接管理**：根據需要輕鬆啟用或禁用個別 OpenAI 和 Ollama 連接。

- 🎨 **直觀的模型工作區**：使用重新設計的用戶友好界面管理用戶和群組的模型。

- 🔑 **API 密鑰身份驗證**：輕鬆啟用或禁用 API 密鑰身份驗證，增強安全性。

- 🔄 **統一模型重置**：透過一鍵選項重置並從管理設置中移除所有模型。

- 🔓 **靈活的模型訪問控制**：在不需要時，使用 BYPASS_MODEL_ACCESS_CONTROL 環境變數輕鬆繞過用戶角色的模型訪問控制，簡化可信環境中的工作流程。

- 🔒 **可配置的 API 金鑰身份驗證限制**：靈活配置 API 金鑰身份驗證的端點限制，預設關閉以便在可信環境中更流暢地設置。

---
